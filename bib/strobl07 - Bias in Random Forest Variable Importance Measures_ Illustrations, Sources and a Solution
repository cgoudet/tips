<!DOCTYPE html>
<html lang="en" class="no-js">
    <head>
        <meta charset="UTF-8"/>
        <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
        <meta name="viewport" content="width=device-width, initial-scale=1"/>

        <title>Bias in random forest variable importance measures: Illustrations, sources and a solution | BMC Bioinformatics | Full Text</title>

        

    <meta name="citation_abstract" content="Variable importance measures for random forests have been receiving increased attention as a means of variable selection in many classification tasks in bioinformatics and related scientific fields, for instance to select a subset of genetic markers relevant for the prediction of a certain disease. We show that random forest variable importance measures are a sensible means for variable selection in many applications, but are not reliable in situations where potential predictor variables vary in their scale of measurement or their number of categories. This is particularly important in genomics and computational biology, where predictors often include variables of different types, for example when predictors include both sequence data and continuous variables such as folding energy, or when amino acid sequence data show different numbers of categories. Simulation studies are presented illustrating that, when random forest variable importance measures are used with data of varying types, the results are misleading because suboptimal predictor variables may be artificially preferred in variable selection. The two mechanisms underlying this deficiency are biased variable selection in the individual classification trees used to build the random forest on one hand, and effects induced by bootstrap sampling with replacement on the other hand. We propose to employ an alternative implementation of random forests, that provides unbiased variable selection in the individual classification trees. When this method is applied using subsampling without replacement, the resulting variable importance measures can be used reliably for variable selection even in situations where the potential predictor variables vary in their scale of measurement or their number of categories. The usage of both random forest algorithms and their variable importance measures in the R system for statistical computing is illustrated and documented thoroughly in an application re-analyzing data from a study on RNA editing. Therefore the suggested method can be applied straightforwardly by scientists in bioinformatics research."/>

    <meta name="journal_id" content="12859"/>

    <meta name="dc.title" content="Bias in random forest variable importance measures: Illustrations, sources and a solution"/>

    <meta name="dc.source" content="BMC Bioinformatics 2007 8:1"/>

    <meta name="dc.format" content="text/html"/>

    <meta name="dc.publisher" content="BioMed Central"/>

    <meta name="dc.date" content="2007-01-25"/>

    <meta name="dc.type" content="OriginalPaper"/>

    <meta name="dc.language" content="En"/>

    <meta name="dc.copyright" content="2007 Strobl et al; licensee BioMed Central Ltd."/>

    <meta name="dc.rightsAgent" content="reprints@biomedcentral.com"/>

    <meta name="dc.description" content="Variable importance measures for random forests have been receiving increased attention as a means of variable selection in many classification tasks in bioinformatics and related scientific fields, for instance to select a subset of genetic markers relevant for the prediction of a certain disease. We show that random forest variable importance measures are a sensible means for variable selection in many applications, but are not reliable in situations where potential predictor variables vary in their scale of measurement or their number of categories. This is particularly important in genomics and computational biology, where predictors often include variables of different types, for example when predictors include both sequence data and continuous variables such as folding energy, or when amino acid sequence data show different numbers of categories. Simulation studies are presented illustrating that, when random forest variable importance measures are used with data of varying types, the results are misleading because suboptimal predictor variables may be artificially preferred in variable selection. The two mechanisms underlying this deficiency are biased variable selection in the individual classification trees used to build the random forest on one hand, and effects induced by bootstrap sampling with replacement on the other hand. We propose to employ an alternative implementation of random forests, that provides unbiased variable selection in the individual classification trees. When this method is applied using subsampling without replacement, the resulting variable importance measures can be used reliably for variable selection even in situations where the potential predictor variables vary in their scale of measurement or their number of categories. The usage of both random forest algorithms and their variable importance measures in the R system for statistical computing is illustrated and documented thoroughly in an application re-analyzing data from a study on RNA editing. Therefore the suggested method can be applied straightforwardly by scientists in bioinformatics research."/>

    <meta name="prism.issn" content="1471-2105"/>

    <meta name="prism.publicationName" content="BMC Bioinformatics"/>

    <meta name="prism.publicationDate" content="2007-01-25"/>

    <meta name="prism.volume" content="8"/>

    <meta name="prism.number" content="1"/>

    <meta name="prism.section" content="OriginalPaper"/>

    <meta name="prism.startingPage" content="1"/>

    <meta name="prism.endingPage" content="21"/>

    <meta name="prism.copyright" content="2007 Strobl et al; licensee BioMed Central Ltd."/>

    <meta name="prism.rightsAgent" content="reprints@biomedcentral.com"/>

    <meta name="prism.url" content="https://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-8-25"/>

    <meta name="prism.doi" content="doi:10.1186/1471-2105-8-25"/>

    <meta name="citation_pdf_url" content="https://bmcbioinformatics.biomedcentral.com/track/pdf/10.1186/1471-2105-8-25"/>

    <meta name="citation_fulltext_html_url" content="https://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-8-25"/>

    <meta name="citation_journal_title" content="BMC Bioinformatics"/>

    <meta name="citation_journal_abbrev" content="BMC Bioinformatics"/>

    <meta name="citation_publisher" content="BioMed Central"/>

    <meta name="citation_issn" content="1471-2105"/>

    <meta name="citation_title" content="Bias in random forest variable importance measures: Illustrations, sources and a solution"/>

    <meta name="citation_volume" content="8"/>

    <meta name="citation_issue" content="1"/>

    <meta name="citation_publication_date" content="2007/12"/>

    <meta name="citation_online_date" content="2007/01/25"/>

    <meta name="citation_firstpage" content="1"/>

    <meta name="citation_lastpage" content="21"/>

    <meta name="citation_article_type" content="Methodology article"/>

    <meta name="citation_fulltext_world_readable" content=""/>

    <meta name="citation_language" content="en"/>

    <meta name="dc.identifier" content="doi:10.1186/1471-2105-8-25"/>

    <meta name="DOI" content="10.1186/1471-2105-8-25"/>

    <meta name="citation_doi" content="10.1186/1471-2105-8-25"/>

    <meta name="description" content="Variable importance measures for random forests have been receiving increased attention as a means of variable selection in many classification tasks in bioinformatics and related scientific fields, for instance to select a subset of genetic markers relevant for the prediction of a certain disease. We show that random forest variable importance measures are a sensible means for variable selection in many applications, but are not reliable in situations where potential predictor variables vary in their scale of measurement or their number of categories. This is particularly important in genomics and computational biology, where predictors often include variables of different types, for example when predictors include both sequence data and continuous variables such as folding energy, or when amino acid sequence data show different numbers of categories. Simulation studies are presented illustrating that, when random forest variable importance measures are used with data of varying types, the results are misleading because suboptimal predictor variables may be artificially preferred in variable selection. The two mechanisms underlying this deficiency are biased variable selection in the individual classification trees used to build the random forest on one hand, and effects induced by bootstrap sampling with replacement on the other hand. We propose to employ an alternative implementation of random forests, that provides unbiased variable selection in the individual classification trees. When this method is applied using subsampling without replacement, the resulting variable importance measures can be used reliably for variable selection even in situations where the potential predictor variables vary in their scale of measurement or their number of categories. The usage of both random forest algorithms and their variable importance measures in the R system for statistical computing is illustrated and documented thoroughly in an application re-analyzing data from a study on RNA editing. Therefore the suggested method can be applied straightforwardly by scientists in bioinformatics research."/>

    <meta name="dc.creator" content="Carolin Strobl"/>

    <meta name="dc.creator" content="Anne-Laure Boulesteix"/>

    <meta name="dc.creator" content="Achim Zeileis"/>

    <meta name="dc.creator" content="Torsten Hothorn"/>

    <meta name="dc.subject" content="Bioinformatics"/>

    <meta name="dc.subject" content="Microarrays"/>

    <meta name="dc.subject" content="Computational Biology/Bioinformatics"/>

    <meta name="dc.subject" content="Computer Appl. in Life Sciences"/>

    <meta name="dc.subject" content="Algorithms"/>

    <meta name="dc.subject" content="Algorithms"/>

    <meta name="citation_reference" content="citation_journal_title=Genetic Epidemiology; citation_title=Identifying SNPs Predictive of Phenotype Using Random Forests; citation_author=A Bureau, J Dupuis, K Falls, KL Lunetta, B Hayward, TP Keith, PV Eerdewegh; citation_volume=28; citation_publication_date=2005; citation_pages=171-182; citation_doi=10.1002/gepi.20041; citation_id=CR1"/>

    <meta name="citation_reference" content="citation_journal_title=BMC Genetics; citation_title=The Challenge for Genetic Epidemiologists: How to Analyze Large Numbers of SNPs in Relation to Complex Diseases; citation_author=AG Heidema, JMA Boer, N Nagelkerke, ECM Mariman, DL van der A, EJM Feskens; citation_volume=7; citation_publication_date=2006; citation_pages=23; citation_doi=10.1186/1471-2156-7-23; citation_id=CR2"/>

    <meta name="citation_reference" content="citation_journal_title=Machine Learning; citation_title=Random Forests; citation_author=L Breiman; citation_volume=45; citation_publication_date=2001; citation_pages=5-32; citation_doi=10.1023/A:1010933404324; citation_id=CR3"/>

    <meta name="citation_reference" content="citation_journal_title=BMC Bioinformatics; citation_title=Gene Selection and Classification of Microarray Data Using Random Forest; citation_author=R D&#237;az-Uriarte, S Alvarez de Andr&#233;s; citation_volume=7; citation_publication_date=2006; citation_pages=3; citation_doi=10.1186/1471-2105-7-3; citation_id=CR4"/>

    <meta name="citation_reference" content="citation_journal_title=BMC Genetics; citation_title=Screening Large-Scale Association Study Data: Exploiting Interactions Using Random Forests; citation_author=KL Lunetta, LB Hayward, J Segal, PV Eerdewegh; citation_volume=5; citation_publication_date=2004; citation_pages=32; citation_doi=10.1186/1471-2156-5-32; citation_id=CR5"/>

    <meta name="citation_reference" content="citation_journal_title=Proceedings of the National Academy of Sciences; citation_title=Prediction of Clinical Drug Efficacy by Classification of Drug-induced Genomic Expression Profiles in vitro; citation_author=EC Gunther, DJ Stone, RW Gerwien, P Bento, MP Heyes; citation_volume=100; citation_publication_date=2003; citation_pages=9608-9613; citation_doi=10.1073/pnas.1632587100; citation_id=CR6"/>

    <meta name="citation_reference" content="citation_journal_title=BMC Bioinformatics; citation_title=A Comparative Study of Discriminating Human Heart Failure Etiology Using Gene Expression Profiles; citation_author=X Huang, W Pan, S Grindle, X Han, Y Chen, SJ Park, LW Miller, J Hall; citation_volume=6; citation_publication_date=2005; citation_pages=205; citation_doi=10.1186/1471-2105-6-205; citation_id=CR7"/>

    <meta name="citation_reference" content="citation_journal_title=Modern Pathology; citation_title=Tumor Classification by Tissue Microarray Profiling: Random Forest Clustering Applied to Renal Cell Carcinoma; citation_author=Y Shih; citation_volume=18; citation_publication_date=2005; citation_pages=547-557; citation_doi=10.1038/modpathol.3800322; citation_id=CR8"/>

    <meta name="citation_reference" content="citation_journal_title=Statistical Applications in Genetics and Molecular Biology; citation_title=Relating HIV-1 Sequence Variation to Replication Capacity via Trees and Forests; citation_author=MR Segal, JD Barbour, RM Grant; citation_volume=3; citation_publication_date=2004; citation_pages=2; citation_id=CR9"/>

    <meta name="citation_reference" content="citation_journal_title=BMC Bioinformatics; citation_title=Few Amino Acid Positions in rpoB are Associated with Most of the Rifampin Resistance in Mycobacterium Tuberculosis; citation_author=MP Cummings, MR Segal; citation_volume=5; citation_publication_date=2004; citation_pages=137; citation_doi=10.1186/1471-2105-5-137; citation_id=CR10"/>

    <meta name="citation_reference" content="citation_journal_title=BMC Bioinformatics; citation_title=Simple Statistical Models Predict C-to-U Edited Sites in Plant Mitochondrial RNA; citation_author=MP Cummings, DS Myers; citation_volume=5; citation_publication_date=2004; citation_pages=132; citation_doi=10.1186/1471-2105-5-132; citation_id=CR11"/>

    <meta name="citation_reference" content="citation_journal_title=Proteins; citation_title=Evaluation of Different Biological Data and Computational Classification Methods for Use in Protein Interaction Prediction; citation_author=Y Qi, Z Bar-Joseph, J Klein-Seetharaman; citation_volume=63; citation_publication_date=2006; citation_pages=490-500; citation_doi=10.1002/prot.20865; citation_id=CR12"/>

    <meta name="citation_reference" content="citation_journal_title=Journal of Chemical Information and Computer Sciences; citation_title=Development of Linear, Ensemble, and Nonlinear Models for the Prediction and Interpretation of the Biological Activity of a Set of PDGFR Inhibitors; citation_author=R Guha, PC Jurs; citation_volume=44; citation_publication_date=2003; citation_pages=2179-2189; citation_id=CR13"/>

    <meta name="citation_reference" content="citation_journal_title=Journal of Chemical Information and Computer Sciences; citation_title=Random Forest: A Classification and Regression Tool for Compound Classification and QSAR Modeling; citation_author=V Svetnik, A Liaw, C Tong, JC Culberson, RP Sheridan, BP Feuston; citation_volume=43; citation_publication_date=2003; citation_pages=1947-1958; citation_id=CR14"/>

    <meta name="citation_reference" content="citation_title=Structure Based Chemical Shift Prediction Using Random Forests Non-linear Regression; citation_inbook_title=Proceedings of the Fourth Asia-Pacific Bioinformatics Conference, Taipei, Taiwan; citation_publication_date=2006; citation_pages=317-326; citation_id=CR15; citation_author=K Arun; citation_author=CJ Langmead"/>

    <meta name="citation_reference" content="citation_title=GIS and the Random Forest Predictor: Integration in R for Tick-Borne Disease Risk Assessment; citation_inbook_title=Proceedings of the 3rd International Workshop on Distributed Statistical Computing, Vienna, Austria; citation_publication_date=2003; citation_id=CR16; citation_author=C Furlanello; citation_author=M Neteler; citation_author=S Merler; citation_author=S Menegon; citation_author=S Fontanari; citation_author=D Donini; citation_author=A Rizzoli; citation_author=C Chemini"/>

    <meta name="citation_reference" content="citation_journal_title=Arthritis and Rheumatism; citation_title=Short-Term Prediction of Mortality in Patients with Systemic Lupus Erythematosus: Classification of Outcomes Using Random Forests; citation_author=MM Ward, S Pajevic, J Dreyfuss, JD Malley; citation_volume=55; citation_publication_date=2006; citation_pages=74-80; citation_doi=10.1002/art.21695; citation_id=CR17"/>

    <meta name="citation_reference" content="citation_title=Classification and Regression Trees; citation_publication_date=1984; citation_id=CR18; citation_author=L Breiman; citation_author=JH Friedman; citation_author=RA Olshen; citation_author=CJ Stone; citation_publisher=Chapman and Hall"/>

    <meta name="citation_reference" content="citation_journal_title=The Annals of Statistics; citation_title=Greedy Function Approximation: A Gradient Boosting Machine; citation_author=J Friedman; citation_volume=29; citation_publication_date=2001; citation_pages=1189-1232; citation_doi=10.1214/aos/1013203451; citation_id=CR19"/>

    <meta name="citation_reference" content="citation_title=R: A Language and Environment for Statistical Computing; citation_publication_date=2006; citation_id=CR20; citation_publisher=R Foundation for Statistical Computing"/>

    <meta name="citation_reference" content="citation_title=Breiman and Cutler&#39;s Random Forests for Classification and Regression; citation_publication_date=2006; citation_id=CR21; citation_author=L Breiman; citation_author=A Cutler; citation_author=A Liaw; citation_author=M Wiener"/>

    <meta name="citation_reference" content="citation_journal_title=R News; citation_title=Classification and Regression by randomForest; citation_author=A Liaw, M Wiener; citation_volume=2; citation_publication_date=2002; citation_pages=18-22; citation_id=CR22"/>

    <meta name="citation_reference" content="citation_title=party: A Laboratory for Recursive Part(y)itioning; citation_publication_date=2006; citation_id=CR23; citation_author=T Hothorn; citation_author=K Hornik; citation_author=A Zeileis"/>

    <meta name="citation_reference" content="citation_title=On Biases in Estimating Multi-Valued Attributes; citation_inbook_title=Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence, Montr&#233;al, Canada; citation_publication_date=1995; citation_pages=1034-1040; citation_id=CR24; citation_author=I Kononenko"/>

    <meta name="citation_reference" content="citation_journal_title=Journal of the American Statistical Association; citation_title=Classification Trees with Unbiased Multiway Splits; citation_author=H Kim, W Loh; citation_volume=96; citation_publication_date=2001; citation_pages=589-604; citation_doi=10.1198/016214501753168271; citation_id=CR25"/>

    <meta name="citation_reference" content="citation_journal_title=Biometrical Journal; citation_title=Maximally Selected Chi-square Statistics for Ordinal Variables; citation_author=AL Boulesteix; citation_volume=48; citation_publication_date=2006; citation_pages=451-462; citation_doi=10.1002/bimj.200510161; citation_id=CR26"/>

    <meta name="citation_reference" content="citation_journal_title=Biometrical Journal; citation_title=Maximally Selected Chi-square Statistics and Binary Splits of Nominal Variables; citation_author=AL Boulesteix; citation_volume=48; citation_publication_date=2006; citation_pages=838-848; citation_doi=10.1002/bimj.200510191; citation_id=CR27"/>

    <meta name="citation_reference" content="citation_title=Unbiased Split Selection for Classification Trees Based on the Gini Index; citation_inbook_title=Computational Statistics &amp; Data Analysis; citation_publication_date=2006; citation_id=CR28; citation_author=C Strobl; citation_author=AL Boulesteix; citation_author=T Augustin"/>

    <meta name="citation_reference" content="citation_journal_title=Journal of Computational and Graphical Statistics; citation_title=Unbiased Recursive Partitioning: A Conditional Inference Framework; citation_author=T Hothorn, K Hornik, A Zeileis; citation_volume=15; citation_publication_date=2006; citation_pages=651-674; citation_doi=10.1198/106186006X133933; citation_id=CR29"/>

    <meta name="citation_reference" content="citation_title=On Bagging and Nonlinear Estimation; citation_inbook_title=preprint; citation_publication_date=1999; citation_id=CR30; citation_author=J Friedman; citation_author=P Hall"/>

    <meta name="citation_reference" content="citation_journal_title=The Annals of Statistics; citation_title=Analyzing Bagging; citation_author=P B&#252;hlmann, B Yu; citation_volume=30; citation_publication_date=2002; citation_pages=927-961; citation_doi=10.1214/aos/1031689014; citation_id=CR31"/>

    <meta name="citation_reference" content="citation_title=Subsampling; citation_publication_date=1999; citation_id=CR32; citation_author=DN Politis; citation_author=JP Romano; citation_author=M Wolf; citation_publisher=Springer"/>

    <meta name="citation_reference" content="citation_title=Bias Correction in Classification Tree Construction; citation_inbook_title=Proceedings of the Seventeenth International Conference on Machine Learning, Williams College, Williamstown, MA, USA; citation_publication_date=2001; citation_pages=90-97; citation_id=CR33; citation_author=A Dobra; citation_author=J Gehrke"/>

    <meta name="citation_reference" content="citation_title=Statistical Sources of Variable Selection Bias in Classification Tree Algorithms Based on the Gini Index; citation_inbook_title=Discussion Paper 420, SFB &quot;Statistical Analysis of Discrete Structures&quot;, Munich, Germany; citation_publication_date=2005; citation_id=CR34; citation_author=C Strobl"/>

    <meta name="citation_reference" content="citation_title=Variable Selection in Classification Trees Based on Imprecise Probabilities; citation_inbook_title=Proceedings of the Fourth International Symposium on Imprecise Probabilities and Their Applications, Carnegy Mellon University, Pittsburgh, PA, USA; citation_publication_date=2005; citation_pages=340-348; citation_id=CR35; citation_author=C Strobl"/>

    <meta name="citation_reference" content="citation_title=rpart: Recursive Partitioning; citation_publication_date=2006; citation_id=CR36; citation_author=TM Therneau; citation_author=B Atkinson; citation_author=BD Ripley"/>

    <meta name="citation_reference" content="citation_title=The Bootstrap in Hypothesis Testing; citation_inbook_title=State of the Art in Probability and Statistics, Festschrift for Willem R. van Zwet, IMS Lecture Notes Monograph Series, Beachwood, OH, USA; citation_publication_date=2001; citation_pages=91-112; citation_id=CR37; citation_author=PJ Bickel; citation_author=JJ Ren"/>

    <meta name="citation_reference" content="citation_journal_title=International Journal of Biostatistics; citation_title=Statistical Inference for Variable Importance; citation_author=M van der Laan; citation_volume=2; citation_publication_date=2006; citation_pages=1008-1008; citation_id=CR38"/>

    <meta name="citation_author" content="Carolin Strobl"/>

    <meta name="citation_author_institution" content="Institut f&#252;r Statistik, Ludwig-Maximilians-Universit&#228;t M&#252;nchen, Germany"/>

    <meta name="citation_author" content="Anne-Laure Boulesteix"/>

    <meta name="citation_author_institution" content="Institut f&#252;r medizinische Statistik und Epidemiologie, Technische Universit&#228;t M&#252;nchen, M&#252;nchen, Germany"/>

    <meta name="citation_author" content="Achim Zeileis"/>

    <meta name="citation_author_institution" content="Department f&#252;r Statistik und Mathematik, Wirtschaftsuniversit&#228;t Wien, Wien, Austria"/>

    <meta name="citation_author" content="Torsten Hothorn"/>

    <meta name="citation_author_institution" content="Institut f&#252;r Medizininformatik, Biometrie und Epidemiologie, Friedrich-Alexander-Universtit&#228;t Erlangen-N&#252;rnberg, Germany"/>



        <meta name="format-detection" content="telephone=no">

        <link rel="shortcut icon" data-test="shortcut-icon"
      href=/static/images/favicons/bmc/favicon-9ff1bf1161.ico>
<link rel="apple-touch-icon"
      sizes="114x114"
      href=/static/images/favicons/bmc/app-icon-114x114-3b8894feb3.png>
<link rel="apple-touch-icon"
      sizes="144x144"
      href=/static/images/favicons/bmc/app-icon-144x144-46be65d032.png>
<link rel="apple-touch-icon"
      sizes="180x180"
      href=/static/images/favicons/bmc/app-icon-180x180-d205ab10f5.png>
<link rel="icon"
      type="image/png"
      sizes="16x16"
      href=/static/images/favicons/bmc/favicon-16x16-5beafe3a97.png>
<link rel="icon"
      type="image/png"
      sizes="32x32"
      href=/static/images/favicons/bmc/favicon-32x32-103a91ebba.png>
<link rel="icon"
      type="image/png"
      sizes="96x96"
      href=/static/images/favicons/bmc/favicon-96x96-6aff193bdb.png>
<link rel="icon"
      type="image/png"
      sizes="194x194"
      href=/static/images/favicons/bmc/favicon-194x194-501ed5e5ea.png>
<meta name="msapplication-TileColor"
      content="#e6e6e6">
<meta name="msapplication-TileImage"
      content=/static/images/favicons/bmc/app-icon-144x144-46be65d032.png>
<meta name="theme-color"
      content="#1b3051">


        <script>(function(H){H.className=H.className.replace(/\bno-js\b/,'js')})(document.documentElement)</script>
        
    <link rel="stylesheet" media="screen" href=/static/app-bmc/core-article-f837ea88d2.css>


<link rel="stylesheet" media="screen" href=/static/app-bmc/core-d3fdd25a61.css>
<link rel="stylesheet" media="print" href=/static/app-bmc/print-7680b1a80b.css>

<link rel="stylesheet" id="js-mustard" href=/static/app-bmc/enhanced-9a3a5f7091.css
      media="only screen and (-webkit-min-device-pixel-ratio:0) and (min-color-index:0), (-ms-high-contrast: none), only all and (min--moz-device-pixel-ratio:0) and (min-resolution: 3e1dpcm)">


    <link rel="stylesheet" href=/static/app-bmc/enhanced-article-a205d1f7a8.css
          media="only screen and (-webkit-min-device-pixel-ratio:0) and (min-color-index:0), (-ms-high-contrast: none), only all and (min--moz-device-pixel-ratio:0) and (min-resolution: 3e1dpcm)">


        

        <script>
            window.airbrakeErrors = [];
            window.onerror = function(error) {window.airbrakeErrors.push(error);}
        </script>

        
    <script type="text/javascript">
        config = {
            env: 'live',
            site: 'bmcbioinformatics.biomedcentral.com',
            siteWithPath: 'bmcbioinformatics.biomedcentral.com' + window.location.pathname,
            twitterHashtag: 'bmcbioinformatics',
            cmsPrefix: 'https://studio-cms.springernature.com/studio/',
            
            doi: '10.1186/1471-2105-8-25',
            figshareScriptUrl: 'https://widgets.figshare.com/static/figshare.js',
            hasFigshareInvoked: false,
            publisherBrand: 'BioMed Central',
            mustardcut: false
        };
    </script>

        <!-- SpringerLink's event tracker, as per: https://github.com/springernature/springerlink-event-tracker -->

<script type="text/javascript">
document.addEventListener('dataLayerCreated', function() {
    var script = document.createElement('script');
    script.id = 'springerlink-event-tracker';
    script.src = 'https://event-tracker.springernature.com/dist/eventTracker.js';
    script.onload = function () {
        var dL;
        var doi;
        var imprint;
        var bpids;
        var publisher;
        var pageType;
        var eventObject;

        for (var i = 0; i < window.dataLayer.length; i++) {
            if (window.dataLayer[i].event === "dataLayerCreated") {
                dL = window.dataLayer[i];
            }
        }

        if (!dL || !dL.content.article || !dL.content.article.doi) { return false;}

        doi = dL.content.article.doi;
        imprint = dL.content.contentInfo.imprint;
        bpids = dL.session.authentication.authenticationID;
        pageType = dL.page.category.pageType;

        if (pageType) {
            pageType = pageType.charAt(0).toUpperCase() + pageType.substring(1);
        }

        eventObject = {'content_type': pageType, 'doi': doi};

        if (imprint === 'BioMed Central') {
            publisher = 'BMC';
        }
        else if (imprint === 'SpringerOpen') {
            publisher = 'SpringerOpen';
        }
        else {
            throw new Error('Event Tracker Error: The publisher has an unexpected value');
        }

        if (bpids.length > 0) {
            eventObject['business_partner_ids'] = bpids;
        }

        new EventTracker({'platform': publisher}).sendEvent('display', eventObject);
    };
    document.head.appendChild(script);
});
</script>

        <!--Polyfills CustomEvent constructor in IE. Allows us to use events to manage race conditions in client side js-->
<script>
    (function () {
        if (typeof window.CustomEvent === "function") { return false; } // If IE polyfill not needed just return

        function CustomEvent ( event, params ) {
            params = params || { bubbles: false, cancelable: false, detail: undefined };
            var evt = document.createEvent( 'CustomEvent' );
            evt.initCustomEvent( event, params.bubbles, params.cancelable, params.detail );
            return evt;
        }

        CustomEvent.prototype = window.Event.prototype;

        window.CustomEvent = CustomEvent;
    })();
</script> 
        
    <script type="text/javascript" data-test="dataLayer">
        window.dataLayer = [{"content":{"article":{"doi":"10.1186/1471-2105-8-25","articleType":"Methodology article","peerReviewType":"Closed","supplement":null,"keywords":"Variable Selection;Random Forest;Bootstrap Sampling;Variable Importance;Importance Measure"},"contentInfo":{"imprint":"BioMed Central","title":"Bias in random forest variable importance measures: Illustrations, sources and a solution","publishedAt":1169683200000,"publishedAtDate":"2007-01-25","author":["Carolin Strobl","Anne-Laure Boulesteix","Achim Zeileis","Torsten Hothorn"],"collection":[]},"attributes":{"deliveryPlatform":"oscar","template":"rebrand","cms":null,"copyright":{"creativeCommonsType":"CC BY","openAccess":true},"environment":"live"},"journal":{"siteKey":"bmcbioinformatics.biomedcentral.com","volume":"8","issue":"1","title":"BMC Bioinformatics","type":"SERIES","journalID":12859,"gaCode":"UA-62065396-3","section":[]},"category":{"pmc":{"primarySubject":"Life Sciences"},"contentType":"Methodology article","publishingSegment":"BMC Series - Life and Health"}},"session":{"authentication":{"authenticationID":[]}},"version":"1.0.0","page":{"category":{"pageType":"article"},"attributes":{"featureFlags":[]},"name":null},"event":"dataLayerCreated"}];
        var event = new CustomEvent('dataLayerCreated');
        document.dispatchEvent(event);
    </script>


        <script>
            
            var mustardcutlink = document.getElementById('js-mustard');
            if (mustardcutlink && window.matchMedia && window.matchMedia(mustardcutlink.media).matches) {
                window.config.mustardcut = true;
            }
        </script>
        <script>
            (function(d){
                var config = window.config;
                if (config && config.mustardcut && config.publisherBrand && sessionStorage.fontsLoaded === 'true') {
                    d.className += ' webfonts-loaded';
                }
            })(document.documentElement);
        </script>

        
    
        <script src="/static/js/jquery-220afd743d.js"></script>
    
    <script src="https://cdn.cookielaw.org/consent/7d6f4b4f-77fb-43b9-b429-eb1e1eeac6aa.js" id="onetrust-bmc-control" charset="UTF-8"></script>

        
    
        
    

        
    
        
            <!-- Google Tag Manager -->
            <script>
                (function (w, d, s, l, i) {
                w[l] = w[l] || [];
                w[l].push({'gtm.start': new Date().getTime(), event: 'gtm.js'});
                var f = d.getElementsByTagName(s)[0],
                        j = d.createElement(s),
                        dl = l != 'dataLayer' ? '&l=' + l : '';
                j.async = true;
                j.src = 'https://www.googletagmanager.com/gtm.js?id=' + i + dl;
                f.parentNode.insertBefore(j, f);
            })(window, document, 'script', 'dataLayer', 'GTM-TDGJHK');
            </script>
            <!-- End Google Tag Manager -->
        
    


        
    
    <link rel="canonical" href="https://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-8-25"/>
    

        
        
        <meta property="og:url" content="https://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-8-25"/>
        <meta property="og:type" content="article"/>
        <meta property="og:site_name" content="BMC Bioinformatics"/>
        <meta property="og:title" content="Bias in random forest variable importance measures: Illustrations, sources and a solution"/>
        <meta property="og:description" content="Variable importance measures for random forests have been receiving increased attention as a means of variable selection in many classification tasks in bioinformatics and related scientific fields, for instance to select a subset of genetic markers relevant for the prediction of a certain disease. We show that random forest variable importance measures are a sensible means for variable selection in many applications, but are not reliable in situations where potential predictor variables vary in their scale of measurement or their number of categories. This is particularly important in genomics and computational biology, where predictors often include variables of different types, for example when predictors include both sequence data and continuous variables such as folding energy, or when amino acid sequence data show different numbers of categories. Simulation studies are presented illustrating that, when random forest variable importance measures are used with data of varying types, the results are misleading because suboptimal predictor variables may be artificially preferred in variable selection. The two mechanisms underlying this deficiency are biased variable selection in the individual classification trees used to build the random forest on one hand, and effects induced by bootstrap sampling with replacement on the other hand. We propose to employ an alternative implementation of random forests, that provides unbiased variable selection in the individual classification trees. When this method is applied using subsampling without replacement, the resulting variable importance measures can be used reliably for variable selection even in situations where the potential predictor variables vary in their scale of measurement or their number of categories. The usage of both random forest algorithms and their variable importance measures in the R system for statistical computing is illustrated and documented thoroughly in an application re-analyzing data from a study on RNA editing. Therefore the suggested method can be applied straightforwardly by scientists in bioinformatics research."/>
        <meta property="og:image" content="https://media.springernature.com/w110/springer-static/cover/journal/12859.jpg"/>
    
        
    </head>

    <body class="journal journal-fulltext"
    
          >
        
    
        
            <!-- Google Tag Manager (noscript) -->
            <noscript>
                <iframe src="https://www.googletagmanager.com/ns.html?id=GTM-TDGJHK"
                        height="0" width="0" style="display:none;visibility:hidden"></iframe>
            </noscript>
            <!-- End Google Tag Manager (noscript) -->
        
    

        <div class="u-visually-hidden" aria-hidden="true">
    
    <?xml version="1.0" encoding="UTF-8"?><!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"><svg xmlns="http://www.w3.org/2000/svg"><symbol id="icon-alert" viewBox="0 0 18 18"><path fill-rule="evenodd" d="M4 10h2.5a.5.5 0 010 1H3.414l-1.121 1.121a1 1 0 00-.293.707V13h14v-.172a1 1 0 00-.293-.707L14 10.414V7A5 5 0 004 7zm3 4a2 2 0 104 0zm-5 0a1 1 0 01-1-1v-.172a2 2 0 01.586-1.414L3 10V7a6 6 0 1112 0v3l1.414 1.414A2 2 0 0117 12.828V13a1 1 0 01-1 1h-4a3 3 0 01-6 0z"/></symbol><symbol id="icon-arrow-left-bullet" viewBox="0 0 8 16"><path d="M3 8l5 5v3L0 8l8-8v3L3 8z"/></symbol><symbol id="icon-arrow-left"><path d="M7.002 15.002a1 1 0 102 0V3.386l2.482 2.482a.994.994 0 001.403.02 1.001 1.001 0 00.001-1.416l-.001-.001L8.71.295a1 1 0 00-1.415 0h-.001L3.118 4.472a.99.99 0 00-.016 1.4 1 1 0 001.414.003l.006-.006 2.48-2.482v11.615z"/></symbol><symbol id="icon-book" viewBox="0 0 18 18"><path fill-rule="evenodd" d="M4 13V2h1v11h11V2H3a1 1 0 00-1 1v10.268A1.99 1.99 0 013 13zm12 1H3a1 1 0 000 2h13zm0 3H3a2 2 0 01-2-2V3a2 2 0 012-2h13a1 1 0 011 1v14a1 1 0 01-1 1zM7.5 4h6a.5.5 0 110 1h-6a.5.5 0 010-1zm1 2h4a.5.5 0 110 1h-4a.5.5 0 010-1z"/></symbol><symbol id="icon-chevron-down"><path d="M8 8.586l3.293-3.293a1 1 0 011.414 1.414l-4 4a1 1 0 01-1.414 0l-4-4a1 1 0 011.414-1.414z" fill-rule="evenodd"/></symbol><symbol id="icon-chevron-right"><path d="M7.782 7L5.3 4.518a.994.994 0 01-.02-1.403 1.001 1.001 0 011.417 0l4.176 4.177a1.001 1.001 0 010 1.416l-4.176 4.177a.991.991 0 01-1.4.016 1 1 0 01.003-1.42L7.782 9l1.013-.998z" fill-rule="evenodd"/></symbol><symbol id="icon-chevron-up"><path d="M8 7.414l3.293 3.293a1 1 0 001.414-1.414l-4-4a1 1 0 00-1.414 0l-4 4a1 1 0 001.414 1.414z" fill-rule="evenodd"/></symbol><symbol id="icon-download-rounded"><path d="M0 13c0-.556.449-1 1.002-1h9.996a.999.999 0 110 2H1.002A1.006 1.006 0 010 13zM7 1v6.8l2.482-2.482c.392-.392 1.022-.4 1.403-.02a1.001 1.001 0 010 1.417l-4.177 4.177a1.001 1.001 0 01-1.416 0L1.115 6.715a.991.991 0 01-.016-1.4 1 1 0 011.42.003L5 7.8V1c0-.55.444-.996 1-.996.552 0 1 .445 1 .996z"/></symbol><symbol id="icon-download" viewBox="-301 390 9 14"><path d="M-301 395.6l4.5 5.1 4.5-5.1h-3V390h-3v5.6h-3zm0 6.5h9v1.9h-9z"/></symbol><symbol id="icon-editors" viewBox="0 0 18 18"><path fill-rule="evenodd" d="M8.726 2.546A3 3 0 105.37 7.519l.63.409v1.024l-.79.329A5.221 5.221 0 002 14.099V15H1v-.901a6.221 6.221 0 013.825-5.741 4 4 0 114.976-6.213 4.965 4.965 0 00-1.075.4zM6 17H5v-.901a6.221 6.221 0 013.825-5.741 4 4 0 114.349 0A6.221 6.221 0 0117 16.099V17h-1v-.901a5.221 5.221 0 00-3.21-4.818l-.79-.33V9.929l.63-.409a3 3 0 10-3.26 0l.63.409v1.024l-.79.329A5.221 5.221 0 006 16.099z"/></symbol><symbol id="icon-ethics"><path d="M12.182 2.272l1.038-1.038a4.014 4.014 0 015.677 0l1.038 1.038a3.21 3.21 0 002.271.941h2.684a4.014 4.014 0 014.014 4.014v2.684c0 .852.339 1.669.94 2.271l1.039 1.038a4.014 4.014 0 010 5.677l-1.038 1.038a3.211 3.211 0 00-.94 2.271v2.684a4.014 4.014 0 01-4.015 4.014h-2.684c-.852 0-1.669.339-2.27.94l-1.039 1.039a4.014 4.014 0 01-5.677 0l-1.038-1.038a3.211 3.211 0 00-2.27-.94H7.226a4.014 4.014 0 01-4.014-4.015v-2.684c0-.852-.338-1.669-.94-2.27l-1.039-1.039a4.014 4.014 0 010-5.677l1.038-1.038a3.208 3.208 0 00.941-2.27V7.226a4.014 4.014 0 014.014-4.014H9.91c.852 0 1.669-.338 2.271-.94zm1.136 1.136a4.817 4.817 0 01-3.407 1.41H7.227a2.409 2.409 0 00-2.408 2.41V9.91a4.817 4.817 0 01-1.411 3.407L2.37 14.356a2.41 2.41 0 000 3.406L3.408 18.8a4.817 4.817 0 011.41 3.406v2.684a2.409 2.409 0 002.41 2.409H9.91a4.82 4.82 0 013.407 1.41l1.038 1.038c.94.941 2.465.941 3.406 0L18.8 28.71a4.817 4.817 0 013.406-1.41h2.684a2.409 2.409 0 002.409-2.409v-2.684c0-1.278.507-2.503 1.41-3.406l1.038-1.038a2.408 2.408 0 000-3.406l-1.038-1.038A4.817 4.817 0 0127.3 9.91V7.227a2.409 2.409 0 00-2.41-2.407h-2.684A4.817 4.817 0 0118.8 3.408L17.762 2.37a2.409 2.409 0 00-3.406 0l-1.038 1.038zM15.03 17.86l4.332-4.73a.803.803 0 111.224 1.04l-4.844 5.367a.803.803 0 01-1.112.076l-3.1-2.605a.803.803 0 011.027-1.233l2.473 2.085zm1.028 7.832c-.41 0-.41-1.482 0-1.482a8.152 8.152 0 006.657-12.858.741.741 0 111.21-.857 9.634 9.634 0 01-7.867 15.197zM21.68 8.234a.741.741 0 01-.866 1.203 8.152 8.152 0 00-12.908 6.578.741.741 0 01-1.483-.007A9.635 9.635 0 0121.68 8.234zM6.907 19.077a.741.741 0 011.407-.464 8.155 8.155 0 007.745 5.598.741.741 0 110 1.482 9.637 9.637 0 01-9.152-6.616z"/></symbol><symbol id="icon-explore"><path d="M15 28.3c7.3 0 13.3-6 13.3-13.3S22.3 1.7 15 1.7 1.7 7.7 1.7 15s6 13.3 13.3 13.3zm0 1.7C6.7 30 0 23.3 0 15S6.7 0 15 0s15 6.7 15 15-6.7 15-15 15zm0-4.2c-.5 0-.8-.3-.8-.8s.3-.8.8-.8c5 0 9-4 9.2-8.8 0-.5.3-.8.8-.8s.8.3.8.8c-.1 5.8-5 10.4-10.8 10.4zm-.5-21.6c.5 0 .8.3.8.8s-.3.8-.6.8c-5 .2-8.9 4.4-8.9 9.2 0 .5-.3.8-.8.8s-.8-.3-.8-.8c0-5.8 4.5-10.5 10.3-10.8zm1.8 13.5l-2-2c-.3-.3-.3-.8 0-1.2.3-.3.8-.3 1.2 0l2 2 2.7-6.7-7.5 2.8-3 7.5 6.6-2.4zm6.9-10.9L18.7 18c-.2.5-.5.8-1 1L6.5 23.5 11 12.3c.3-.7.7-1 1.2-1.2l11-4.3z"/></symbol><symbol id="icon-ext-link" viewBox="0 0 16 16"><path fill="#676767" d="M12.9 16H3.1C1.4 16 0 14.6 0 12.9V3.2C0 1.4 1.4 0 3.1 0h3.7v1H3.1C2 1 1 2 1 3.2v9.7C1 14 2 15 3.1 15h9.7c1.2 0 2.1-1 2.1-2.1V8.7h1v4.2c.1 1.7-1.3 3.1-3 3.1z"/><path fill="#676767" d="M12.8 2.5l.7.7-9 8.9-.7-.7 9-8.9z"/><path fill="#676767" d="M9.7 0L16 6.2V0z"/></symbol><symbol id="icon-info-bordered" viewBox="470.812 270.868 18 18"><path d="M479.812 270.868c-4.972 0-9 4.029-9 9s4.028 9 9 9c4.971 0 9-4.029 9-9s-4.029-9-9-9zm0 16.875a7.875 7.875 0 01-7.875-7.875 7.875 7.875 0 1115.75 0 7.875 7.875 0 01-7.875 7.875z"/><path d="M479.284 279.586c.089-.238-.024-.361-.13-.361-.489 0-1.123 1.16-1.359 1.16-.093 0-.173-.092-.173-.174 0-.238.581-.801.751-.971.526-.506 1.217-.895 1.979-.895.567 0 1.174.346.703 1.639l-.952 2.604c-.079.199-.224.531-.224.746 0 .092.054.186.159.186.395 0 1.121-1.135 1.304-1.135.067 0 .158.086.158.199 0 .385-1.542 2.043-2.874 2.043-.477 0-.804-.225-.804-.732 0-.641.447-1.734.538-1.963l.924-2.346zm.727-3.41c0-.586.498-1.066 1.082-1.066.527 0 .91.357.91.906 0 .615-.501 1.068-1.098 1.068-.541-.002-.894-.361-.894-.908z"/></symbol><symbol id="icon-opr" viewBox="0 0 18 18"><path d="M.9 2.5c-.2-.2-.4-.3-.6-.2-.3.2-.3.4-.3.6 0 .8 0 1.7.1 2.5 0 .5.3.7.7.6.9 0 1.7-.2 2.5-.3h.2c.5-.2.6-.5.3-.8-.2-.2-.4-.4-.6-.5-.1-.1-.2-.2-.4-.3.5-.6 1-1.1 1.7-1.5 4.6-3 10.9-.5 12 4.9.9 4.4-2.2 8.6-6.7 9.2-3.7.5-7.2-1.6-8.4-5.1 0-.1-.1-.2-.1-.3-.1-.3-.5-.5-.8-.4-.3.1-.5.4-.4.8.4 1.3 1.1 2.4 2 3.4 1.4 1.5 3.1 2.4 5.1 2.8 3 .5 5.6-.2 7.8-2.2 2.1-1.9 3-4.2 3-6.9-.1-4-3.1-7.6-7.1-8.4-3.3-.9-6.2 0-8.6 2.3-.2.1-.3.3-.5.5-.3-.2-.6-.5-.9-.7z"/><path d="M13 4.7c-2.6 1.6-4.5 3.6-5.3 4.6L5.6 7.7l-.9.7L8.3 12c.6-1.6 2.6-4.6 4.9-6.8l-.2-.5z"/></symbol><symbol id="icon-remove" viewBox="-296 388 18 18"><path d="M-291.7 396.1h9v2h-9z"/><path d="M-287 405.5c-4.7 0-8.5-3.8-8.5-8.5s3.8-8.5 8.5-8.5 8.5 3.8 8.5 8.5-3.8 8.5-8.5 8.5zm0-16c-4.1 0-7.5 3.4-7.5 7.5s3.4 7.5 7.5 7.5 7.5-3.4 7.5-7.5-3.4-7.5-7.5-7.5z"/></symbol><symbol id="icon-rss"><ellipse cx="3.305" cy="20.702" rx="3.306" ry="3.298"/><path d="M15.978 24h-4.684c0-6.224-5.057-11.27-11.294-11.27V8.058c8.824 0 15.978 7.137 15.978 15.942z"/><path d="M19.2 23.95C19.2 13.366 10.604 4.79 0 4.79V0c13.255 0 24 10.723 24 23.95h-4.8z"/></symbol><symbol id="icon-search"><path d="M13.545 12.648a.641.641 0 01.006.903.646.646 0 01-.903-.006l-2.664-2.663a6.125 6.125 0 11.897-.898l2.664 2.664zm-7.42-1.273a5.25 5.25 0 100-10.5 5.25 5.25 0 000 10.5z"/></symbol><symbol id="icon-springer-arrow-left"><path d="M15 7a1 1 0 000-2H3.385l2.482-2.482a.994.994 0 00.02-1.403 1.001 1.001 0 00-1.417 0L.294 5.292a1.001 1.001 0 000 1.416l4.176 4.177a.991.991 0 001.4.016 1 1 0 00-.003-1.42L3.385 7H15z"/></symbol><symbol id="icon-springer-arrow-right"><path d="M1 7a1 1 0 010-2h11.615l-2.482-2.482a.994.994 0 01-.02-1.403 1.001 1.001 0 011.417 0l4.176 4.177a1.001 1.001 0 010 1.416l-4.176 4.177a.991.991 0 01-1.4.016 1 1 0 01.003-1.42L12.615 7H1z"/></symbol><symbol id="icon-updates" viewBox="0 0 18 18"><path d="M16.98 3.484h-.48c-2.52-.058-5.04 1.161-7.44 2.903-2.46-1.8-4.74-2.903-8.04-2.903-.3 0-.54.29-.54.58v9.813c0 .29.24.523.54.581 2.76.348 4.86 1.045 7.62 2.903.24.116.54.116.72 0 2.76-1.858 4.86-2.555 7.62-2.903.3-.058.54-.29.54-.58V4.064c0-.29-.24-.523-.54-.581zm-15.3 1.22c2.34 0 4.86 1.509 6.72 2.786v8.478c-2.34-1.394-4.38-2.09-6.72-2.439V4.703zm14.58 8.767c-2.34.348-4.38 1.045-6.72 2.439V7.374C12 5.632 14.1 4.645 16.26 4.645v8.826z"/><path d="M9 .058c-1.56 0-2.76 1.22-2.76 2.671C6.24 4.181 7.5 5.4 9 5.4c1.5 0 2.76-1.22 2.76-2.671 0-1.452-1.2-2.67-2.76-2.67zm0 4.413c-.96 0-1.8-.755-1.8-1.742C7.2 1.8 7.98.987 9 .987s1.8.755 1.8 1.742c0 .93-.84 1.742-1.8 1.742z"/></symbol><symbol id="icon-error" viewBox="2.002 0 14 14"><path d="M16.002 11.949L13.951 14 9.002 9.051 4.053 14l-2.051-2.051L6.951 7 2.002 2.05 4.053 0l4.949 4.95L13.951 0l2.051 2.049L11.053 7l4.949 4.949z"/></symbol><symbol id="icon-info" viewBox="5.502 0 7 14"><path d="M8.165 5.923c.146-.384-.04-.577-.209-.577-.783 0-1.798 1.856-2.177 1.856-.15 0-.277-.147-.277-.279 0-.383.933-1.282 1.203-1.557.846-.811 1.949-1.434 3.174-1.434.908 0 1.879.555 1.125 2.63l-1.526 4.167c-.126.32-.358.854-.358 1.198 0 .148.088.298.255.298.632 0 1.796-1.818 2.091-1.818.105 0 .252.134.252.321C11.717 11.345 9.245 14 7.11 14c-.763 0-1.289-.361-1.289-1.176 0-1.027.717-2.778.865-3.145l1.479-3.756zm1.144-4.211C9.309.771 10.111 0 11.045 0c.845 0 1.457.577 1.457 1.456 0 .983-.804 1.709-1.757 1.709-.866-.001-1.436-.578-1.436-1.453z"/></symbol><symbol id="icon-success"><path d="M15.592 0c-4.867 2.984-8.4 6.751-9.987 8.641L1.717 5.595 0 6.979l6.717 6.832c1.157-2.961 4.817-8.748 9.287-12.86L15.592 0z"/></symbol><symbol id="icon-warning" viewBox="7.002 0 2.789 14"><path d="M7.002 11.211h2.789V14H7.002v-2.789zM7.002 0v3.436l.741 5.326h1.326l.723-5.326V0h-2.79z"/></symbol><symbol id="icon-facebook-bordered" viewBox="463.812 263.868 32 32"><path d="M479.812 263.868c-8.837 0-16 7.163-16 16s7.163 16 16 16 16-7.163 16-16-7.163-16-16-16zm0 30c-7.732 0-14-6.269-14-14s6.268-14 14-14 14 6.269 14 14-6.267 14-14 14z"/><path d="M483.025 280.48l.32-2.477h-2.453v-1.582c0-.715.199-1.207 1.227-1.207h1.311v-2.213a17.753 17.753 0 00-1.907-.098c-1.894 0-3.186 1.154-3.186 3.271V278h-2.142v2.477h2.142v6.354h2.557v-6.354l2.131.003z"/></symbol><symbol id="icon-twitter-bordered" viewBox="463.812 263.868 32 32"><path d="M486.416 276.191a5.622 5.622 0 01-1.554.429 2.718 2.718 0 001.19-1.502 5.456 5.456 0 01-1.72.657 2.71 2.71 0 00-1.979-.854 2.711 2.711 0 00-2.642 3.326 7.681 7.681 0 01-5.586-2.831 2.714 2.714 0 00.839 3.618 2.748 2.748 0 01-1.227-.339v.031a2.71 2.71 0 002.174 2.656 2.735 2.735 0 01-1.229.049 2.726 2.726 0 002.531 1.883 5.442 5.442 0 01-4.01 1.123 7.672 7.672 0 004.155 1.215c4.983 0 7.71-4.129 7.71-7.711 0-.115-.004-.232-.006-.351a5.41 5.41 0 001.354-1.399z"/><path d="M479.812 263.868c-8.837 0-16 7.163-16 16s7.163 16 16 16 16-7.163 16-16-7.163-16-16-16zm0 30c-7.732 0-14-6.269-14-14s6.268-14 14-14 14 6.269 14 14-6.267 14-14 14z"/></symbol><symbol id="icon-weibo-bordered" viewBox="463.812 263.868 32 32"><path d="M479.812 263.868c-8.838 0-16 7.163-16 16s7.162 16 16 16c8.837 0 16-7.163 16-16s-7.163-16-16-16zm0 30c-7.732 0-14-6.269-14-14s6.268-14 14-14c7.731 0 14 6.269 14 14s-6.267 14-14 14z"/><path d="M478.552 285.348c-2.616.261-4.876-.926-5.044-2.649-.167-1.722 1.814-3.33 4.433-3.588 2.609-.263 4.871.926 5.041 2.647.165 1.721-1.818 3.331-4.43 3.59m5.23-5.718c-.226-.065-.374-.109-.259-.403.25-.639.276-1.188.005-1.581-.515-.734-1.915-.693-3.521-.021 0 0-.508.224-.378-.181.247-.798.209-1.468-.178-1.852-.87-.878-3.194.032-5.183 2.027-1.489 1.494-2.357 3.082-2.357 4.453 0 2.619 3.354 4.213 6.631 4.213 4.297 0 7.154-2.504 7.154-4.493.001-1.198-1.007-1.881-1.914-2.162m2.855-4.797a4.176 4.176 0 00-3.982-1.291.608.608 0 00-.465.72.604.604 0 00.72.466 2.968 2.968 0 012.827.92 3 3 0 01.625 2.918.602.602 0 00.39.762.603.603 0 00.763-.391v-.001a4.218 4.218 0 00-.878-4.103"/><path d="M485.041 276.276a2.037 2.037 0 00-1.938-.63.518.518 0 00-.396.621.517.517 0 00.617.398c.336-.071.702.03.947.307s.312.649.207.979a.52.52 0 00.336.654.523.523 0 00.657-.336 2.038 2.038 0 00-.43-1.993m-6.347 5.951c-.09.156-.293.233-.451.166-.151-.062-.204-.235-.115-.389.093-.155.284-.229.44-.168.157.056.214.235.126.391m-.832 1.074c-.253.405-.795.58-1.202.396-.403-.186-.521-.655-.27-1.051.248-.39.771-.566 1.176-.393.413.17.543.636.296 1.048m.95-2.864c-1.244-.326-2.65.294-3.19 1.396-.553 1.119-.021 2.369 1.236 2.775 1.303.42 2.84-.225 3.374-1.436.526-1.183-.132-2.402-1.42-2.735"/></symbol></svg>
</div>


        

        

    <div class="u-vh-full">
        <div class="u-visually-hidden" aria-hidden="true">
    
    <?xml version="1.0" encoding="UTF-8"?><!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"><svg xmlns="http://www.w3.org/2000/svg"><symbol id="icon-alert" viewBox="0 0 18 18"><path fill-rule="evenodd" d="M4 10h2.5a.5.5 0 010 1H3.414l-1.121 1.121a1 1 0 00-.293.707V13h14v-.172a1 1 0 00-.293-.707L14 10.414V7A5 5 0 004 7zm3 4a2 2 0 104 0zm-5 0a1 1 0 01-1-1v-.172a2 2 0 01.586-1.414L3 10V7a6 6 0 1112 0v3l1.414 1.414A2 2 0 0117 12.828V13a1 1 0 01-1 1h-4a3 3 0 01-6 0z"/></symbol><symbol id="icon-arrow-left-bullet" viewBox="0 0 8 16"><path d="M3 8l5 5v3L0 8l8-8v3L3 8z"/></symbol><symbol id="icon-arrow-left"><path d="M7.002 15.002a1 1 0 102 0V3.386l2.482 2.482a.994.994 0 001.403.02 1.001 1.001 0 00.001-1.416l-.001-.001L8.71.295a1 1 0 00-1.415 0h-.001L3.118 4.472a.99.99 0 00-.016 1.4 1 1 0 001.414.003l.006-.006 2.48-2.482v11.615z"/></symbol><symbol id="icon-book" viewBox="0 0 18 18"><path fill-rule="evenodd" d="M4 13V2h1v11h11V2H3a1 1 0 00-1 1v10.268A1.99 1.99 0 013 13zm12 1H3a1 1 0 000 2h13zm0 3H3a2 2 0 01-2-2V3a2 2 0 012-2h13a1 1 0 011 1v14a1 1 0 01-1 1zM7.5 4h6a.5.5 0 110 1h-6a.5.5 0 010-1zm1 2h4a.5.5 0 110 1h-4a.5.5 0 010-1z"/></symbol><symbol id="icon-chevron-down"><path d="M8 8.586l3.293-3.293a1 1 0 011.414 1.414l-4 4a1 1 0 01-1.414 0l-4-4a1 1 0 011.414-1.414z" fill-rule="evenodd"/></symbol><symbol id="icon-chevron-right"><path d="M7.782 7L5.3 4.518a.994.994 0 01-.02-1.403 1.001 1.001 0 011.417 0l4.176 4.177a1.001 1.001 0 010 1.416l-4.176 4.177a.991.991 0 01-1.4.016 1 1 0 01.003-1.42L7.782 9l1.013-.998z" fill-rule="evenodd"/></symbol><symbol id="icon-chevron-up"><path d="M8 7.414l3.293 3.293a1 1 0 001.414-1.414l-4-4a1 1 0 00-1.414 0l-4 4a1 1 0 001.414 1.414z" fill-rule="evenodd"/></symbol><symbol id="icon-download-rounded"><path d="M0 13c0-.556.449-1 1.002-1h9.996a.999.999 0 110 2H1.002A1.006 1.006 0 010 13zM7 1v6.8l2.482-2.482c.392-.392 1.022-.4 1.403-.02a1.001 1.001 0 010 1.417l-4.177 4.177a1.001 1.001 0 01-1.416 0L1.115 6.715a.991.991 0 01-.016-1.4 1 1 0 011.42.003L5 7.8V1c0-.55.444-.996 1-.996.552 0 1 .445 1 .996z"/></symbol><symbol id="icon-download" viewBox="-301 390 9 14"><path d="M-301 395.6l4.5 5.1 4.5-5.1h-3V390h-3v5.6h-3zm0 6.5h9v1.9h-9z"/></symbol><symbol id="icon-editors" viewBox="0 0 18 18"><path fill-rule="evenodd" d="M8.726 2.546A3 3 0 105.37 7.519l.63.409v1.024l-.79.329A5.221 5.221 0 002 14.099V15H1v-.901a6.221 6.221 0 013.825-5.741 4 4 0 114.976-6.213 4.965 4.965 0 00-1.075.4zM6 17H5v-.901a6.221 6.221 0 013.825-5.741 4 4 0 114.349 0A6.221 6.221 0 0117 16.099V17h-1v-.901a5.221 5.221 0 00-3.21-4.818l-.79-.33V9.929l.63-.409a3 3 0 10-3.26 0l.63.409v1.024l-.79.329A5.221 5.221 0 006 16.099z"/></symbol><symbol id="icon-ethics"><path d="M12.182 2.272l1.038-1.038a4.014 4.014 0 015.677 0l1.038 1.038a3.21 3.21 0 002.271.941h2.684a4.014 4.014 0 014.014 4.014v2.684c0 .852.339 1.669.94 2.271l1.039 1.038a4.014 4.014 0 010 5.677l-1.038 1.038a3.211 3.211 0 00-.94 2.271v2.684a4.014 4.014 0 01-4.015 4.014h-2.684c-.852 0-1.669.339-2.27.94l-1.039 1.039a4.014 4.014 0 01-5.677 0l-1.038-1.038a3.211 3.211 0 00-2.27-.94H7.226a4.014 4.014 0 01-4.014-4.015v-2.684c0-.852-.338-1.669-.94-2.27l-1.039-1.039a4.014 4.014 0 010-5.677l1.038-1.038a3.208 3.208 0 00.941-2.27V7.226a4.014 4.014 0 014.014-4.014H9.91c.852 0 1.669-.338 2.271-.94zm1.136 1.136a4.817 4.817 0 01-3.407 1.41H7.227a2.409 2.409 0 00-2.408 2.41V9.91a4.817 4.817 0 01-1.411 3.407L2.37 14.356a2.41 2.41 0 000 3.406L3.408 18.8a4.817 4.817 0 011.41 3.406v2.684a2.409 2.409 0 002.41 2.409H9.91a4.82 4.82 0 013.407 1.41l1.038 1.038c.94.941 2.465.941 3.406 0L18.8 28.71a4.817 4.817 0 013.406-1.41h2.684a2.409 2.409 0 002.409-2.409v-2.684c0-1.278.507-2.503 1.41-3.406l1.038-1.038a2.408 2.408 0 000-3.406l-1.038-1.038A4.817 4.817 0 0127.3 9.91V7.227a2.409 2.409 0 00-2.41-2.407h-2.684A4.817 4.817 0 0118.8 3.408L17.762 2.37a2.409 2.409 0 00-3.406 0l-1.038 1.038zM15.03 17.86l4.332-4.73a.803.803 0 111.224 1.04l-4.844 5.367a.803.803 0 01-1.112.076l-3.1-2.605a.803.803 0 011.027-1.233l2.473 2.085zm1.028 7.832c-.41 0-.41-1.482 0-1.482a8.152 8.152 0 006.657-12.858.741.741 0 111.21-.857 9.634 9.634 0 01-7.867 15.197zM21.68 8.234a.741.741 0 01-.866 1.203 8.152 8.152 0 00-12.908 6.578.741.741 0 01-1.483-.007A9.635 9.635 0 0121.68 8.234zM6.907 19.077a.741.741 0 011.407-.464 8.155 8.155 0 007.745 5.598.741.741 0 110 1.482 9.637 9.637 0 01-9.152-6.616z"/></symbol><symbol id="icon-explore"><path d="M15 28.3c7.3 0 13.3-6 13.3-13.3S22.3 1.7 15 1.7 1.7 7.7 1.7 15s6 13.3 13.3 13.3zm0 1.7C6.7 30 0 23.3 0 15S6.7 0 15 0s15 6.7 15 15-6.7 15-15 15zm0-4.2c-.5 0-.8-.3-.8-.8s.3-.8.8-.8c5 0 9-4 9.2-8.8 0-.5.3-.8.8-.8s.8.3.8.8c-.1 5.8-5 10.4-10.8 10.4zm-.5-21.6c.5 0 .8.3.8.8s-.3.8-.6.8c-5 .2-8.9 4.4-8.9 9.2 0 .5-.3.8-.8.8s-.8-.3-.8-.8c0-5.8 4.5-10.5 10.3-10.8zm1.8 13.5l-2-2c-.3-.3-.3-.8 0-1.2.3-.3.8-.3 1.2 0l2 2 2.7-6.7-7.5 2.8-3 7.5 6.6-2.4zm6.9-10.9L18.7 18c-.2.5-.5.8-1 1L6.5 23.5 11 12.3c.3-.7.7-1 1.2-1.2l11-4.3z"/></symbol><symbol id="icon-ext-link" viewBox="0 0 16 16"><path fill="#676767" d="M12.9 16H3.1C1.4 16 0 14.6 0 12.9V3.2C0 1.4 1.4 0 3.1 0h3.7v1H3.1C2 1 1 2 1 3.2v9.7C1 14 2 15 3.1 15h9.7c1.2 0 2.1-1 2.1-2.1V8.7h1v4.2c.1 1.7-1.3 3.1-3 3.1z"/><path fill="#676767" d="M12.8 2.5l.7.7-9 8.9-.7-.7 9-8.9z"/><path fill="#676767" d="M9.7 0L16 6.2V0z"/></symbol><symbol id="icon-info-bordered" viewBox="470.812 270.868 18 18"><path d="M479.812 270.868c-4.972 0-9 4.029-9 9s4.028 9 9 9c4.971 0 9-4.029 9-9s-4.029-9-9-9zm0 16.875a7.875 7.875 0 01-7.875-7.875 7.875 7.875 0 1115.75 0 7.875 7.875 0 01-7.875 7.875z"/><path d="M479.284 279.586c.089-.238-.024-.361-.13-.361-.489 0-1.123 1.16-1.359 1.16-.093 0-.173-.092-.173-.174 0-.238.581-.801.751-.971.526-.506 1.217-.895 1.979-.895.567 0 1.174.346.703 1.639l-.952 2.604c-.079.199-.224.531-.224.746 0 .092.054.186.159.186.395 0 1.121-1.135 1.304-1.135.067 0 .158.086.158.199 0 .385-1.542 2.043-2.874 2.043-.477 0-.804-.225-.804-.732 0-.641.447-1.734.538-1.963l.924-2.346zm.727-3.41c0-.586.498-1.066 1.082-1.066.527 0 .91.357.91.906 0 .615-.501 1.068-1.098 1.068-.541-.002-.894-.361-.894-.908z"/></symbol><symbol id="icon-opr" viewBox="0 0 18 18"><path d="M.9 2.5c-.2-.2-.4-.3-.6-.2-.3.2-.3.4-.3.6 0 .8 0 1.7.1 2.5 0 .5.3.7.7.6.9 0 1.7-.2 2.5-.3h.2c.5-.2.6-.5.3-.8-.2-.2-.4-.4-.6-.5-.1-.1-.2-.2-.4-.3.5-.6 1-1.1 1.7-1.5 4.6-3 10.9-.5 12 4.9.9 4.4-2.2 8.6-6.7 9.2-3.7.5-7.2-1.6-8.4-5.1 0-.1-.1-.2-.1-.3-.1-.3-.5-.5-.8-.4-.3.1-.5.4-.4.8.4 1.3 1.1 2.4 2 3.4 1.4 1.5 3.1 2.4 5.1 2.8 3 .5 5.6-.2 7.8-2.2 2.1-1.9 3-4.2 3-6.9-.1-4-3.1-7.6-7.1-8.4-3.3-.9-6.2 0-8.6 2.3-.2.1-.3.3-.5.5-.3-.2-.6-.5-.9-.7z"/><path d="M13 4.7c-2.6 1.6-4.5 3.6-5.3 4.6L5.6 7.7l-.9.7L8.3 12c.6-1.6 2.6-4.6 4.9-6.8l-.2-.5z"/></symbol><symbol id="icon-remove" viewBox="-296 388 18 18"><path d="M-291.7 396.1h9v2h-9z"/><path d="M-287 405.5c-4.7 0-8.5-3.8-8.5-8.5s3.8-8.5 8.5-8.5 8.5 3.8 8.5 8.5-3.8 8.5-8.5 8.5zm0-16c-4.1 0-7.5 3.4-7.5 7.5s3.4 7.5 7.5 7.5 7.5-3.4 7.5-7.5-3.4-7.5-7.5-7.5z"/></symbol><symbol id="icon-rss"><ellipse cx="3.305" cy="20.702" rx="3.306" ry="3.298"/><path d="M15.978 24h-4.684c0-6.224-5.057-11.27-11.294-11.27V8.058c8.824 0 15.978 7.137 15.978 15.942z"/><path d="M19.2 23.95C19.2 13.366 10.604 4.79 0 4.79V0c13.255 0 24 10.723 24 23.95h-4.8z"/></symbol><symbol id="icon-search"><path d="M13.545 12.648a.641.641 0 01.006.903.646.646 0 01-.903-.006l-2.664-2.663a6.125 6.125 0 11.897-.898l2.664 2.664zm-7.42-1.273a5.25 5.25 0 100-10.5 5.25 5.25 0 000 10.5z"/></symbol><symbol id="icon-springer-arrow-left"><path d="M15 7a1 1 0 000-2H3.385l2.482-2.482a.994.994 0 00.02-1.403 1.001 1.001 0 00-1.417 0L.294 5.292a1.001 1.001 0 000 1.416l4.176 4.177a.991.991 0 001.4.016 1 1 0 00-.003-1.42L3.385 7H15z"/></symbol><symbol id="icon-springer-arrow-right"><path d="M1 7a1 1 0 010-2h11.615l-2.482-2.482a.994.994 0 01-.02-1.403 1.001 1.001 0 011.417 0l4.176 4.177a1.001 1.001 0 010 1.416l-4.176 4.177a.991.991 0 01-1.4.016 1 1 0 01.003-1.42L12.615 7H1z"/></symbol><symbol id="icon-updates" viewBox="0 0 18 18"><path d="M16.98 3.484h-.48c-2.52-.058-5.04 1.161-7.44 2.903-2.46-1.8-4.74-2.903-8.04-2.903-.3 0-.54.29-.54.58v9.813c0 .29.24.523.54.581 2.76.348 4.86 1.045 7.62 2.903.24.116.54.116.72 0 2.76-1.858 4.86-2.555 7.62-2.903.3-.058.54-.29.54-.58V4.064c0-.29-.24-.523-.54-.581zm-15.3 1.22c2.34 0 4.86 1.509 6.72 2.786v8.478c-2.34-1.394-4.38-2.09-6.72-2.439V4.703zm14.58 8.767c-2.34.348-4.38 1.045-6.72 2.439V7.374C12 5.632 14.1 4.645 16.26 4.645v8.826z"/><path d="M9 .058c-1.56 0-2.76 1.22-2.76 2.671C6.24 4.181 7.5 5.4 9 5.4c1.5 0 2.76-1.22 2.76-2.671 0-1.452-1.2-2.67-2.76-2.67zm0 4.413c-.96 0-1.8-.755-1.8-1.742C7.2 1.8 7.98.987 9 .987s1.8.755 1.8 1.742c0 .93-.84 1.742-1.8 1.742z"/></symbol><symbol id="icon-error" viewBox="2.002 0 14 14"><path d="M16.002 11.949L13.951 14 9.002 9.051 4.053 14l-2.051-2.051L6.951 7 2.002 2.05 4.053 0l4.949 4.95L13.951 0l2.051 2.049L11.053 7l4.949 4.949z"/></symbol><symbol id="icon-info" viewBox="5.502 0 7 14"><path d="M8.165 5.923c.146-.384-.04-.577-.209-.577-.783 0-1.798 1.856-2.177 1.856-.15 0-.277-.147-.277-.279 0-.383.933-1.282 1.203-1.557.846-.811 1.949-1.434 3.174-1.434.908 0 1.879.555 1.125 2.63l-1.526 4.167c-.126.32-.358.854-.358 1.198 0 .148.088.298.255.298.632 0 1.796-1.818 2.091-1.818.105 0 .252.134.252.321C11.717 11.345 9.245 14 7.11 14c-.763 0-1.289-.361-1.289-1.176 0-1.027.717-2.778.865-3.145l1.479-3.756zm1.144-4.211C9.309.771 10.111 0 11.045 0c.845 0 1.457.577 1.457 1.456 0 .983-.804 1.709-1.757 1.709-.866-.001-1.436-.578-1.436-1.453z"/></symbol><symbol id="icon-success"><path d="M15.592 0c-4.867 2.984-8.4 6.751-9.987 8.641L1.717 5.595 0 6.979l6.717 6.832c1.157-2.961 4.817-8.748 9.287-12.86L15.592 0z"/></symbol><symbol id="icon-warning" viewBox="7.002 0 2.789 14"><path d="M7.002 11.211h2.789V14H7.002v-2.789zM7.002 0v3.436l.741 5.326h1.326l.723-5.326V0h-2.79z"/></symbol><symbol id="icon-facebook-bordered" viewBox="463.812 263.868 32 32"><path d="M479.812 263.868c-8.837 0-16 7.163-16 16s7.163 16 16 16 16-7.163 16-16-7.163-16-16-16zm0 30c-7.732 0-14-6.269-14-14s6.268-14 14-14 14 6.269 14 14-6.267 14-14 14z"/><path d="M483.025 280.48l.32-2.477h-2.453v-1.582c0-.715.199-1.207 1.227-1.207h1.311v-2.213a17.753 17.753 0 00-1.907-.098c-1.894 0-3.186 1.154-3.186 3.271V278h-2.142v2.477h2.142v6.354h2.557v-6.354l2.131.003z"/></symbol><symbol id="icon-twitter-bordered" viewBox="463.812 263.868 32 32"><path d="M486.416 276.191a5.622 5.622 0 01-1.554.429 2.718 2.718 0 001.19-1.502 5.456 5.456 0 01-1.72.657 2.71 2.71 0 00-1.979-.854 2.711 2.711 0 00-2.642 3.326 7.681 7.681 0 01-5.586-2.831 2.714 2.714 0 00.839 3.618 2.748 2.748 0 01-1.227-.339v.031a2.71 2.71 0 002.174 2.656 2.735 2.735 0 01-1.229.049 2.726 2.726 0 002.531 1.883 5.442 5.442 0 01-4.01 1.123 7.672 7.672 0 004.155 1.215c4.983 0 7.71-4.129 7.71-7.711 0-.115-.004-.232-.006-.351a5.41 5.41 0 001.354-1.399z"/><path d="M479.812 263.868c-8.837 0-16 7.163-16 16s7.163 16 16 16 16-7.163 16-16-7.163-16-16-16zm0 30c-7.732 0-14-6.269-14-14s6.268-14 14-14 14 6.269 14 14-6.267 14-14 14z"/></symbol><symbol id="icon-weibo-bordered" viewBox="463.812 263.868 32 32"><path d="M479.812 263.868c-8.838 0-16 7.163-16 16s7.162 16 16 16c8.837 0 16-7.163 16-16s-7.163-16-16-16zm0 30c-7.732 0-14-6.269-14-14s6.268-14 14-14c7.731 0 14 6.269 14 14s-6.267 14-14 14z"/><path d="M478.552 285.348c-2.616.261-4.876-.926-5.044-2.649-.167-1.722 1.814-3.33 4.433-3.588 2.609-.263 4.871.926 5.041 2.647.165 1.721-1.818 3.331-4.43 3.59m5.23-5.718c-.226-.065-.374-.109-.259-.403.25-.639.276-1.188.005-1.581-.515-.734-1.915-.693-3.521-.021 0 0-.508.224-.378-.181.247-.798.209-1.468-.178-1.852-.87-.878-3.194.032-5.183 2.027-1.489 1.494-2.357 3.082-2.357 4.453 0 2.619 3.354 4.213 6.631 4.213 4.297 0 7.154-2.504 7.154-4.493.001-1.198-1.007-1.881-1.914-2.162m2.855-4.797a4.176 4.176 0 00-3.982-1.291.608.608 0 00-.465.72.604.604 0 00.72.466 2.968 2.968 0 012.827.92 3 3 0 01.625 2.918.602.602 0 00.39.762.603.603 0 00.763-.391v-.001a4.218 4.218 0 00-.878-4.103"/><path d="M485.041 276.276a2.037 2.037 0 00-1.938-.63.518.518 0 00-.396.621.517.517 0 00.617.398c.336-.071.702.03.947.307s.312.649.207.979a.52.52 0 00.336.654.523.523 0 00.657-.336 2.038 2.038 0 00-.43-1.993m-6.347 5.951c-.09.156-.293.233-.451.166-.151-.062-.204-.235-.115-.389.093-.155.284-.229.44-.168.157.056.214.235.126.391m-.832 1.074c-.253.405-.795.58-1.202.396-.403-.186-.521-.655-.27-1.051.248-.39.771-.566 1.176-.393.413.17.543.636.296 1.048m.95-2.864c-1.244-.326-2.65.294-3.19 1.396-.553 1.119-.021 2.369 1.236 2.775 1.303.42 2.84-.225 3.374-1.436.526-1.183-.132-2.402-1.42-2.735"/></symbol></svg>
</div>

        <a class="u-visually-hidden u-visually-hidden-focus" href="#main-content">
    <span class="c-banner">Skip to main content</span>
</a>

        
            
    <div class="adsbox c-ad c-ad--LB1">
        <div class="c-ad__inner" >
            <p class="c-ad__label">Advertisement</p>
            <div id="div-gpt-ad-LB1"
                 data-gpt-unitpath="/270604982/bmc/bmcbioinformatics/articles"
                 data-gpt-sizes="728x90,970x90"
                 data-gpt-targeting="pos=LB1;doi=10.1186/1471-2105-8-25;kwrd=Variable Selection,Random Forest,Bootstrap Sampling,Variable Importance,Importance Measure;pmc=L15001,B12050,I23050,L17004,M14018,M14018;"
                 data-ad-type="LB1">
                <noscript>
                    <a href="//pubads.g.doubleclick.net/gampad/jump?iu=/270604982/bmc/bmcbioinformatics/articles&amp;sz=728x90,970x90&amp;pos=LB1&amp;doi=10.1186/1471-2105-8-25&amp;kwrd=Variable Selection,Random Forest,Bootstrap Sampling,Variable Importance,Importance Measure&amp;pmc=L15001,B12050,I23050,L17004,M14018,M14018&amp;">
                        <img data-test="gpt-advert-fallback-img"
                             src="//pubads.g.doubleclick.net/gampad/ad?iu=/270604982/bmc/bmcbioinformatics/articles&amp;sz=728x90,970x90&amp;pos=LB1&amp;doi=10.1186/1471-2105-8-25&amp;kwrd=Variable Selection,Random Forest,Bootstrap Sampling,Variable Importance,Importance Measure&amp;pmc=L15001,B12050,I23050,L17004,M14018,M14018&amp;"
                             alt="Advertisement"
                             width="728"
                             height="90">
                    </a>
                </noscript>
            </div>
        </div>
    </div>

        
         
    
        <div id="membership-message-loader-desktop" class="placeholder" data-placeholder="/placeholder/v1/membership/message"></div>
    
    
        <div id="top" class="c-popup-search">
    <header class="c-header" data-test="publisher-header">
        <div class="c-header__container">
            <div class="c-header__brand u-margin-right-xxl" itemscope itemtype="http://schema.org/Organization" data-test="navbar-logo-header">
                <div class="c-logo">
    <a href="https://www.biomedcentral.com" itemprop="url">
        <img alt="BMC" itemprop="logo" width="76" height="18" role="img" src=/static/images/bmc/logos/logo-bmc-white-series-589b048892.svg>
        <div class="c-logo__strapline">
            <img alt="Part of Springer Nature" width="173" height="16" role="img" src=/static/images/bmc/logos/logo-bmc-white-strapline-sn-7ea0ab832c.svg>
        </div>
    </a>
</div>

            </div>
            <div class="c-header__navigation">
                <button
                    type="button"
                    class="c-header__link u-button-reset js-publisher-search-button u-margin-right-lg"
                    data-toggle="collapse"
                    data-test="header-search-button"
                    data-target="publisher-header-search"
                    aria-controls="publisher-header-search"
                    aria-expanded="false">
                    <span class="u-display-flex u-flex-align-center">
                        Search
                        <svg class="c-icon u-margin-left-xs" width="14" height="14" aria-hidden="true" focusable="false">
                            <use xlink:href="#icon-search"></use>
                        </svg>
                    </span>
                </button>
                <nav>
                    <ul class="c-header__menu" data-header-menu data-test="publisher-navigation">
                        
                            
                                <li class="c-header__item">
                                    <a class="c-header__link"
                                       href="//www.biomedcentral.com/journals">
                                        Explore journals
                                    </a>
                                </li>
                            
                                <li class="c-header__item">
                                    <a class="c-header__link"
                                       href="//www.biomedcentral.com/getpublished">
                                        Get published
                                    </a>
                                </li>
                            
                                <li class="c-header__item">
                                    <a class="c-header__link"
                                       href="//www.biomedcentral.com/about">
                                        About BMC
                                    </a>
                                </li>
                            
                        
                        <li class="c-header__item">
                            <a data-header-account
                               class="c-header__link"
                               href="https://www.biomedcentral.com/account"
                               data-test="login-link">
                                My Account
                            </a>
                        </li>
                    </ul>
                </nav>
            </div>
        </div>
    </header>
    <div class="c-popup-search__content c-collapse js-publisher-search-bar" id="publisher-header-search">
        <div class="u-container">
            <div class="c-popup-search__container">
                <div class="ctx-search">
    <form role="search" class="c-form-field" method="GET" action="//www.biomedcentral.com/search" data-track="submit"
        data-track-category="Search and Results" data-track-action="Submit search" data-dynamic-track-label data-track-label="" data-test="global-search">
        <label for="publisherSearch" class="c-form-field__label">Search all BMC articles</label>
        <div class="u-display-flex">
            <input id="publisherSearch" class="c-form-field__input js-publisher-search-input" autocomplete="off" role="textbox" data-test="search-input" name="query" type="text" value=""/>
            <div>
                <button class="c-button" type="submit" data-test="search-submit-button">
    <span class="u-visually-hidden">Search</span>
    <svg class="c-icon" width="16" height="16" aria-hidden="true" focusable="false">
        <use xlink:href="#icon-search"></use>
    </svg>
</button>


            </div>
        </div>
        <input type="hidden" name="searchType" value="publisherSearch"/>
    </form>
</div>

            </div>
        </div>
    </div>
</div>

    

        
            <header class="c-journal-header c-journal-header--bmc-bioinformatics ctx-journal-header">
                <div class="u-container">
                    <div class="c-journal-header__inner ">
                        
                        <div class="c-journal-title" id="journalTitle">
                            <a href="/">
    
        
    
    <span class="c-journal-title__text ">BMC Bioinformatics</span>
    
</a>
                        </div>
                        
                    </div>
                </div>
                <div class="c-navbar">
                    <div class="c-navbar__container">
                        
                            <div class="c-navbar__content">
                                <nav class="c-navbar__nav">
                                    <ul class="c-navbar__nav c-navbar__nav--journal" role="menu" data-test="site-navigation">
                                        
                                            <li class="c-navbar__item" role="menuitem">
                                                <a class="c-navbar__link" data-track="click" data-track-category="Home" data-track-action="Clicked journal navigation link" href='/'>Home</a>
                                            </li>
                                        
                                            <li class="c-navbar__item" role="menuitem">
                                                <a class="c-navbar__link" data-track="click" data-track-category="About" data-track-action="Clicked journal navigation link" href='/about'>About</a>
                                            </li>
                                        
                                            <li class="c-navbar__item" role="menuitem">
                                                <a class="c-navbar__link c-navbar__link--is-shown" data-track="click" data-track-category="Articles" data-track-action="Clicked journal navigation link" href='/articles'>Articles</a>
                                            </li>
                                        
                                            <li class="c-navbar__item" role="menuitem">
                                                <a class="c-navbar__link" data-track="click" data-track-category="In Review" data-track-action="Clicked journal navigation link" href='https://bmcbioinformatics.biomedcentral.com/in-review'>In Review</a>
                                            </li>
                                        
                                            <li class="c-navbar__item" role="menuitem">
                                                <a class="c-navbar__link" data-track="click" data-track-category="Submission Guidelines" data-track-action="Clicked journal navigation link" href='/submission-guidelines'>Submission Guidelines</a>
                                            </li>
                                        
                                    </ul>
                                </nav>
                            </div>
                        
                    </div>
                </div>
                <div class="c-journal-header__identity c-journal-header__identity--default">
                    
                </div>
            </header>
            
        

        <div class="u-container u-margin-top-xl u-margin-bottom-xl c-article-container" id="main-content" data-component="article-container">
            <div class="c-page-layout c-page-layout--article" data-component="sticky-container">

                <main class="c-page-layout__main">
                    <article itemscope itemtype="http://schema.org/ScholarlyArticle" lang="en">
                        <div class="c-article-header">
                            

                            <ul class="c-article-identifiers" data-test="article-identifier">
                                
    <li class="c-article-identifiers__item" data-test="article-category">Methodology article</li>
    
        
            <li class="c-article-identifiers__item">
                <span class="c-article-identifiers__open" data-test="open-access">Open Access</span>
            </li>
        
        
    
    

                                <li class="c-article-identifiers__item"><a href="#article-info" data-track="click" data-track-action="publication date" data-track-category="article body" data-track-label="link">Published: <time datetime="2007-01-25" itemprop="datePublished">25 January 2007</time></a></li>
                            </ul>

                            <h1 class="c-article-title u-h1" data-test="article-title" data-article-title="" itemprop="name headline">Bias in random forest variable importance measures: Illustrations, sources and a solution</h1>
                            <ul class="c-author-list js-list-authors js-etal-collapsed" data-etal="25" data-etal-small="3" data-test="authors-list"><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-category="article body" data-track-label="link" href="#auth-1" data-corresp-id="c1">Carolin Strobl<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-email"></use></svg></a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Ludwig-Maximilians-Universitt Mnchen" /><meta itemprop="address" content="grid.5252.0, 000000041936973X, Institut fr Statistik, Ludwig-Maximilians-Universitt Mnchen, Ludwigstr. 33, 80539, Mnchen, Germany" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-category="article body" data-track-label="link" href="#auth-2">Anne-Laure Boulesteix</a></span><sup class="u-js-hide"><a href="#Aff2">2</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Technische Universitt Mnchen" /><meta itemprop="address" content="grid.6936.a, 0000000123222966, Institut fr medizinische Statistik und Epidemiologie, Technische Universitt Mnchen, Ismaningerstr. 22, 81675, Mnchen, Germany" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-category="article body" data-track-label="link" href="#auth-3">Achim Zeileis</a></span><sup class="u-js-hide"><a href="#Aff3">3</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Wirtschaftsuniversitt Wien" /><meta itemprop="address" content="grid.15788.33, 0000000111774763, Department fr Statistik und Mathematik, Wirtschaftsuniversitt Wien, Augasse 2-6, 1090, Wien, Austria" /></span></sup> &amp; </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-category="article body" data-track-label="link" href="#auth-4">Torsten Hothorn</a></span><sup class="u-js-hide"><a href="#Aff4">4</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Friedrich-Alexander-Universtitt Erlangen-Nrnberg" /><meta itemprop="address" content="grid.5330.5, 0000000121073311, Institut fr Medizininformatik, Biometrie und Epidemiologie, Friedrich-Alexander-Universtitt Erlangen-Nrnberg, Waldstr. 6, D-91054, Erlangen, Germany" /></span></sup></li></ul>
                            <p class="c-article-info-details" data-container-section="info">
                                
    <a data-test="journal-link" href="/"><i data-test="journal-title">BMC Bioinformatics</i></a>

                                <b data-test="journal-volume"><span class="u-visually-hidden">volume</span>8</b>, Articlenumber:<span data-test="article-number">25</span> (<span data-test="article-publication-year">2007</span>)
            <a href="#citeas" class="c-article-info-details__cite-as u-hide-print" data-track="click" data-track-action="cite this article" data-track-category="article body" data-track-label="link">Cite this article</a>
                            </p>
                            
    
        <div class="c-article-metrics-bar__wrapper u-clear-both">
            <ul class="c-article-metrics-bar u-list-inline">
                
                    <li class=" c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">90k <span class="c-article-metrics-bar__label">Accesses</span></p>
                    </li>
                
                
                    <li class="c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">926 <span class="c-article-metrics-bar__label">Citations</span></p>
                    </li>
                
                
                    
                        <li class="c-article-metrics-bar__item">
                            <p class="c-article-metrics-bar__count">19 <span class="c-article-metrics-bar__label">Altmetric</span></p>
                        </li>
                    
                    
                        <li class="c-article-metrics-bar__item">
                            <p class="c-article-metrics-bar__details"><a href="/articles/10.1186/1471-2105-8-25/metrics" data-track="click" data-track-action="view metrics" data-track-category="article body" data-track-label="link" rel="nofollow">Metrics <span class="u-visually-hidden">details</span></a></p>
                        </li>
                    
                
            </ul>
        </div>
    

                            

                            
                        </div>

                        <section aria-labelledby="Abs1" lang="en"><div class="c-article-section" id="Abs1-section"><h2 class="c-article-section__title u-h2 js-section-title js-c-reading-companion-sections-item" id="Abs1">Abstract</h2><div class="c-article-section__content" id="Abs1-content"><h3 class="c-article__sub-heading u-h3" data-test="abstract-sub-heading">Background</h3><p>Variable importance measures for random forests have been receiving increased attention as a means of variable selection in many classification tasks in bioinformatics and related scientific fields, for instance to select a subset of genetic markers relevant for the prediction of a certain disease. We show that random forest variable importance measures are a sensible means for variable selection in many applications, but are not reliable in situations where potential predictor variables vary in their scale of measurement or their number of categories. This is particularly important in genomics and computational biology, where predictors often include variables of different types, for example when predictors include both sequence data and continuous variables such as folding energy, or when amino acid sequence data show different numbers of categories.</p><h3 class="c-article__sub-heading u-h3" data-test="abstract-sub-heading">Results</h3><p>Simulation studies are presented illustrating that, when random forest variable importance measures are used with data of varying types, the results are misleading because suboptimal predictor variables may be artificially preferred in variable selection. The two mechanisms underlying this deficiency are biased variable selection in the individual classification trees used to build the random forest on one hand, and effects induced by bootstrap sampling with replacement on the other hand.</p><h3 class="c-article__sub-heading u-h3" data-test="abstract-sub-heading">Conclusion</h3><p>We propose to employ an alternative implementation of random forests, that provides unbiased variable selection in the individual classification trees. When this method is applied using subsampling without replacement, the resulting variable importance measures can be used reliably for variable selection even in situations where the potential predictor variables vary in their scale of measurement or their number of categories. The usage of both random forest algorithms and their variable importance measures in the R system for statistical computing is illustrated and documented thoroughly in an application re-analyzing data from a study on RNA editing. Therefore the suggested method can be applied straightforwardly by scientists in bioinformatics research.</p></div></div></section>
                        
    


                        <section aria-labelledby="Sec1"><div class="c-article-section" id="Sec1-section"><h2 class="c-article-section__title u-h2 js-section-title js-c-reading-companion-sections-item" id="Sec1">Background</h2><div class="c-article-section__content" id="Sec1-content"><p>In bioinformatics and related scientific fields, such as statistical genomics and genetic epidemiology, an important task is the prediction of a categorical response variable (such as the disease status of a patient or the properties of a molecule) based on a large number of predictors. The aim of this research is on one hand to predict the value of the response variable from the values of the predictors, i.e. to create a diagnostic tool, and on the other hand to reliably identify relevant predictors from a large set of candidate variables. From a statistical point of view, one of the challenges in identifying these relevant predictor variables is the so-called "small <i>n</i> large <i>p</i>" problem: Usual data sets in genomics often contain hundreds or thousands of genes or markers that serve as predictor variables <i>X</i><sub>1</sub>,..., <i>X</i><sub>
                  <i>p</i>
                </sub>, but only for a comparatively small number <i>n</i> of subjects or tissue types.</p><p>Traditional statistical models used in clinical case control studies for predicting the disease status from selected predictor variables, such as logistic regression, are not suitable for "small <i>n</i> large <i>p</i>" problems [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1" title="Bureau A, Dupuis J, Falls K, Lunetta KL, Hayward B, Keith TP, Eerdewegh PV: Identifying SNPs Predictive of Phenotype Using Random Forests. Genetic Epidemiology 2005, 28: 171182. 10.1002/gepi.20041" href="/articles/10.1186/1471-2105-8-25#ref-CR1" id="ref-link-section-d19935e477">1</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2" title="Heidema AG, Boer JMA, Nagelkerke N, Mariman ECM, van der A DL, Feskens EJM: The Challenge for Genetic Epidemiologists: How to Analyze Large Numbers of SNPs in Relation to Complex Diseases. BMC Genetics 2006, 7: 23. 10.1186/1471-2156-7-23" href="/articles/10.1186/1471-2105-8-25#ref-CR2" id="ref-link-section-d19935e480">2</a>]. A more appropriate approach from machine learning, that has been proposed recently for prediction and variable selection in various fields related to bioinformatics and computational biology, is the nonlinear and nonparametric random forest method [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 3" title="Breiman L: Random Forests. Machine Learning 2001, 45: 532. 10.1023/A:1010933404324" href="/articles/10.1186/1471-2105-8-25#ref-CR3" id="ref-link-section-d19935e483">3</a>]. It also provides variable importance measures for variable selection purposes.</p><p>Random forests have been successfully applied to various problems in, e.g., genetic epidemiology and microbiology in general within the last five years. Within a very short period of time, random forests have become a major data analysis tool, that performs well in comparison with many standard methods [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2" title="Heidema AG, Boer JMA, Nagelkerke N, Mariman ECM, van der A DL, Feskens EJM: The Challenge for Genetic Epidemiologists: How to Analyze Large Numbers of SNPs in Relation to Complex Diseases. BMC Genetics 2006, 7: 23. 10.1186/1471-2156-7-23" href="/articles/10.1186/1471-2105-8-25#ref-CR2" id="ref-link-section-d19935e489">2</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 4" title="Daz-Uriarte R, Alvarez de Andrs S: Gene Selection and Classification of Microarray Data Using Random Forest. BMC Bioinformatics 2006, 7: 3. 10.1186/1471-2105-7-3" href="/articles/10.1186/1471-2105-8-25#ref-CR4" id="ref-link-section-d19935e492">4</a>]. What has greatly contributed to the popularity of random forests is the fact that they can be applied to a wide range of prediction problems, even if they are nonlinear and involve complex high-order interaction effects, and that random forests produce variable importance measures for each predictor variable.</p><p>Applications of random forests in bioinformatics include large-scale association studies for complex genetic diseases, as e.g. Lunetta et al. [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 5" title="Lunetta KL, Hayward LB, Segal J, Eerdewegh PV: Screening Large-Scale Association Study Data: Exploiting Interactions Using Random Forests. BMC Genetics 2004, 5: 32. 10.1186/1471-2156-5-32" href="/articles/10.1186/1471-2105-8-25#ref-CR5" id="ref-link-section-d19935e498">5</a>] and Bureau et al. [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1" title="Bureau A, Dupuis J, Falls K, Lunetta KL, Hayward B, Keith TP, Eerdewegh PV: Identifying SNPs Predictive of Phenotype Using Random Forests. Genetic Epidemiology 2005, 28: 171182. 10.1002/gepi.20041" href="/articles/10.1186/1471-2105-8-25#ref-CR1" id="ref-link-section-d19935e501">1</a>], who detect SNP-SNP interactions in the case-control context by means of computing a random forest variable importance measure for each polymorphism. A comparison of the performance of random forests and other classification methods for the analysis of gene expression data is presented by Daz-Uriate and Alvarez de Andrs [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 4" title="Daz-Uriarte R, Alvarez de Andrs S: Gene Selection and Classification of Microarray Data Using Random Forest. BMC Bioinformatics 2006, 7: 3. 10.1186/1471-2105-7-3" href="/articles/10.1186/1471-2105-8-25#ref-CR4" id="ref-link-section-d19935e504">4</a>], who propose a new gene selection method based on random forests for sample classification with microarray data. We refer to [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 6" title="Gunther EC, Stone DJ, Gerwien RW, Bento P, Heyes MP: Prediction of Clinical Drug Efficacy by Classification of Drug-induced Genomic Expression Profiles in vitro . Proceedings of the National Academy of Sciences 2003, 100: 96089613. 10.1073/pnas.1632587100" href="/articles/10.1186/1471-2105-8-25#ref-CR6" id="ref-link-section-d19935e507">6</a><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 8" title="Shih Y: Tumor Classification by Tissue Microarray Profiling: Random Forest Clustering Applied to Renal Cell Carcinoma. Modern Pathology 2005, 18: 547557. 10.1038/modpathol.3800322" href="/articles/10.1186/1471-2105-8-25#ref-CR8" id="ref-link-section-d19935e510">8</a>] for other applications of the random forest methodology to microarray data.</p><p>Prediction of phenotypes based on amino acid or DNA sequence is another important area of application of random forests, since possibly involving many interactions. For example, Segal et al. [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 9" title="Segal MR, Barbour JD, Grant RM: Relating HIV-1 Sequence Variation to Replication Capacity via Trees and Forests. Statistical Applications in Genetics and Molecular Biology 2004, 3: 2." href="/articles/10.1186/1471-2105-8-25#ref-CR9" id="ref-link-section-d19935e517">9</a>] use random forests to predict the replication capacity of viruses, such as HIV-1, based on amino acid sequence from reverse transcriptase and protease. Cummings and Segal [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 10" title="Cummings MP, Segal MR: Few Amino Acid Positions in rpoB are Associated with Most of the Rifampin Resistance in Mycobacterium Tuberculosis. BMC Bioinformatics 2004, 5: 137. 10.1186/1471-2105-5-137" href="/articles/10.1186/1471-2105-8-25#ref-CR10" id="ref-link-section-d19935e520">10</a>] link the rifampin resistance in <i>Mycobacterium tuberculosis</i> to a few amino acid positions in rpoB, whereas Cummings and Myers [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 11" title="Cummings MP, Myers DS: Simple Statistical Models Predict C-to-U Edited Sites in Plant Mitochondrial RNA. BMC Bioinformatics 2004, 5: 132. 10.1186/1471-2105-5-132" href="/articles/10.1186/1471-2105-8-25#ref-CR11" id="ref-link-section-d19935e526">11</a>] predict C-to-U edited sites in plant mitochondrial RNA based on sequence regions flanking edited sites and a few other (continuous) parameters.</p><p>The random forest approach was shown to outperform six other methods in the prediction of protein interactions based on various biological features such as gene expression, gene ontology (GO) features and sequence data [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Qi Y, Bar-Joseph Z, Klein-Seetharaman J: Evaluation of Different Biological Data and Computational Classification Methods for Use in Protein Interaction Prediction. Proteins 2006, 63: 490500. 10.1002/prot.20865" href="/articles/10.1186/1471-2105-8-25#ref-CR12" id="ref-link-section-d19935e532">12</a>]. Other applications of random forests can be found in fields as different as quantitative structure-activity relationship (QSAR) modeling [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 13" title="Guha R, Jurs PC: Development of Linear, Ensemble, and Nonlinear Models for the Prediction and Interpretation of the Biological Activity of a Set of PDGFR Inhibitors. Journal of Chemical Information and Computer Sciences 2003, 44: 21792189. 10.1021/ci049849f" href="/articles/10.1186/1471-2105-8-25#ref-CR13" id="ref-link-section-d19935e535">13</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 14" title="Svetnik V, Liaw A, Tong C, Culberson JC, Sheridan RP, Feuston BP: Random Forest: A Classification and Regression Tool for Compound Classification and QSAR Modeling. Journal of Chemical Information and Computer Sciences 2003, 43: 19471958. 10.1021/ci034160g" href="/articles/10.1186/1471-2105-8-25#ref-CR14" id="ref-link-section-d19935e538">14</a>], nuclear magnetic resonance spectroscopy [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 15" title="Arun K, Langmead CJ: Structure Based Chemical Shift Prediction Using Random Forests Non-linear Regression. In Proceedings of the Fourth Asia-Pacific Bioinformatics Conference, Taipei, Taiwan Edited by: Jiang T, Yang UC, Chen YPP, Wong L. 2006, 317326." href="/articles/10.1186/1471-2105-8-25#ref-CR15" id="ref-link-section-d19935e541">15</a>], landscape epidemiology [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 16" title="Furlanello C, Neteler M, Merler S, Menegon S, Fontanari S, Donini D, Rizzoli A, Chemini C: GIS and the Random Forest Predictor: Integration in R for Tick-Borne Disease Risk Assessment.In Proceedings of the 3rd International Workshop on Distributed Statistical Computing, Vienna, Austria Edited by: Hornik K, Leisch F, Zeileis A. 2003. [&#xA;                    http://www.ci.tuwien.ac.at/Conferences/DSC-2003/Proceedings/&#xA;                    &#xA;                  ]" href="/articles/10.1186/1471-2105-8-25#ref-CR16" id="ref-link-section-d19935e544">16</a>] and medicine in general [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 17" title="Ward MM, Pajevic S, Dreyfuss J, Malley JD: Short-Term Prediction of Mortality in Patients with Systemic Lupus Erythematosus: Classification of Outcomes Using Random Forests. Arthritis and Rheumatism 2006, 55: 7480. 10.1002/art.21695" href="/articles/10.1186/1471-2105-8-25#ref-CR17" id="ref-link-section-d19935e548">17</a>].</p><p>The scope of this paper is to show that the variable importance measures of Breiman's original random forest method [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 3" title="Breiman L: Random Forests. Machine Learning 2001, 45: 532. 10.1023/A:1010933404324" href="/articles/10.1186/1471-2105-8-25#ref-CR3" id="ref-link-section-d19935e554">3</a>], based on CART classification trees [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 18" title="Breiman L, Friedman JH, Olshen RA, Stone CJ: Classification and Regression Trees. New York: Chapman and Hall; 1984." href="/articles/10.1186/1471-2105-8-25#ref-CR18" id="ref-link-section-d19935e557">18</a>], are a sensible means for variable selection in many of these applications, but are not reliable in situations where potential predictor variables vary in their scale of measurement or their number of categories, as, e.g., when both genetic and environmental variables, individually and in interactions, are considered as potential predictors, or predictor variables of the same type vary in the number of categories present in a certain sample, as is often the case in genomics, bioinformatics and related disciplines.</p><p>Simulation studies are presented illustrating that variable selection with the variable importance measure of the original random forest method bears the risk that suboptimal predictor variables are artificially preferred in such scenarios.</p><p>In an extra section, further details and explanations of the statistical sources underlying the deficiency of the variable importance measures of the original random forest method, namely biased variable selection in the individual classification trees used to build the random forest and effects induced by bootstrap sampling with replacement, are given.</p><p>We propose to employ an alternative random forest method, the variable importance measure of which can be employed to reliably select relevant predictor variables in any data set. The performance of this method is compared to that of the original random forest method in simulation studies, and is illustrated by an application to the prediction of C-to-U edited sites in plant mitochondrial RNA, re-analyzing the data of [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 11" title="Cummings MP, Myers DS: Simple Statistical Models Predict C-to-U Edited Sites in Plant Mitochondrial RNA. BMC Bioinformatics 2004, 5: 132. 10.1186/1471-2105-5-132" href="/articles/10.1186/1471-2105-8-25#ref-CR11" id="ref-link-section-d19935e567">11</a>] that were previously analyzed with the original random forest method.</p></div></div></section><section aria-labelledby="Sec2"><div class="c-article-section" id="Sec2-section"><h2 class="c-article-section__title u-h2 js-section-title js-c-reading-companion-sections-item" id="Sec2">Methods</h2><div class="c-article-section__content" id="Sec2-content"><p>Here we focus on the use of random forests for classification tasks, rather than regression tasks, for instance for predicting the disease status from a set of selected genetic and environmental risk factors, or for predicting whether a site of interest is edited by means of neighboring sites and other predictor variables as in our application example.</p><p>Random forests are an ensemble method that combines several individual classification trees in the following way: From the original sample several bootstrap samples are drawn, and an unpruned classification tree is fit to each bootstrap sample. The variable selection for each split in the classification tree is conducted only from a small random subset of predictor variables, so that the "small <i>n</i> large <i>p</i>" problem is avoided. From the complete forest the status of the response variable is predicted as an average or majority vote of the predictions of all trees.</p><p>Random forests can highly increase the prediction accuracy as compared to individual classification trees, because the ensemble adjusts for the instability of the individual trees induced by small changes in the learning sample, that impairs the prediction accuracy in test samples. However, the interpretability of a random forest is not as straightforward as that of an individual classification tree, where the influence of a predictor variable directly corresponds to its position in the tree. Thus, alternative measures for variable importance are required for the interpretation of random forests.</p><h3 class="c-article__sub-heading u-h3" id="Sec3">Random forest variable importance measures</h3><p>A naive variable importance measure to use in tree-based ensemble methods is to merely count the number of times each variable is selected by all individual trees in the ensemble.</p><p>More elaborate variable importance measures incorporate a (weighted) mean of the individual trees' improvement in the splitting criterion produced by each variable [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 19" title="Friedman J: Greedy Function Approximation: A Gradient Boosting Machine. The Annals of Statistics 2001, 29: 11891232. 10.1214/aos/1013203451" href="/articles/10.1186/1471-2105-8-25#ref-CR19" id="ref-link-section-d19935e597">19</a>]. An example for such a measure in classification is the "Gini importance" available in random forest implementations. The "Gini importance" describes the improvement in the "Gini gain" splitting criterion.</p><p>The most advanced variable importance measure available in random forests is the "permutation accuracy importance" measure. Its rationale is the following: By randomly permuting the predictor variable <i>X</i><sub>
                    <i>j</i>
                  </sub>, its original association with the response <i>Y</i> is broken. When the permuted variable <i>X</i><sub>
                    <i>j</i>
                  </sub>, together with the remaining unpermuted predictor variables, is used to predict the response, the prediction accuracy (i.e. the number of observations classified correctly) decreases substantially, if the original variable <i>X</i><sub>
                    <i>j</i>
                  </sub>was associated with the response. Thus, a reasonable measure for variable importance is the difference in prediction accuracy before and after permuting <i>X</i><sub>
                    <i>j</i>
                  </sub>.</p><p>For variable selection purposes the advantage of the random forest permutation accuracy importance measure as compared to univariate screening methods is that it covers the impact of each predictor variable individually as well as in multivariate interactions with other predictor variables. For example, Lunetta et al. [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 5" title="Lunetta KL, Hayward LB, Segal J, Eerdewegh PV: Screening Large-Scale Association Study Data: Exploiting Interactions Using Random Forests. BMC Genetics 2004, 5: 32. 10.1186/1471-2156-5-32" href="/articles/10.1186/1471-2105-8-25#ref-CR5" id="ref-link-section-d19935e642">5</a>] find that genetic markers relevant in interactions with other markers or environmental variables can be detected more efficiently by means of random forests than by means of univariate screening methods like Fisher's exact test.</p><p>The Gini importance and the permutation accuracy importance measures are employed as variable selection criteria in many recent studies in various disciplines related to bioinformatics, as outlined in the background section. Therefore we want to investigate their reliability as variable importance measures in different scenarios.</p><p>In the simulation studies presented in the next section, we compare the behavior of all three random forest variable importance measures, namely the number of times each variable is selected by all individual trees in the ensemble (termed "selection frequency" in the following), the "Gini importance" and the permutation accuracy importance measure (termed "permutation importance" in the following).</p><h3 class="c-article__sub-heading u-h3" id="Sec4">Simulation studies</h3><p>The reference implementation of Breiman's original random forest method [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 3" title="Breiman L: Random Forests. Machine Learning 2001, 45: 532. 10.1023/A:1010933404324" href="/articles/10.1186/1471-2105-8-25#ref-CR3" id="ref-link-section-d19935e659">3</a>] is available in the R system for statistical computing [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 20" title="R Development Core Team:R: A Language and Environment for Statistical Computing. R Foundation for Statistical Computing, Vienna, Austria; 2006. [&#xA;                    http://www.R-project.org/&#xA;                    &#xA;                  ]" href="/articles/10.1186/1471-2105-8-25#ref-CR20" id="ref-link-section-d19935e662">20</a>] via the randomForest add-on package by Liaw and Wiener [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 21" title="Breiman L, Cutler A, Liaw A, Wiener M:Breiman and Cutler's Random Forests for Classification and Regression. 2006. [R package version 4.516]. [&#xA;                    http://CRAN.R-project.org/&#xA;                    &#xA;                  ] [R package version 4.516]." href="/articles/10.1186/1471-2105-8-25#ref-CR21" id="ref-link-section-d19935e665">21</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 22" title="Liaw A, Wiener M: Classification and Regression by randomForest. R News 2002, 2: 1822. [&#xA;                    http://CRAN.R-project.org/doc/Rnews/&#xA;                    &#xA;                  ]" href="/articles/10.1186/1471-2105-8-25#ref-CR22" id="ref-link-section-d19935e668">22</a>]. The behavior of the selection frequency, the Gini importance and the permutation importance of the randomForest function is explored in a simulation design where potential predictor variables vary in their scale of measurement and number of categories.</p><p>As an alternative, we propose to use the new random forest function cforest available in the R add-on package party [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 23" title="Hothorn T, Hornik K, Zeileis A:party: A Laboratory for Recursive Part(y)itioning. 2006. [R package version 0.90]. [&#xA;                    http://CRAN.R-project.org/&#xA;                    &#xA;                  ] [R package version 0.9-0]." href="/articles/10.1186/1471-2105-8-25#ref-CR23" id="ref-link-section-d19935e674">23</a>] in such scenarios. In contrast to randomForest, the cforest function creates random forests not from CART classification trees based on the Gini split criterion [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 18" title="Breiman L, Friedman JH, Olshen RA, Stone CJ: Classification and Regression Trees. New York: Chapman and Hall; 1984." href="/articles/10.1186/1471-2105-8-25#ref-CR18" id="ref-link-section-d19935e677">18</a>], that are known to prefer variables with, e.g., more categories in variable selection [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 18" title="Breiman L, Friedman JH, Olshen RA, Stone CJ: Classification and Regression Trees. New York: Chapman and Hall; 1984." href="/articles/10.1186/1471-2105-8-25#ref-CR18" id="ref-link-section-d19935e680">18</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 24" title="Kononenko I: On Biases in Estimating Multi-Valued Attributes. In Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence, Montral, Canada Edited by: Mellish C. 1995, 10341040." href="/articles/10.1186/1471-2105-8-25#ref-CR24" id="ref-link-section-d19935e683">24</a><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 28" title="Strobl C, Boulesteix AL, Augustin T: Unbiased Split Selection for Classification Trees Based on the Gini Index. Computational Statistics &amp; Data Analysis 2006. [&#xA;                    http://dx.doi.org/10.1016/j.csda.2006.12.030&#xA;                    &#xA;                  ]" href="/articles/10.1186/1471-2105-8-25#ref-CR28" id="ref-link-section-d19935e686">28</a>], but from unbiased classification trees based on a conditional inference framework [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 29" title="Hothorn T, Hornik K, Zeileis A: Unbiased Recursive Partitioning: A Conditional Inference Framework. Journal of Computational and Graphical Statistics 2006, 15: 651674. 10.1198/106186006X133933" href="/articles/10.1186/1471-2105-8-25#ref-CR29" id="ref-link-section-d19935e690">29</a>]. The problem of biased variable selection in classification trees is covered more thoroughly in a separate section below.</p><p>Since the cforest function does not employ the Gini criterion, we investigate the behavior of the Gini importance for the randomForest function only. The selection frequency and the permutation importance is studied for both functions randomForest and cforest in two ways: Either the individual trees are built on bootstrap samples of the original sample size <i>n</i> drawn with replacement, as suggested in [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 3" title="Breiman L: Random Forests. Machine Learning 2001, 45: 532. 10.1023/A:1010933404324" href="/articles/10.1186/1471-2105-8-25#ref-CR3" id="ref-link-section-d19935e699">3</a>], or on subsamples drawn without replacement.</p><p>For sampling without replacement the subsample size here is set to 0.632 times the original sample size <i>n</i>, because in bootstrap sampling with replacement about 63.2% of the data end up in the bootstrap sample. Other fractions for the subsample size are possible, for instance 0.5 as suggested by Friedman and Hall [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 30" title="Friedman J, Hall P: On Bagging and Nonlinear Estimation. preprint 1999. [&#xA;                    http://www-stat.stanford.edu/~jhf/&#xA;                    &#xA;                  ]" href="/articles/10.1186/1471-2105-8-25#ref-CR30" id="ref-link-section-d19935e708">30</a>]. Subsampling as an alternative to bootstrap sampling in aggregating, e.g., individual classification trees is investigated further by Bhlmann and Yu [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 31" title="Bhlmann P, Yu B: Analyzing Bagging. The Annals of Statistics 2002, 30: 927961. 10.1214/aos/1031689014" href="/articles/10.1186/1471-2105-8-25#ref-CR31" id="ref-link-section-d19935e711">31</a>], who also coin the term "subagging" as an abbreviation for "subsample aggregating" as opposed to "bagging" for "bootstrap aggregating". Politis, Romano and Wolf [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 32" title="Politis DN, Romano JP, Wolf M: Subsampling. New York: Springer; 1999." href="/articles/10.1186/1471-2105-8-25#ref-CR32" id="ref-link-section-d19935e714">32</a>] show that, for statistical inference in general, subsampling works under weaker assumptions than bootstrap sampling and even in situations when bootstrap sampling fails.</p><p>The simulation design used throughout this paper represents a scenario where a binary response variable <i>Y</i> is supposed to be predicted from a set of potential predictor variables that vary in their scale of measurement and number of categories. The first predictor variable <i>X</i><sub>1</sub> is continuous, while the other predictor variables <i>X</i><sub>2</sub>,..., <i>X</i><sub>5</sub> are categorical (on a nominal scale of measurement) with their number of categories between two and up to twenty. The simulation designs of both studies are summarized in Tables <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/articles/10.1186/1471-2105-8-25#Tab1">1</a> and <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/articles/10.1186/1471-2105-8-25#Tab2">2</a>. The sample size for all simulation studies was set to <i>n</i> = 120.</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-1"><figure><figcaption class="c-article-table__figcaption"><b id="Tab1" data-test="table-caption">Table 1 Simulation design for the simulation studies  predictor variables</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-category="article body" data-track-label="button" rel="nofollow" href="/articles/10.1186/1471-2105-8-25/tables/1"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-2"><figure><figcaption class="c-article-table__figcaption"><b id="Tab2" data-test="table-caption">Table 2 Simulation design for the simulation studies  response variable</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-category="article body" data-track-label="button" rel="nofollow" href="/articles/10.1186/1471-2105-8-25/tables/2"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><p>In the first simulation study, the so-called null case, none of the predictor variables is informative for the response, i.e. all predictor variables and the response are sampled independently. In this situation a sensible variable importance measure should not prefer any one predictor variable over any other.</p><p>In the second simulation study, the so-called power case, the predictor variable <i>X</i><sub>2</sub> is informative for the response, i.e. the distribution of the response depends on the value of this predictor variable. The degree of dependence between the informative predictor variable <i>X</i><sub>2</sub> and the response <i>Y</i> is regulated by the <i>relevance</i> parameter of the conditional distribution of <i>Y</i> given <i>X</i><sub>2</sub> (cf. Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/articles/10.1186/1471-2105-8-25#Tab2">2</a>). We will later display results for different values of the <i>relevance</i> parameter indicating different degrees of dependence between <i>X</i><sub>2</sub> and <i>Y</i>. In the power case, a sensible variable importance measure should be able to distinguish the informative predictor variable from its uninformative competitors, and even more so with increasing degree of dependence.</p></div></div></section><section aria-labelledby="Sec5"><div class="c-article-section" id="Sec5-section"><h2 class="c-article-section__title u-h2 js-section-title js-c-reading-companion-sections-item" id="Sec5">Results and discussion</h2><div class="c-article-section__content" id="Sec5-content"><p>Our simulation studies show that for the randomForest function all three variable importance measures are unreliable, and the Gini importance is most strongly biased. For the cforest function reliable results can be achieved both with the selection frequency and the permutation importance if the function is used together with subsampling without replacement. Otherwise the measures are biased as well.</p><h3 class="c-article__sub-heading u-h3" id="Sec6">Results of the null case simulation study</h3><p>In the null case, when all predictor variables are equally uninformative, the selection frequencies as well as the Gini importance and the permutation importance of all predictor variables are supposed to be equal. However, as presented in Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/10.1186/1471-2105-8-25#Fig1">1</a>, the mean selection frequencies (over 1000 simulation runs) of the predictor variables differ substantially when the randomForest function (cf. top row in Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/10.1186/1471-2105-8-25#Fig1">1</a>) or the cforest function with bootstrap sampling (cf. bottom row, left plot in Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/10.1186/1471-2105-8-25#Fig1">1</a>) are used. Variables with more categories are obviously preferred. Only when the cforest function is used together with subsampling without replacement (cf. bottom row, right plot in Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/10.1186/1471-2105-8-25#Fig1">1</a>) are the variable selection frequencies for the uninformative predictor variables equally low as desired.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-1"><figure><figcaption><b id="Fig1" class="c-article-section__figure-caption" data-test="figure-caption-text">Figure 1</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-category="article body" data-track-label="image" data-track-action="view figure" href="/articles/10.1186/1471-2105-8-25/figures/1" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1186%2F1471-2105-8-25/MediaObjects/12859_2006_Article_1397_Fig1_HTML.jpg?as=webp"></source><img aria-describedby="figure-1-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1186%2F1471-2105-8-25/MediaObjects/12859_2006_Article_1397_Fig1_HTML.jpg" alt="figure1" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-1-desc"><p><b>Results of the null case study  variable selection frequency</b>. Mean variable selection frequencies for the null case, where none of the predictor variables is informative. The plots in the top row display the frequencies when the randomForest function is used, the bottom row when the cforest function is used. The left column corresponds to bootstrap sampling with replacement, the right column to subsampling without replacement.</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-category="article body" data-track-label="button" data-track-action="view figure" href="/articles/10.1186/1471-2105-8-25/figures/1" data-track-dest="link:Figure1 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><p>It is obvious that variable importance cannot be represented reliably by the selection frequencies, that can be considered as very basic variable importance measures, if the potential predictor variables vary in their scale of measurement or number of categories when the randomForest function or the cforest function with bootstrap sampling is used.</p><p>The mean Gini importance (over 1000 simulation runs), that is displayed in Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/10.1186/1471-2105-8-25#Fig2">2</a>, is biased even stronger. Like the selection frequencies for the randomForest function (cf. top row in Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/10.1186/1471-2105-8-25#Fig1">1</a>) the Gini importance shows a strong preference for variables with many categories and the continuous variable, the statistical sources of which are explained in the section on variable selection bias in classification trees below. We conclude that the Gini importance cannot be used to reliably measure variable importance in this situation either.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-2"><figure><figcaption><b id="Fig2" class="c-article-section__figure-caption" data-test="figure-caption-text">Figure 2</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-category="article body" data-track-label="image" data-track-action="view figure" href="/articles/10.1186/1471-2105-8-25/figures/2" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1186%2F1471-2105-8-25/MediaObjects/12859_2006_Article_1397_Fig2_HTML.jpg?as=webp"></source><img aria-describedby="figure-2-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1186%2F1471-2105-8-25/MediaObjects/12859_2006_Article_1397_Fig2_HTML.jpg" alt="figure2" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-2-desc"><p><b>Results of the null case study  Gini importance</b>. Mean Gini importance for the null case, where none of the predictor variables is informative. The left plot corresponds to bootstrap sampling with replacement, the right plot to subsampling without replacement.</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-category="article body" data-track-label="button" data-track-action="view figure" href="/articles/10.1186/1471-2105-8-25/figures/2" data-track-dest="link:Figure2 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><p>We now consider the more advanced permutation importance measure. We find that here an effect of the scale of measurement or number of categories of the potential predictor variables is less obvious but still severely affects the reliability and interpretability of the variable importance measure.</p><p>Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/10.1186/1471-2105-8-25#Fig3">3</a> shows boxplots of the distributions (over 1000 simulation runs) of the permutation importance measures of both functions for the null case. The plots in the top row again display the distribution when the randomForest function is used, the bottom row when the cforest function is used. The left column of plots displays the distributions when bootstrap sampling is conducted with replacement, while the right column displays the distributions when subsampling is conducted without replacement.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-3"><figure><figcaption><b id="Fig3" class="c-article-section__figure-caption" data-test="figure-caption-text">Figure 3</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-category="article body" data-track-label="image" data-track-action="view figure" href="/articles/10.1186/1471-2105-8-25/figures/3" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1186%2F1471-2105-8-25/MediaObjects/12859_2006_Article_1397_Fig3_HTML.jpg?as=webp"></source><img aria-describedby="figure-3-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1186%2F1471-2105-8-25/MediaObjects/12859_2006_Article_1397_Fig3_HTML.jpg" alt="figure3" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-3-desc"><p><b>Results of the null case study  unscaled permutation importance</b>. Distributions of the unscaled permutation importance measures for the null case, where none of the predictor variables is informative. The plots in the top row display the distributions when the randomForest function is used, the bottom row when the cforest function is used. The left column corresponds to bootstrap sampling with replacement, the right column to subsampling without replacement.</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-category="article body" data-track-label="button" data-track-action="view figure" href="/articles/10.1186/1471-2105-8-25/figures/3" data-track-dest="link:Figure3 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><p>Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/10.1186/1471-2105-8-25#Fig4">4</a> shows boxplots of the distributions of the scaled version of the permutation importance measures of both functions, incorporating the standard deviation of the measures.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-4"><figure><figcaption><b id="Fig4" class="c-article-section__figure-caption" data-test="figure-caption-text">Figure 4</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-category="article body" data-track-label="image" data-track-action="view figure" href="/articles/10.1186/1471-2105-8-25/figures/4" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1186%2F1471-2105-8-25/MediaObjects/12859_2006_Article_1397_Fig4_HTML.jpg?as=webp"></source><img aria-describedby="figure-4-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1186%2F1471-2105-8-25/MediaObjects/12859_2006_Article_1397_Fig4_HTML.jpg" alt="figure4" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-4-desc"><p><b>Results of the null case study  scaled permutation importance</b>. Distributions of the scaled permutation importance measures for the null case, where none of the predictor variables is informative. The plots in the top row display the distributions when the randomForest function is used, the bottom row when the cforest function is used. The left column corresponds to bootstrap sampling with replacement, the right column to subsampling without replacement.</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-category="article body" data-track-label="button" data-track-action="view figure" href="/articles/10.1186/1471-2105-8-25/figures/4" data-track-dest="link:Figure4 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><p>The scaled variable importance is the default output of the randomForest function. However, it has been noted, e.g., by Daz-Uriate and Alvarez de Andrs [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 4" title="Daz-Uriarte R, Alvarez de Andrs S: Gene Selection and Classification of Microarray Data Using Random Forest. BMC Bioinformatics 2006, 7: 3. 10.1186/1471-2105-7-3" href="/articles/10.1186/1471-2105-8-25#ref-CR4" id="ref-link-section-d19935e1265">4</a>] in their supplementary material, that the scaled variable importance of the randomForest function depends on the number of trees grown in the random forest. (In the cforest function, this is not the case.) Therefore we suggest not to interpret the magnitude of the scaled variable importance of the randomForest function.</p><p>The plots show that for the randomForest function (cf. top row in Figures <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/10.1186/1471-2105-8-25#Fig3">3</a> and <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/10.1186/1471-2105-8-25#Fig4">4</a>) and, less pronounced, for the cforest function with bootstrap sampling (cf. bottom row, left plot in Figures <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/10.1186/1471-2105-8-25#Fig3">3</a> and <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/10.1186/1471-2105-8-25#Fig4">4</a>), the deviation of the permutation importance measure over the simulation runs is highest for the variable <i>X</i><sub>5</sub> with the highest number of categories, and decreases for the variables with less categories and the continuous variable. This effect is weakened but not substantially altered by scaling the measure (cf. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/10.1186/1471-2105-8-25#Fig3">3</a> vs. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/10.1186/1471-2105-8-25#Fig4">4</a>).</p><p>As opposed to the obvious effect in the selection frequencies and the Gini importance, there is no effect in the mean values of the distributions of the permutation importance measures, which are in mean close to zero as expected for uninformative variables. However, the notable differences in the variance of the distributions for predictor variables with different scale of measurement or number of categories seriously affect the expressiveness of the variable importance measure.</p><p>In a single trial this effect may lead to a severe over- or underestimation of the variable importance of variables that have more categories as an artefact of the method, even though they are no more or less informative than the other variables.</p><p>Only when the cforest function is used together with subsampling without replacement (cf. bottom row, right plot in Figures <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/10.1186/1471-2105-8-25#Fig3">3</a> and <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/10.1186/1471-2105-8-25#Fig4">4</a>) does the deviation of the permutation importance measure over the simulation runs not increase substantially with the number of categories or scale of measurement of the predictor variables.</p><p>Thus, only the variable importance measure available in cforest, and only when used together with sampling without replacement, reliably reflects the true importance of potential predictor variables in a scenario where the potential predictor variables vary in their scale of measurement or number of categories.</p><h3 class="c-article__sub-heading u-h3" id="Sec7">Results of the power case simulation study</h3><p>In the power case, where only the predictor variable <i>X</i><sub>2</sub> is informative, a sensible variable importance measure should be able to distinguish the informative predictor variable.</p><p>The following figures display the results of the power case with the highest value 0.2 of the <i>relevance</i> parameter, indicating a high degree of dependence between <i>X</i><sub>2</sub> and the response. In this setting, each of the variable importance measures should clearly prefer <i>X</i><sub>2</sub>, while the respective values for the remaining predictor variables should be equally low.</p><p>Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/10.1186/1471-2105-8-25#Fig5">5</a> shows that the mean selection frequencies (again over 1000 simulation runs) of the predictor variables again differ substantially when the randomForest function (cf. top row in Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/10.1186/1471-2105-8-25#Fig5">5</a>) is used, and the relevant predictor variable <i>X</i><sub>2</sub> cannot be identified. With the cforest function with bootstrap sampling (cf. bottom row, left plot in Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/10.1186/1471-2105-8-25#Fig5">5</a>) there is still bias obvious in the selection frequencies of the categorical predictor variables with many categories. Only when the cforest function is used together with subsampling without replacement (cf. bottom row, right plot in Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/10.1186/1471-2105-8-25#Fig5">5</a>), are the variable selection frequencies for the uninformative predictor variables equally low as desired, and the value for the relevant predictor variable <i>X</i><sub>2</sub> sticks out.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-5"><figure><figcaption><b id="Fig5" class="c-article-section__figure-caption" data-test="figure-caption-text">Figure 5</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-category="article body" data-track-label="image" data-track-action="view figure" href="/articles/10.1186/1471-2105-8-25/figures/5" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1186%2F1471-2105-8-25/MediaObjects/12859_2006_Article_1397_Fig5_HTML.jpg?as=webp"></source><img aria-describedby="figure-5-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1186%2F1471-2105-8-25/MediaObjects/12859_2006_Article_1397_Fig5_HTML.jpg" alt="figure5" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-5-desc"><p><b>Results of the power case study  variable selection frequency</b>. Mean variable selection frequencies for the power case, where only the second predictor variable is informative. The plots in the top row display the frequencies when the randomForest function is used, the bottom row when the cforest function is used. The left column corresponds to bootstrap sampling with replacement, the right column to subsampling without replacement.</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-category="article body" data-track-label="button" data-track-action="view figure" href="/articles/10.1186/1471-2105-8-25/figures/5" data-track-dest="link:Figure5 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><p>The mean Gini importance, that is displayed in Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/10.1186/1471-2105-8-25#Fig6">6</a>, again shows a strong bias towards variables with many categories and the continuous variable. It completely fails to identify the relevant predictor variable, with the mean value for the relevant variable <i>X</i><sub>2</sub> only slightly higher than in the null case.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-6"><figure><figcaption><b id="Fig6" class="c-article-section__figure-caption" data-test="figure-caption-text">Figure 6</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-category="article body" data-track-label="image" data-track-action="view figure" href="/articles/10.1186/1471-2105-8-25/figures/6" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1186%2F1471-2105-8-25/MediaObjects/12859_2006_Article_1397_Fig6_HTML.jpg?as=webp"></source><img aria-describedby="figure-6-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1186%2F1471-2105-8-25/MediaObjects/12859_2006_Article_1397_Fig6_HTML.jpg" alt="figure6" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-6-desc"><p><b>Results of the power case study  Gini importance</b>. Mean Gini importance for the power case, where only the second predictor variable is informative. The left plot corresponds to bootstrap sampling with replacement, the right plot to subsampling without replacement.</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-category="article body" data-track-label="button" data-track-action="view figure" href="/articles/10.1186/1471-2105-8-25/figures/6" data-track-dest="link:Figure6 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><p>Figures <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/10.1186/1471-2105-8-25#Fig7">7</a> and <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/10.1186/1471-2105-8-25#Fig8">8</a> show boxplots of the distributions of the unscaled and scaled permutation importance measures of both functions. Again for the randomForest function (cf. top row in Figures <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/10.1186/1471-2105-8-25#Fig7">7</a> and <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/10.1186/1471-2105-8-25#Fig8">8</a>) and, less pronounced, for the cforest function with bootstrap sampling (cf. bottom row, left plot in Figures <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/10.1186/1471-2105-8-25#Fig7">7</a> and <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/10.1186/1471-2105-8-25#Fig8">8</a>), the deviation of the permutation importance measure over the simulation runs is highest for the variable <i>X</i><sub>5</sub> with the highest number of categories, and decreases for the variables with less categories and the continuous variable. This effect is weakened but not substantially altered by scaling the measure (cf. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/10.1186/1471-2105-8-25#Fig7">7</a> vs. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/10.1186/1471-2105-8-25#Fig8">8</a>).</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-7"><figure><figcaption><b id="Fig7" class="c-article-section__figure-caption" data-test="figure-caption-text">Figure 7</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-category="article body" data-track-label="image" data-track-action="view figure" href="/articles/10.1186/1471-2105-8-25/figures/7" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1186%2F1471-2105-8-25/MediaObjects/12859_2006_Article_1397_Fig7_HTML.jpg?as=webp"></source><img aria-describedby="figure-7-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1186%2F1471-2105-8-25/MediaObjects/12859_2006_Article_1397_Fig7_HTML.jpg" alt="figure7" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-7-desc"><p><b>Results of the power case study  unscaled permutation importance</b>. Distributions of the unscaled permutation importance measures for the power case, where only the second predictor variable is informative. The plots in the top row display the distributions when the randomForest function is used, the bottom row when the cforest function is used. The left column corresponds to bootstrap sampling with replacement, the right column to subsampling without replacement.</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-category="article body" data-track-label="button" data-track-action="view figure" href="/articles/10.1186/1471-2105-8-25/figures/7" data-track-dest="link:Figure7 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-8"><figure><figcaption><b id="Fig8" class="c-article-section__figure-caption" data-test="figure-caption-text">Figure 8</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-category="article body" data-track-label="image" data-track-action="view figure" href="/articles/10.1186/1471-2105-8-25/figures/8" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1186%2F1471-2105-8-25/MediaObjects/12859_2006_Article_1397_Fig8_HTML.jpg?as=webp"></source><img aria-describedby="figure-8-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1186%2F1471-2105-8-25/MediaObjects/12859_2006_Article_1397_Fig8_HTML.jpg" alt="figure8" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-8-desc"><p><b>Results of the power case study  scaled permutation importance</b>. Distributions of the scaled permutation importance measures for the power case, where only the second predictor variable is informative. The plots in the top row display the distributions when the randomForest function is used, the bottom row when the cforest function is used. The left column corresponds to bootstrap sampling with replacement, the right column to subsampling without replacement.</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-category="article body" data-track-label="button" data-track-action="view figure" href="/articles/10.1186/1471-2105-8-25/figures/8" data-track-dest="link:Figure8 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><p>As expected the mean value of the permutation importance measure for the informative predictor variable <i>X</i><sub>2</sub> is higher than for the uninformative variables. However, the deviation of the variable importance measure for the uninformative variables with many categories <i>X</i><sub>4</sub> and <i>X</i><sub>5</sub> is so high that in a single trial these uninformative variables may outperform the informative variable as an artefact of the method. Thus, only the variable importance measure computed with the cforest function, and only when used together with sampling without replacement, is able to reliably detect the informative variable out of a set of uninformative competitors, even if the degree of dependence between <i>X</i><sub>2</sub> and the response is high. The rate at which the informative predictor variable is correctly identified (by producing the highest value of the permutation importance measure) increases with the degree of dependence between <i>X</i><sub>2</sub> and the response. In Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/articles/10.1186/1471-2105-8-25#Tab3">3</a> the rates of correct identifications (over 1000 simulation runs) for four different degrees of dependence between <i>X</i><sub>2</sub> and the response are summarized for the randomForest and cforest function with different options.</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-3"><figure><figcaption class="c-article-table__figcaption"><b id="Tab3" data-test="table-caption">Table 3 Rates of correct identifications of the informative variable for the power case</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-category="article body" data-track-label="button" rel="nofollow" href="/articles/10.1186/1471-2105-8-25/tables/3"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><p>For all degrees of dependence between <i>X</i><sub>2</sub> and the response <i>Y</i> the cforest function detects the informative variable more reliably than the randomForest function, and the cforest function used with subsampling without replacement outperforms the cforest function with bootstrap sampling with replacement. For the randomForest function scaling the permutation importance measure can slightly increase the rates of correct identifications because, as shown in Figures <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/10.1186/1471-2105-8-25#Fig4">4</a> and <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/10.1186/1471-2105-8-25#Fig8">8</a>, scaling weakens the differences in variance of the permutation importance measure for variables of different scale of measurement and number of categories. For the cforest function, that is not affected by the scale of measurement and number of categories of the predictor variables, both the unscaled and the scaled permutation importance perform equally well.</p><p>So far we have seen that for the assessment of variable importance and variable selection purposes it is important to use a reliable method, that is not affected by other characteristics of the predictor variables. Statistical explanations of our findings are given in a later section.</p><p>In addition to its superiority in the assessment of variable importance the cforest method, especially when used together with subsampling without replacement, can also be superior to the randomForest method with respect to classification accuracy in situations like that of the power case simulation study, where uninformative predictor variables with many categories "fool" the randomForest function.</p><p>Due to its artificial preference for uninformative predictor variables with many categories the randomForest function can produce a higher mean misclassification rate than the cforest function. The mean misclassification rates (again over 1000 simulation runs) for the randomForest and cforest function, again for four different degrees of dependence and used with sampling with and without replacement, are displayed in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/articles/10.1186/1471-2105-8-25#Tab4">4</a>.</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-4"><figure><figcaption class="c-article-table__figcaption"><b id="Tab4" data-test="table-caption">Table 4 Mean misclassification rates for the power case</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-category="article body" data-track-label="button" rel="nofollow" href="/articles/10.1186/1471-2105-8-25/tables/4"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><p>Each method was applied to the same simulated test set in each simulation run. The test sets were generated from the same data generating process as the learning sets. We find that for all degrees of dependence between <i>X</i><sub>2</sub> and the response <i>Y</i> the cforest function, especially with sampling without replacement, outperforms the other methods. A similar result is obtained in the application to C-to-U conversion data presented in the next section.</p><p>The differences in classification accuracy are moderate in the latter case, however one could think of more extreme situations that would produce even greater differences. This shows that the same mechanisms underlying the variable importance bias can also affect the classification accuracy, e.g. when suboptimal predictor variables, that do not add to the classification accuracy, are artificially preferred in variable selection merely because they have more categories.</p><h3 class="c-article__sub-heading u-h3" id="Sec8">Application to C-to-U conversion data</h3><p>RNA editing is the process whereby RNA is modified from the sequence of the corresponding DNA template [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 11" title="Cummings MP, Myers DS: Simple Statistical Models Predict C-to-U Edited Sites in Plant Mitochondrial RNA. BMC Bioinformatics 2004, 5: 132. 10.1186/1471-2105-5-132" href="/articles/10.1186/1471-2105-8-25#ref-CR11" id="ref-link-section-d19935e2222">11</a>]. For instance, cytidine-to-uridine conversion (abbreviated C-to-U conversion) is common in plant mitochondria. The mechanisms of this conversion remain largely unknown, although the role of neighboring nucleotides is emphasized. Cummings and Myers [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 11" title="Cummings MP, Myers DS: Simple Statistical Models Predict C-to-U Edited Sites in Plant Mitochondrial RNA. BMC Bioinformatics 2004, 5: 132. 10.1186/1471-2105-5-132" href="/articles/10.1186/1471-2105-8-25#ref-CR11" id="ref-link-section-d19935e2225">11</a>] suggest to use information from sequence regions flanking the sites of interest to predict editing in <i>Arabidopsis thaliana</i>, <i>Brassica napus</i> and <i>Oryza sativa</i> based on random forests. The <i>Arabidopsis thaliana</i> data of [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 11" title="Cummings MP, Myers DS: Simple Statistical Models Predict C-to-U Edited Sites in Plant Mitochondrial RNA. BMC Bioinformatics 2004, 5: 132. 10.1186/1471-2105-5-132" href="/articles/10.1186/1471-2105-8-25#ref-CR11" id="ref-link-section-d19935e2241">11</a>] can be loaded from the journal's homepage. For each of the 876 observations, the data set gives</p>
                  <ul class="u-list-style-bullet">
                    <li>
                      <p>the response at the site of interest (binary: edited/not edited) and as potential predictor variables</p>
                    </li>
                    <li>
                      <p>the 40 nucleotides at positions -20 to 20, relative to the edited site (4 categories),</p>
                    </li>
                    <li>
                      <p>the codon position (4 categories),</p>
                    </li>
                    <li>
                      <p>the estimated folding energy (continuous) and</p>
                    </li>
                    <li>
                      <p>the difference in estimated folding energy between pre-edited and edited sequences (continuous).</p>
                    </li>
                  </ul>
                <p>We first derive the permutation importance measure for each of the 43 potential predictor variables with each method. As can be seen from the barplot in Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/10.1186/1471-2105-8-25#Fig9">9</a>, the (scaled) variable importance measures largely reflect the results of [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 11" title="Cummings MP, Myers DS: Simple Statistical Models Predict C-to-U Edited Sites in Plant Mitochondrial RNA. BMC Bioinformatics 2004, 5: 132. 10.1186/1471-2105-5-132" href="/articles/10.1186/1471-2105-8-25#ref-CR11" id="ref-link-section-d19935e2281">11</a>] based on the Gini importance measure, but differ slightly for the randomForest and cforest function and the different resampling schemes. In particular, the variable importance measure of the randomForest function seems to produce more "noise" than that of the cforest function: the contrast of amplitudes between irrelevant and relevant predictors is more pronounced when the cforest function is used.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-9"><figure><figcaption><b id="Fig9" class="c-article-section__figure-caption" data-test="figure-caption-text">Figure 9</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-category="article body" data-track-label="image" data-track-action="view figure" href="/articles/10.1186/1471-2105-8-25/figures/9" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1186%2F1471-2105-8-25/MediaObjects/12859_2006_Article_1397_Fig9_HTML.jpg?as=webp"></source><img aria-describedby="figure-9-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1186%2F1471-2105-8-25/MediaObjects/12859_2006_Article_1397_Fig9_HTML.jpg" alt="figure9" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-9-desc"><p><b>Results for the C-to-U conversion data  scaled permutation importance</b>. Scaled variable importance measures for the C-to-U conversion data. The plots in the top row display the measures when the randomForest function is used, the bottom row when the cforest function is used. The left column corresponds to bootstrap sampling with replacement, the right column to subsampling without replacement. In each plot the positions -20 through 20 indicate the nucleotides flanking the site of interest, and the last three bars on the right refer to the codon position (cp), the estimated folding energy (fe) and the difference in estimated folding energy (dfe).</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-category="article body" data-track-label="button" data-track-action="view figure" href="/articles/10.1186/1471-2105-8-25/figures/9" data-track-dest="link:Figure9 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><p>Note, however, that the the permutation importance values for one predictor variable can vary between two computations, because each computation is based on a different random permutation of the variable. Therefore, before interpreting random forest permutation importance values, the analysis should be repeated (with several different random seeds) to test the stability of the results.</p><p>Similarly to the simulation study, we also compared the prediction accuracy of the four approaches for this data set. To do so, we split the original data set into learning and test sets with size ratio 2:1 in a standard split-sample validation scheme. A random forest is grown based on the learning set and subsequently used to predict the observations in the test set. This procedure is repeated 100 times, and the mean misclassification rates over the 100 runs are reported in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/articles/10.1186/1471-2105-8-25#Tab5">5</a>. Again we find a slight superiority of the cforest function, especially when sampling is conducted without replacement. (Differences to the accuracy values reported in [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 11" title="Cummings MP, Myers DS: Simple Statistical Models Predict C-to-U Edited Sites in Plant Mitochondrial RNA. BMC Bioinformatics 2004, 5: 132. 10.1186/1471-2105-5-132" href="/articles/10.1186/1471-2105-8-25#ref-CR11" id="ref-link-section-d19935e2313">11</a>] are most likely due to their use of a different validation scheme, that is not reported in detail in [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 11" title="Cummings MP, Myers DS: Simple Statistical Models Predict C-to-U Edited Sites in Plant Mitochondrial RNA. BMC Bioinformatics 2004, 5: 132. 10.1186/1471-2105-5-132" href="/articles/10.1186/1471-2105-8-25#ref-CR11" id="ref-link-section-d19935e2316">11</a>].)</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-5"><figure><figcaption class="c-article-table__figcaption"><b id="Tab5" data-test="table-caption">Table 5 Mean misclassification rates for application to C-to-U conversion data</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-category="article body" data-track-label="button" rel="nofollow" href="/articles/10.1186/1471-2105-8-25/tables/5"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><p>All function calls and all important options of the randomForest and cforest functions used in the simulation studies and the application to C-to-U conversion data are documented in the supplement [see Additional file <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/10.1186/1471-2105-8-25#MOESM1">1</a>].</p><h3 class="c-article__sub-heading u-h3" id="Sec9">Sources of variable importance bias</h3><p>The main difference between the randomForest function, based on CART trees [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 18" title="Breiman L, Friedman JH, Olshen RA, Stone CJ: Classification and Regression Trees. New York: Chapman and Hall; 1984." href="/articles/10.1186/1471-2105-8-25#ref-CR18" id="ref-link-section-d19935e2445">18</a>], and cforest function, based on conditional inference trees [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 29" title="Hothorn T, Hornik K, Zeileis A: Unbiased Recursive Partitioning: A Conditional Inference Framework. Journal of Computational and Graphical Statistics 2006, 15: 651674. 10.1198/106186006X133933" href="/articles/10.1186/1471-2105-8-25#ref-CR29" id="ref-link-section-d19935e2448">29</a>], is that in randomForest the variable selection in the individual CART trees is biased, so that e.g. variables with more categories are preferred. This is illustrated in the next section on variable selection bias in individual classification trees.</p><p>However, even if the individual trees select variables in an unbiased way as in the cforest function, we find that the variable importance measures, as well as the selection frequencies of the variables, are affected by the bootstrap sampling with replacement. This is explained in the section on effects induced by bootstrapping.</p><h3 class="c-article__sub-heading u-h3" id="Sec10">Variable selection bias in the individual classification trees of a random forest</h3><p>Let us again consider the null case simulation study design, where none of the variables is informative, and thus should be selected with equally low probabilities in a classification tree.</p><p>In traditional classification tree algorithms, like CART, for each variable a split criterion like the "Gini index" is computed for all possible cutpoints within the range of that variable. The variable selected for the next split is the one that produced the highest criterion value overall, i.e. in its best cutpoint.</p><p>Obviously variables with more potential cutpoints are more likely to produce a good criterion value by chance, as in a multiple testing situation. Therefore, if we compare the highest criterion value of a variable with two categories, say, that provides only one cutpoint from which the criterion was computed, with a variable with four categories, that provides seven cutpoints from which the best criterion value is used, the latter is often preferred. Because the number of cutpoints grows exponentially with the number of categories of unordered categorical predictors we find a preference for variables with more categories in CART-like classification trees. For further reading on variable selection bias in classification trees see, e.g., the corresponding sections in [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 24" title="Kononenko I: On Biases in Estimating Multi-Valued Attributes. In Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence, Montral, Canada Edited by: Mellish C. 1995, 10341040." href="/articles/10.1186/1471-2105-8-25#ref-CR24" id="ref-link-section-d19935e2465">24</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 25" title="Kim H, Loh W: Classification Trees with Unbiased Multiway Splits. Journal of the American Statistical Association 2001, 96: 589604. 10.1198/016214501753168271" href="/articles/10.1186/1471-2105-8-25#ref-CR25" id="ref-link-section-d19935e2468">25</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 28" title="Strobl C, Boulesteix AL, Augustin T: Unbiased Split Selection for Classification Trees Based on the Gini Index. Computational Statistics &amp; Data Analysis 2006. [&#xA;                    http://dx.doi.org/10.1016/j.csda.2006.12.030&#xA;                    &#xA;                  ]" href="/articles/10.1186/1471-2105-8-25#ref-CR28" id="ref-link-section-d19935e2471">28</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 29" title="Hothorn T, Hornik K, Zeileis A: Unbiased Recursive Partitioning: A Conditional Inference Framework. Journal of Computational and Graphical Statistics 2006, 15: 651674. 10.1198/106186006X133933" href="/articles/10.1186/1471-2105-8-25#ref-CR29" id="ref-link-section-d19935e2474">29</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 33" title="Dobra A, Gehrke J: Bias Correction in Classification Tree Construction. In Proceedings of the Seventeenth International Conference on Machine Learning, Williams College, Williamstown, MA, USA Edited by: Brodley CE, Danyluk AP. 2001, 9097." href="/articles/10.1186/1471-2105-8-25#ref-CR33" id="ref-link-section-d19935e2477">33</a><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 35" title="Strobl C: Variable Selection in Classification Trees Based on Imprecise Probabilities. In Proceedings of the Fourth International Symposium on Imprecise Probabilities and Their Applications, Carnegy Mellon University, Pittsburgh, PA, USA Edited by: Cozman F, Nau R, Seidenfeld T. 2005, 340348." href="/articles/10.1186/1471-2105-8-25#ref-CR35" id="ref-link-section-d19935e2481">35</a>].</p><p>Since the Gini importance measure in randomForest is directly derived from the Gini index split criterion used in the underlying individual classification trees, it carries forward the same bias, as was shown in Figures <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/10.1186/1471-2105-8-25#Fig2">2</a> and <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/10.1186/1471-2105-8-25#Fig6">6</a>.</p><p>Conditional inference trees [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 29" title="Hothorn T, Hornik K, Zeileis A: Unbiased Recursive Partitioning: A Conditional Inference Framework. Journal of Computational and Graphical Statistics 2006, 15: 651674. 10.1198/106186006X133933" href="/articles/10.1186/1471-2105-8-25#ref-CR29" id="ref-link-section-d19935e2497">29</a>], that are used to construct the classification trees in cforest, are unbiased in variable selection. Here, the variable selection is conducted by minimizing the p value of a conditional inference independence test, comparable e.g. to the <i></i><sup>2</sup> test, that incorporates the number of categories of each variable in the degrees of freedom.</p><p>The mean selection frequencies (again over 1000 simulation runs) of the five predictor variables of the null case simulation study design for both CART classification trees (as implemented in the rpart function [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 36" title="Therneau TM, Atkinson B, Ripley BD:rpart: Recursive Partitioning. 2006. [R package version 3.130]. [&#xA;                    http://CRAN.R-project.org/&#xA;                    &#xA;                  ] [R package version 3.130]." href="/articles/10.1186/1471-2105-8-25#ref-CR36" id="ref-link-section-d19935e2507">36</a>]) and conditional inference trees (function ctree) are displayed in Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/10.1186/1471-2105-8-25#Fig10">10</a>. We find that the variable selection with the rpart function is highly biased, while for the ctree function it is unbiased.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-10"><figure><figcaption><b id="Fig10" class="c-article-section__figure-caption" data-test="figure-caption-text">Figure 10</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-category="article body" data-track-label="image" data-track-action="view figure" href="/articles/10.1186/1471-2105-8-25/figures/10" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1186%2F1471-2105-8-25/MediaObjects/12859_2006_Article_1397_Fig10_HTML.jpg?as=webp"></source><img aria-describedby="figure-10-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1186%2F1471-2105-8-25/MediaObjects/12859_2006_Article_1397_Fig10_HTML.jpg" alt="figure10" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-10-desc"><p><b>Variable selection bias in individual trees</b>. Relative selection frequencies for the rpart (left) and the ctree (right) classification tree methods. All variables are uninformative as in the null case simulation study.</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-category="article body" data-track-label="button" data-track-action="view figure" href="/articles/10.1186/1471-2105-8-25/figures/10" data-track-dest="link:Figure10 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><p>The variable selection bias that occurs in every individual tree in the randomForest function also has a direct effect on the variable importance measures of this function. Predictor variables with more categories are artificially preferred in variable selection in each splitting decision. Thus, they are selected in more individual classification trees and tend to be situated closer to the root node in each tree.</p><p>The variable selection bias affects the variable importance measures in two respects. Firstly, the variable selection frequencies over all trees are directly affected by the variable selection bias in each individual tree. Secondly, the effect on the permutation importance is less obvious but just as severe.</p><p>When permuting the variables to compute their permutation importance measure, the variables that appear in more trees and are situated closer to the root node can affect the prediction accuracy of a larger set of observations, while variables that appear in fewer trees and are situated closer to the bottom nodes affect only small subsets of observations. Thus, the range of possible changes in prediction accuracy in the random forest, i.e. the deviation of the variable importance measure, is higher for variables that are preferred by the individual trees due to variable selection bias.</p><p>We found in Figures <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/10.1186/1471-2105-8-25#Fig1">1</a> through <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/10.1186/1471-2105-8-25#Fig9">9</a>, that the effects induced by the differences in scale of measurement of the predictor variables were more pronounced for the randomForest function, where variable selection in the individual trees is biased, than for the cforest function, where the individual trees are unbiased. However, we also found that when the cforest function is used with bootstrap sampling, the variable selection frequencies of the categorical predictors still depend on their number of categories (cf., e.g., bottom row, left plot in Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/10.1186/1471-2105-8-25#Fig1">1</a>), and also the deviation of the permutation importance measure is still affected by the number of categories (cf., e.g., bottom row, left plot in Figures <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/10.1186/1471-2105-8-25#Fig3">3</a> and <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/10.1186/1471-2105-8-25#Fig4">4</a>).</p><p>Thus, there must be another source of bias, besides the variable selection bias in the individual trees, that affects the selection frequencies and the deviation of the permutation importance measure.</p><p>We show in the next section that this additional effect is due to bootstrap sampling with replacement, that is traditionally employed in random forests.</p><h3 class="c-article__sub-heading u-h3" id="Sec11">Effects induced by bootstrapping</h3><p>From the comparison of left and right columns (representing sampling with and without replacement) in Figures <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/10.1186/1471-2105-8-25#Fig1">1</a> and <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/10.1186/1471-2105-8-25#Fig5">5</a> we learned that the variable selection frequencies in random forest functions are affected by the resampling scheme.</p><p>We found that, even when the cforest function based on unbiased classification trees is used, variables with more categories are preferred when bootstrap sampling is conducted with replacement, while no bias occurs when subsampling is conducted without replacement, as displayed in the bottom right plot in Figures <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/10.1186/1471-2105-8-25#Fig1">1</a> and <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/10.1186/1471-2105-8-25#Fig5">5</a>. Thus, the bootstrap sampling induces an effect that is more pronounced for predictor variables with more categories.</p><p>For a better understanding of the underlying mechanism let us consider only the categorical predictor variables <i>X</i><sub>2</sub> through <i>X</i><sub>5</sub> with different numbers of categories from the null case simulation study design.</p><p>Rather than trying to explain the effect of bootstrap sampling in the complex framework of random forests, we use a much simpler independence test for the explanation.</p><p>We consider the p values of <i></i><sup>2</sup> tests (computed from 1000 simulated data sets). In each simulation run, a <i></i><sup>2</sup> test is computed for each predictor variable and the binary response <i>Y</i>. Remember that the variables in the null case are not informative, i.e. the response is independent of all variables.</p><p>For independent variables the distribution of the p values of the <i></i><sup>2</sup> test is supposed to form a uniform distribution.</p><p>The left plot in Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/10.1186/1471-2105-8-25#Fig11">11</a> displays the distribution of the p values of <i></i><sup>2</sup> tests from each predictor variable and the response <i>Y</i> as boxplots. We find that the boxplots range from 0 to 1 with median 0.5 as expected, because the p values of the <i></i><sup>2</sup> test form a uniform distribution when computed before bootstrapping. However, if in each simulation run we draw a bootstrap sample from the original sample and then again compute the p values based on the bootstrap sample, we find that the distribution of the p values is shifted towards zero as displayed in the right plot in Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/10.1186/1471-2105-8-25#Fig11">11</a>.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-11"><figure><figcaption><b id="Fig11" class="c-article-section__figure-caption" data-test="figure-caption-text">Figure 11</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-category="article body" data-track-label="image" data-track-action="view figure" href="/articles/10.1186/1471-2105-8-25/figures/11" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1186%2F1471-2105-8-25/MediaObjects/12859_2006_Article_1397_Fig11_HTML.jpg?as=webp"></source><img aria-describedby="figure-11-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1186%2F1471-2105-8-25/MediaObjects/12859_2006_Article_1397_Fig11_HTML.jpg" alt="figure11" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-11-desc"><p><b>Effects induced by bootstrapping</b>. Distribution of the p values of <i></i><sup>2</sup> tests of each categorical variable <i>X</i><sub>2</sub>,..., <i>X</i><sub>5</sub> and the binary response for the null case simulation study, where none of the predictor variables is informative. The left plots correspond to the distribution of the p values computed from the original sample before bootstrapping. The right plots correspond to the distribution of the p values computed for each variable from the bootstrap sample drawn with replacement.</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-category="article body" data-track-label="button" data-track-action="view figure" href="/articles/10.1186/1471-2105-8-25/figures/11" data-track-dest="link:Figure11 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><p>Obviously, the bootstrap sampling artificially induces an association between the variables. This effect is always present when statistical inference, such as an association test, is carried out on bootstrap samples: Bickel and Ren [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 37" title="Bickel PJ, Ren JJ: The Bootstrap in Hypothesis Testing. In State of the Art in Probability and Statistics, Festschrift for Willem R. van Zwet, IMS Lecture Notes Monograph Series, Beachwood, OH, USA Edited by: de Gunst M, Klaassen C, van der Vaart A. 2001, 36: 91112." href="/articles/10.1186/1471-2105-8-25#ref-CR37" id="ref-link-section-d19935e2676">37</a>] point out that bootstrap hypothesis testing fails whenever the distribution of any statistic in the bootstrap sample, rather than the distribution of the statistic under the null hypothesis, is used for statistical inference. We found that this issue directly affects variable selection in random forests, because the deviation from the null hypothesis is more pronounced for variables that have more categories. The reason for the shift in the distribution of the p values displayed in Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/10.1186/1471-2105-8-25#Fig11">11</a> is that each original sample, even if sampled from theoretically independent distributions, may show some minor variations from the null hypothesis of independence. These minor variations are aggravated by bootstrap sampling with replacement, because the cell counts in the contingency table are affected by observations that are either not included or are doubled or tripled in the bootstrap sample, and therefore the bootsrap sample deviates notably from the null hypothesis  even if the original sample was generated under the null hypothesis.</p><p>This effect is more pronounced for variables with more categories, because in larger tables (such as the 4  2 table from the cross-classification of <i>X</i><sub>3</sub> and the binary response <i>Y</i>), the absolute cell counts are smaller than in smaller tables (such as the 2  2 table from the cross-classification of <i>X</i><sub>2</sub> and the binary response <i>Y</i>). With respect to the smaller absolute cell counts, excluding or duplicating an observation produces more severe variations from the null hypothesis.</p><p>This effect is not eliminated if the sample size is increased, because in bootstrap sampling the size <i>n</i> of the original sample and the bootstrap sample size <i>n</i> increase simultaneously. However, if subsamples are drawn without replacement the effect disappears.</p><p>The apparent association that is induced by bootstrap sampling, and that is more pronounced for predictor variables with many categories, affects both variable importance measures: The selection frequency is again directly affected, and the permutation importance is affected because variables with many categories are selected more often and gain positions closer to the root node in the individual trees. Together with the mechanisms described in the previous section, this explains our findings.</p><p>From our simulation results we can see, however, that the effect of bootstrap sampling is mostly superposed by the much stronger effect of variable selection bias when comparing the conditions of sampling with and without replacement for the randomForest function only (cf. Figures <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/10.1186/1471-2105-8-25#Fig1">1</a> through <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/10.1186/1471-2105-8-25#Fig9">9</a>, top row). Only when variable selection bias is removed by the cforest function the differences between the conditions of sampling with and without replacement are obvious (cf. Figures <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/10.1186/1471-2105-8-25#Fig1">1</a> through <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/10.1186/1471-2105-8-25#Fig9">9</a>, bottom row). We therefore conclude that in order to be able to reliably interpret the variable importance measures of a random forest, the forest must be built from unbiased classification trees, and sampling must be conducted without replacement.</p></div></div></section><section aria-labelledby="Sec12"><div class="c-article-section" id="Sec12-section"><h2 class="c-article-section__title u-h2 js-section-title js-c-reading-companion-sections-item" id="Sec12">Conclusion</h2><div class="c-article-section__content" id="Sec12-content"><p>Random forests are a powerful statistical tool, that has found many applicants in various scientific areas. It has been applied to such a wide variety of problems as large-scale association studies for complex genetic diseases, the prediction of phenotypes based on amino acid or DNA sequences, QSAR modeling and clinical medicine, to name just a few.</p><p>Features that have added to the popularity of random forests especially in bioinformatics and related fields, where identifying a subset of relevant predictor variables from very large sets of candidates is the major challenge, include its ability to deal with critical "small <i>n</i> large <i>p</i>" data sets and the variable importance measures it provides for variable selection purposes.</p><p>However, when a method is used for variable selection, rather than prediction only, it is particularly important that the value and interpretation of the variable importance measure actually depict the importance of the variable, and are not affected by any other characteristics.</p><p>We found that for the original random forest method the variable importance measures are affected by the number of categories and scale of measurement of the predictor variables, which are no direct indicators of the true importance of the variable.</p><p>As long as, e.g., only continuous predictor variables, as in most gene expression studies, or only variables with the same number of categories are considered in the sample, variable selection with random forest variable importance measures is not affected by our findings. However, in studies where continuous variables, such as the folding energy, are used in combination with categorical information from the neighboring nucleotides, or when categorical predictors, as in amino acid sequence data, vary in their number of categories present in the sample variable selection with random forest variable importance measures is unreliable and may even be misleading.</p><p>Especially informations on clinical and environmental variables are often gathered by means of questionnaires, where the number of categories can vary between questions. The number of categories is typically determined by many different factors, but is not necessarily an indicator of variable importance. Similarly, the number of different categories of a predictor actually available in a certain sample is not an indicator of its relevance for predicting the response. Hence, the number of categories of a variable should not influence its estimated importance  otherwise the results of a study could easily be distorted when an irrelevant variable with many categories is included in the study design.</p><p>We showed that, due to variable selection bias in the individual classification trees and effects induced by bootstrap sampling, the variable importance measures of the randomForest function are not reliable in many scenarios relevant in applied research.</p><p>As an alternative random forest method we propose to use the cforest function, that provides unbiased variable selection in the individual classification trees. When this method is applied with subsampling without replacement the resulting variable importance measure can be used reliably for variable selection even in situations where the potential predictor variables vary in their scale of measurement or their number of categories.</p><p>With respect to computation time the cforest function is more expensive than the randomForest function, because in order to be unbiased split decisions and stopping rely on time-consuming conditional inference. To give an impression, the computation times of the application to C-to-U conversion data, with 876 observations and 44 predictor variables, as stated in the supplementary file for the cforest function used with bootstrap sampling with replacement are in the range of 8.38 sec., while subsampling without replacement is computationally less expensive and in the range of 4.82.</p><p>Since we saw that only subsampling without replacement guarantees reliable variable selection and produces unbiased variable importance measures, the faster version without replacement should be preferred anyway. The computation time for the randomForest function is in the range of 0.24 sec. with and 0.18 sec. without replacement. However, we saw that the randomForest function should not be used when the potential predictor variables vary in their scale of measurement or their number of categories. The aim of this paper was to explore the limits of the empirical measures of variable importance provided for random forests, to understand the underlying mechanisms and to use that understanding to guarantee unbiased and reliable variable selection in random forests.</p><p>In a more theoretical work van der Laan [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 38" title="van der Laan M: Statistical Inference for Variable Importance. International Journal of Biostatistics 2006, 2: 10081008." href="/articles/10.1186/1471-2105-8-25#ref-CR38" id="ref-link-section-d19935e2764">38</a>] gives a fundamental definition of variable importance, as well as a statistical inference framework for estimating and testing variable importance. Inspired by this approach, future research on variable importance measures for variable selection with random forests aims at providing further means of statistical inference, that can be used to guide the decision on which and how many predictor variables to select in a certain problem.</p></div></div></section>
                        <section aria-labelledby="Bib1"><div class="c-article-section" id="Bib1-section"><h2 class="c-article-section__title u-h2 js-section-title js-c-reading-companion-sections-item" id="Bib1">References</h2><div class="c-article-section__content" id="Bib1-content"><div data-container-section="references"><ol class="c-article-references"><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="A. Bureau, J. Dupuis, K. Falls, KL. Lunetta, B. Hayward, TP. Keith, PV. Eerdewegh, " /><meta itemprop="datePublished" content="2005" /><meta itemprop="headline" content="Bureau A, Dupuis J, Falls K, Lunetta KL, Hayward B, Keith TP, Eerdewegh PV: Identifying SNPs Predictive of Phe" /><span class="c-article-references__counter">1.</span><p class="c-article-references__text" id="ref-CR1">Bureau A, Dupuis J, Falls K, Lunetta KL, Hayward B, Keith TP, Eerdewegh PV: Identifying SNPs Predictive of Phenotype Using Random Forests. Genetic Epidemiology 2005, 28: 171182. 10.1002/gepi.20041</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1002%2Fgepi.20041" aria-label="View reference 1">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=15593090" aria-label="View reference 1 on PubMed" rel="nofollow">PubMed</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 1 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Identifying%20SNPs%20Predictive%20of%20Phenotype%20Using%20Random%20Forests&amp;journal=Genetic%20Epidemiology&amp;volume=28&amp;pages=171-182&amp;publication_year=2005&amp;author=Bureau%2CA&amp;author=Dupuis%2CJ&amp;author=Falls%2CK&amp;author=Lunetta%2CKL&amp;author=Hayward%2CB&amp;author=Keith%2CTP&amp;author=Eerdewegh%2CPV">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="AG. Heidema, JMA. Boer, N. Nagelkerke, ECM. Mariman, DL. van der A, EJM. Feskens, " /><meta itemprop="datePublished" content="2006" /><meta itemprop="headline" content="Heidema AG, Boer JMA, Nagelkerke N, Mariman ECM, van der A DL, Feskens EJM: The Challenge for Genetic Epidemio" /><span class="c-article-references__counter">2.</span><p class="c-article-references__text" id="ref-CR2">Heidema AG, Boer JMA, Nagelkerke N, Mariman ECM, van der A DL, Feskens EJM: The Challenge for Genetic Epidemiologists: How to Analyze Large Numbers of SNPs in Relation to Complex Diseases. BMC Genetics 2006, 7: 23. 10.1186/1471-2156-7-23</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC1479365" aria-label="View reference 2 on PubMed Central" rel="nofollow">PubMed Central</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1186%2F1471-2156-7-23" aria-label="View reference 2">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=16630340" aria-label="View reference 2 on PubMed" rel="nofollow">PubMed</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 2 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20Challenge%20for%20Genetic%20Epidemiologists%3A%20How%20to%20Analyze%20Large%20Numbers%20of%20SNPs%20in%20Relation%20to%20Complex%20Diseases&amp;journal=BMC%20Genetics&amp;volume=7&amp;publication_year=2006&amp;author=Heidema%2CAG&amp;author=Boer%2CJMA&amp;author=Nagelkerke%2CN&amp;author=Mariman%2CECM&amp;author=van%20der%20A%2CDL&amp;author=Feskens%2CEJM">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="L. Breiman, " /><meta itemprop="datePublished" content="2001" /><meta itemprop="headline" content="Breiman L: Random Forests. Machine Learning 2001, 45: 532. 10.1023/A:1010933404324" /><span class="c-article-references__counter">3.</span><p class="c-article-references__text" id="ref-CR3">Breiman L: Random Forests. Machine Learning 2001, 45: 532. 10.1023/A:1010933404324</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1023%2FA%3A1010933404324" aria-label="View reference 3">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 3 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Random%20Forests&amp;journal=Machine%20Learning&amp;volume=45&amp;pages=5-32&amp;publication_year=2001&amp;author=Breiman%2CL">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="R. Daz-Uriarte, S. Alvarez de Andrs, " /><meta itemprop="datePublished" content="2006" /><meta itemprop="headline" content="Daz-Uriarte R, Alvarez de Andrs S: Gene Selection and Classification of Microarray Data Using Random Forest." /><span class="c-article-references__counter">4.</span><p class="c-article-references__text" id="ref-CR4">Daz-Uriarte R, Alvarez de Andrs S: Gene Selection and Classification of Microarray Data Using Random Forest. BMC Bioinformatics 2006, 7: 3. 10.1186/1471-2105-7-3</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC1363357" aria-label="View reference 4 on PubMed Central" rel="nofollow">PubMed Central</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1186%2F1471-2105-7-3" aria-label="View reference 4">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=16398926" aria-label="View reference 4 on PubMed" rel="nofollow">PubMed</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 4 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Gene%20Selection%20and%20Classification%20of%20Microarray%20Data%20Using%20Random%20Forest&amp;journal=BMC%20Bioinformatics&amp;volume=7&amp;publication_year=2006&amp;author=D%C3%ADaz-Uriarte%2CR&amp;author=Alvarez%20de%20Andr%C3%A9s%2CS">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="KL. Lunetta, LB. Hayward, J. Segal, PV. Eerdewegh, " /><meta itemprop="datePublished" content="2004" /><meta itemprop="headline" content="Lunetta KL, Hayward LB, Segal J, Eerdewegh PV: Screening Large-Scale Association Study Data: Exploiting Intera" /><span class="c-article-references__counter">5.</span><p class="c-article-references__text" id="ref-CR5">Lunetta KL, Hayward LB, Segal J, Eerdewegh PV: Screening Large-Scale Association Study Data: Exploiting Interactions Using Random Forests. BMC Genetics 2004, 5: 32. 10.1186/1471-2156-5-32</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC545646" aria-label="View reference 5 on PubMed Central" rel="nofollow">PubMed Central</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1186%2F1471-2156-5-32" aria-label="View reference 5">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=15588316" aria-label="View reference 5 on PubMed" rel="nofollow">PubMed</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 5 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Screening%20Large-Scale%20Association%20Study%20Data%3A%20Exploiting%20Interactions%20Using%20Random%20Forests&amp;journal=BMC%20Genetics&amp;volume=5&amp;publication_year=2004&amp;author=Lunetta%2CKL&amp;author=Hayward%2CLB&amp;author=Segal%2CJ&amp;author=Eerdewegh%2CPV">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="EC. Gunther, DJ. Stone, RW. Gerwien, P. Bento, MP. Heyes, " /><meta itemprop="datePublished" content="2003" /><meta itemprop="headline" content="Gunther EC, Stone DJ, Gerwien RW, Bento P, Heyes MP: Prediction of Clinical Drug Efficacy by Classification of" /><span class="c-article-references__counter">6.</span><p class="c-article-references__text" id="ref-CR6">Gunther EC, Stone DJ, Gerwien RW, Bento P, Heyes MP: Prediction of Clinical Drug Efficacy by Classification of Drug-induced Genomic Expression Profiles in vitro . Proceedings of the National Academy of Sciences 2003, 100: 96089613. 10.1073/pnas.1632587100</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="/articles/cas-redirect/1%3ACAS%3A528%3ADC%252BD3sXmtlyrsrg%253D" aria-label="View reference 6 on CAS">CAS</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1073%2Fpnas.1632587100" aria-label="View reference 6">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 6 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Prediction%20of%20Clinical%20Drug%20Efficacy%20by%20Classification%20of%20Drug-induced%20Genomic%20Expression%20Profiles%20in%20vitro&amp;journal=Proceedings%20of%20the%20National%20Academy%20of%20Sciences&amp;volume=100&amp;pages=9608-9613&amp;publication_year=2003&amp;author=Gunther%2CEC&amp;author=Stone%2CDJ&amp;author=Gerwien%2CRW&amp;author=Bento%2CP&amp;author=Heyes%2CMP">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="X. Huang, W. Pan, S. Grindle, X. Han, Y. Chen, SJ. Park, LW. Miller, J. Hall, " /><meta itemprop="datePublished" content="2005" /><meta itemprop="headline" content="Huang X, Pan W, Grindle S, Han X, Chen Y, Park SJ, Miller LW, Hall J: A Comparative Study of Discriminating Hu" /><span class="c-article-references__counter">7.</span><p class="c-article-references__text" id="ref-CR7">Huang X, Pan W, Grindle S, Han X, Chen Y, Park SJ, Miller LW, Hall J: A Comparative Study of Discriminating Human Heart Failure Etiology Using Gene Expression Profiles. BMC Bioinformatics 2005, 6: 205. 10.1186/1471-2105-6-205</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC1224853" aria-label="View reference 7 on PubMed Central" rel="nofollow">PubMed Central</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1186%2F1471-2105-6-205" aria-label="View reference 7">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=16120216" aria-label="View reference 7 on PubMed" rel="nofollow">PubMed</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 7 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20Comparative%20Study%20of%20Discriminating%20Human%20Heart%20Failure%20Etiology%20Using%20Gene%20Expression%20Profiles&amp;journal=BMC%20Bioinformatics&amp;volume=6&amp;publication_year=2005&amp;author=Huang%2CX&amp;author=Pan%2CW&amp;author=Grindle%2CS&amp;author=Han%2CX&amp;author=Chen%2CY&amp;author=Park%2CSJ&amp;author=Miller%2CLW&amp;author=Hall%2CJ">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="Y. Shih, " /><meta itemprop="datePublished" content="2005" /><meta itemprop="headline" content="Shih Y: Tumor Classification by Tissue Microarray Profiling: Random Forest Clustering Applied to Renal Cell Ca" /><span class="c-article-references__counter">8.</span><p class="c-article-references__text" id="ref-CR8">Shih Y: Tumor Classification by Tissue Microarray Profiling: Random Forest Clustering Applied to Renal Cell Carcinoma. Modern Pathology 2005, 18: 547557. 10.1038/modpathol.3800322</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1038%2Fmodpathol.3800322" aria-label="View reference 8">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 8 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Tumor%20Classification%20by%20Tissue%20Microarray%20Profiling%3A%20Random%20Forest%20Clustering%20Applied%20to%20Renal%20Cell%20Carcinoma&amp;journal=Modern%20Pathology&amp;volume=18&amp;pages=547-557&amp;publication_year=2005&amp;author=Shih%2CY">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="MR. Segal, JD. Barbour, RM. Grant, " /><meta itemprop="datePublished" content="2004" /><meta itemprop="headline" content="Segal MR, Barbour JD, Grant RM: Relating HIV-1 Sequence Variation to Replication Capacity via Trees and Forest" /><span class="c-article-references__counter">9.</span><p class="c-article-references__text" id="ref-CR9">Segal MR, Barbour JD, Grant RM: Relating HIV-1 Sequence Variation to Replication Capacity via Trees and Forests. Statistical Applications in Genetics and Molecular Biology 2004, 3: 2.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 9 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Relating%20HIV-1%20Sequence%20Variation%20to%20Replication%20Capacity%20via%20Trees%20and%20Forests&amp;journal=Statistical%20Applications%20in%20Genetics%20and%20Molecular%20Biology&amp;volume=3&amp;publication_year=2004&amp;author=Segal%2CMR&amp;author=Barbour%2CJD&amp;author=Grant%2CRM">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="MP. Cummings, MR. Segal, " /><meta itemprop="datePublished" content="2004" /><meta itemprop="headline" content="Cummings MP, Segal MR: Few Amino Acid Positions in rpoB are Associated with Most of the Rifampin Resistance in" /><span class="c-article-references__counter">10.</span><p class="c-article-references__text" id="ref-CR10">Cummings MP, Segal MR: Few Amino Acid Positions in rpoB are Associated with Most of the Rifampin Resistance in Mycobacterium Tuberculosis. BMC Bioinformatics 2004, 5: 137. 10.1186/1471-2105-5-137</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC524371" aria-label="View reference 10 on PubMed Central" rel="nofollow">PubMed Central</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1186%2F1471-2105-5-137" aria-label="View reference 10">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=15453919" aria-label="View reference 10 on PubMed" rel="nofollow">PubMed</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 10 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Few%20Amino%20Acid%20Positions%20in%20rpoB%20are%20Associated%20with%20Most%20of%20the%20Rifampin%20Resistance%20in%20Mycobacterium%20Tuberculosis&amp;journal=BMC%20Bioinformatics&amp;volume=5&amp;publication_year=2004&amp;author=Cummings%2CMP&amp;author=Segal%2CMR">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="MP. Cummings, DS. Myers, " /><meta itemprop="datePublished" content="2004" /><meta itemprop="headline" content="Cummings MP, Myers DS: Simple Statistical Models Predict C-to-U Edited Sites in Plant Mitochondrial RNA. BMC B" /><span class="c-article-references__counter">11.</span><p class="c-article-references__text" id="ref-CR11">Cummings MP, Myers DS: Simple Statistical Models Predict C-to-U Edited Sites in Plant Mitochondrial RNA. BMC Bioinformatics 2004, 5: 132. 10.1186/1471-2105-5-132</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC521485" aria-label="View reference 11 on PubMed Central" rel="nofollow">PubMed Central</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1186%2F1471-2105-5-132" aria-label="View reference 11">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=15373947" aria-label="View reference 11 on PubMed" rel="nofollow">PubMed</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 11 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Simple%20Statistical%20Models%20Predict%20C-to-U%20Edited%20Sites%20in%20Plant%20Mitochondrial%20RNA&amp;journal=BMC%20Bioinformatics&amp;volume=5&amp;publication_year=2004&amp;author=Cummings%2CMP&amp;author=Myers%2CDS">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="Y. Qi, Z. Bar-Joseph, J. Klein-Seetharaman, " /><meta itemprop="datePublished" content="2006" /><meta itemprop="headline" content="Qi Y, Bar-Joseph Z, Klein-Seetharaman J: Evaluation of Different Biological Data and Computational Classificat" /><span class="c-article-references__counter">12.</span><p class="c-article-references__text" id="ref-CR12">Qi Y, Bar-Joseph Z, Klein-Seetharaman J: Evaluation of Different Biological Data and Computational Classification Methods for Use in Protein Interaction Prediction. Proteins 2006, 63: 490500. 10.1002/prot.20865</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3250929" aria-label="View reference 12 on PubMed Central" rel="nofollow">PubMed Central</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="/articles/cas-redirect/1%3ACAS%3A528%3ADC%252BD28XksFait7o%253D" aria-label="View reference 12 on CAS">CAS</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1002%2Fprot.20865" aria-label="View reference 12">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=16450363" aria-label="View reference 12 on PubMed" rel="nofollow">PubMed</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 12 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Evaluation%20of%20Different%20Biological%20Data%20and%20Computational%20Classification%20Methods%20for%20Use%20in%20Protein%20Interaction%20Prediction&amp;journal=Proteins&amp;volume=63&amp;pages=490-500&amp;publication_year=2006&amp;author=Qi%2CY&amp;author=Bar-Joseph%2CZ&amp;author=Klein-Seetharaman%2CJ">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="R. Guha, PC. Jurs, " /><meta itemprop="datePublished" content="2003" /><meta itemprop="headline" content="Guha R, Jurs PC: Development of Linear, Ensemble, and Nonlinear Models for the Prediction and Interpretation o" /><span class="c-article-references__counter">13.</span><p class="c-article-references__text" id="ref-CR13">Guha R, Jurs PC: Development of Linear, Ensemble, and Nonlinear Models for the Prediction and Interpretation of the Biological Activity of a Set of PDGFR Inhibitors. Journal of Chemical Information and Computer Sciences 2003, 44: 21792189. 10.1021/ci049849f</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 13 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Development%20of%20Linear%2C%20Ensemble%2C%20and%20Nonlinear%20Models%20for%20the%20Prediction%20and%20Interpretation%20of%20the%20Biological%20Activity%20of%20a%20Set%20of%20PDGFR%20Inhibitors&amp;journal=Journal%20of%20Chemical%20Information%20and%20Computer%20Sciences&amp;volume=44&amp;pages=2179-2189&amp;publication_year=2003&amp;author=Guha%2CR&amp;author=Jurs%2CPC">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="V. Svetnik, A. Liaw, C. Tong, JC. Culberson, RP. Sheridan, BP. Feuston, " /><meta itemprop="datePublished" content="2003" /><meta itemprop="headline" content="Svetnik V, Liaw A, Tong C, Culberson JC, Sheridan RP, Feuston BP: Random Forest: A Classification and Regressi" /><span class="c-article-references__counter">14.</span><p class="c-article-references__text" id="ref-CR14">Svetnik V, Liaw A, Tong C, Culberson JC, Sheridan RP, Feuston BP: Random Forest: A Classification and Regression Tool for Compound Classification and QSAR Modeling. Journal of Chemical Information and Computer Sciences 2003, 43: 19471958. 10.1021/ci034160g</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="/articles/cas-redirect/1%3ACAS%3A528%3ADC%252BD3sXos1Wiu7s%253D" aria-label="View reference 14 on CAS">CAS</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=14632445" aria-label="View reference 14 on PubMed" rel="nofollow">PubMed</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 14 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Random%20Forest%3A%20A%20Classification%20and%20Regression%20Tool%20for%20Compound%20Classification%20and%20QSAR%20Modeling&amp;journal=Journal%20of%20Chemical%20Information%20and%20Computer%20Sciences&amp;volume=43&amp;pages=1947-1958&amp;publication_year=2003&amp;author=Svetnik%2CV&amp;author=Liaw%2CA&amp;author=Tong%2CC&amp;author=Culberson%2CJC&amp;author=Sheridan%2CRP&amp;author=Feuston%2CBP">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="K. Arun, CJ. Langmead, " /><meta itemprop="datePublished" content="2006" /><meta itemprop="headline" content="Arun K, Langmead CJ: Structure Based Chemical Shift Prediction Using Random Forests Non-linear Regression. In " /><span class="c-article-references__counter">15.</span><p class="c-article-references__text" id="ref-CR15">Arun K, Langmead CJ: Structure Based Chemical Shift Prediction Using Random Forests Non-linear Regression. In Proceedings of the Fourth Asia-Pacific Bioinformatics Conference, Taipei, Taiwan Edited by: Jiang T, Yang UC, Chen YPP, Wong L. 2006, 317326.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 15 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Proceedings%20of%20the%20Fourth%20Asia-Pacific%20Bioinformatics%20Conference%2C%20Taipei%2C%20Taiwan&amp;pages=317-326&amp;publication_year=2006&amp;author=Arun%2CK&amp;author=Langmead%2CCJ">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="C. Furlanello, M. Neteler, S. Merler, S. Menegon, S. Fontanari, D. Donini, A. Rizzoli, C. Chemini, " /><meta itemprop="datePublished" content="2003" /><meta itemprop="headline" content="Furlanello C, Neteler M, Merler S, Menegon S, Fontanari S, Donini D, Rizzoli A, Chemini C: GIS and the Random " /><span class="c-article-references__counter">16.</span><p class="c-article-references__text" id="ref-CR16">Furlanello C, Neteler M, Merler S, Menegon S, Fontanari S, Donini D, Rizzoli A, Chemini C: GIS and the Random Forest Predictor: Integration in R for Tick-Borne Disease Risk Assessment.In Proceedings of the 3rd International Workshop on Distributed Statistical Computing, Vienna, Austria Edited by: Hornik K, Leisch F, Zeileis A. 2003. [<a href="http://www.ci.tuwien.ac.at/Conferences/DSC-2003/Proceedings/">http://www.ci.tuwien.ac.at/Conferences/DSC-2003/Proceedings/</a>]</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 16 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Proceedings%20of%20the%203rd%20International%20Workshop%20on%20Distributed%20Statistical%20Computing%2C%20Vienna%2C%20Austria&amp;publication_year=2003&amp;author=Furlanello%2CC&amp;author=Neteler%2CM&amp;author=Merler%2CS&amp;author=Menegon%2CS&amp;author=Fontanari%2CS&amp;author=Donini%2CD&amp;author=Rizzoli%2CA&amp;author=Chemini%2CC">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="MM. Ward, S. Pajevic, J. Dreyfuss, JD. Malley, " /><meta itemprop="datePublished" content="2006" /><meta itemprop="headline" content="Ward MM, Pajevic S, Dreyfuss J, Malley JD: Short-Term Prediction of Mortality in Patients with Systemic Lupus " /><span class="c-article-references__counter">17.</span><p class="c-article-references__text" id="ref-CR17">Ward MM, Pajevic S, Dreyfuss J, Malley JD: Short-Term Prediction of Mortality in Patients with Systemic Lupus Erythematosus: Classification of Outcomes Using Random Forests. Arthritis and Rheumatism 2006, 55: 7480. 10.1002/art.21695</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1002%2Fart.21695" aria-label="View reference 17">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=16463416" aria-label="View reference 17 on PubMed" rel="nofollow">PubMed</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 17 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Short-Term%20Prediction%20of%20Mortality%20in%20Patients%20with%20Systemic%20Lupus%20Erythematosus%3A%20Classification%20of%20Outcomes%20Using%20Random%20Forests&amp;journal=Arthritis%20and%20Rheumatism&amp;volume=55&amp;pages=74-80&amp;publication_year=2006&amp;author=Ward%2CMM&amp;author=Pajevic%2CS&amp;author=Dreyfuss%2CJ&amp;author=Malley%2CJD">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="L. Breiman, JH. Friedman, RA. Olshen, CJ. Stone, " /><meta itemprop="datePublished" content="1984" /><meta itemprop="headline" content="Breiman L, Friedman JH, Olshen RA, Stone CJ: Classification and Regression Trees. New York: Chapman and Hall; " /><span class="c-article-references__counter">18.</span><p class="c-article-references__text" id="ref-CR18">Breiman L, Friedman JH, Olshen RA, Stone CJ: Classification and Regression Trees. New York: Chapman and Hall; 1984.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 18 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Classification%20and%20Regression%20Trees&amp;publication_year=1984&amp;author=Breiman%2CL&amp;author=Friedman%2CJH&amp;author=Olshen%2CRA&amp;author=Stone%2CCJ">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="J. Friedman, " /><meta itemprop="datePublished" content="2001" /><meta itemprop="headline" content="Friedman J: Greedy Function Approximation: A Gradient Boosting Machine. The Annals of Statistics 2001, 29: 118" /><span class="c-article-references__counter">19.</span><p class="c-article-references__text" id="ref-CR19">Friedman J: Greedy Function Approximation: A Gradient Boosting Machine. The Annals of Statistics 2001, 29: 11891232. 10.1214/aos/1013203451</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1214%2Faos%2F1013203451" aria-label="View reference 19">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 19 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Greedy%20Function%20Approximation%3A%20A%20Gradient%20Boosting%20Machine&amp;journal=The%20Annals%20of%20Statistics&amp;volume=29&amp;pages=1189-1232&amp;publication_year=2001&amp;author=Friedman%2CJ">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="datePublished" content="2006" /><meta itemprop="headline" content="R Development Core Team:R: A Language and Environment for Statistical Computing. R Foundation for Statistical " /><span class="c-article-references__counter">20.</span><p class="c-article-references__text" id="ref-CR20">R Development Core Team:R: A Language and Environment for Statistical Computing. R Foundation for Statistical Computing, Vienna, Austria; 2006. [<a href="http://www.R-project.org/">http://www.R-project.org/</a>]</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 20 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=R%3A%20A%20Language%20and%20Environment%20for%20Statistical%20Computing&amp;publication_year=2006">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="L. Breiman, A. Cutler, A. Liaw, M. Wiener, " /><meta itemprop="datePublished" content="2006" /><meta itemprop="headline" content="Breiman L, Cutler A, Liaw A, Wiener M:Breiman and Cutler's Random Forests for Classification and Regression. 2" /><span class="c-article-references__counter">21.</span><p class="c-article-references__text" id="ref-CR21">Breiman L, Cutler A, Liaw A, Wiener M:Breiman and Cutler's Random Forests for Classification and Regression. 2006. [R package version 4.516]. [<a href="http://CRAN.R-project.org/">http://CRAN.R-project.org/</a>] [R package version 4.516].</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 21 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Breiman%20and%20Cutler%27s%20Random%20Forests%20for%20Classification%20and%20Regression&amp;publication_year=2006&amp;author=Breiman%2CL&amp;author=Cutler%2CA&amp;author=Liaw%2CA&amp;author=Wiener%2CM">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="A. Liaw, M. Wiener, " /><meta itemprop="datePublished" content="2002" /><meta itemprop="headline" content="Liaw A, Wiener M: Classification and Regression by randomForest. R News 2002, 2: 1822. [http://CRAN.R-project" /><span class="c-article-references__counter">22.</span><p class="c-article-references__text" id="ref-CR22">Liaw A, Wiener M: Classification and Regression by randomForest. R News 2002, 2: 1822. [<a href="http://CRAN.R-project.org/doc/Rnews/">http://CRAN.R-project.org/doc/Rnews/</a>]</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 22 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Classification%20and%20Regression%20by%20randomForest&amp;journal=R%20News&amp;volume=2&amp;pages=18-22&amp;publication_year=2002&amp;author=Liaw%2CA&amp;author=Wiener%2CM">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="T. Hothorn, K. Hornik, A. Zeileis, " /><meta itemprop="datePublished" content="2006" /><meta itemprop="headline" content="Hothorn T, Hornik K, Zeileis A:party: A Laboratory for Recursive Part(y)itioning. 2006. [R package version 0.9" /><span class="c-article-references__counter">23.</span><p class="c-article-references__text" id="ref-CR23">Hothorn T, Hornik K, Zeileis A:party: A Laboratory for Recursive Part(y)itioning. 2006. [R package version 0.90]. [<a href="http://CRAN.R-project.org/">http://CRAN.R-project.org/</a>] [R package version 0.9-0].</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 23 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=party%3A%20A%20Laboratory%20for%20Recursive%20Part%28y%29itioning&amp;publication_year=2006&amp;author=Hothorn%2CT&amp;author=Hornik%2CK&amp;author=Zeileis%2CA">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="I. Kononenko, " /><meta itemprop="datePublished" content="1995" /><meta itemprop="headline" content="Kononenko I: On Biases in Estimating Multi-Valued Attributes. In Proceedings of the Fourteenth International J" /><span class="c-article-references__counter">24.</span><p class="c-article-references__text" id="ref-CR24">Kononenko I: On Biases in Estimating Multi-Valued Attributes. In Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence, Montral, Canada Edited by: Mellish C. 1995, 10341040.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 24 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Proceedings%20of%20the%20Fourteenth%20International%20Joint%20Conference%20on%20Artificial%20Intelligence%2C%20Montr%C3%A9al%2C%20Canada&amp;pages=1034-1040&amp;publication_year=1995&amp;author=Kononenko%2CI">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="H. Kim, W. Loh, " /><meta itemprop="datePublished" content="2001" /><meta itemprop="headline" content="Kim H, Loh W: Classification Trees with Unbiased Multiway Splits. Journal of the American Statistical Associat" /><span class="c-article-references__counter">25.</span><p class="c-article-references__text" id="ref-CR25">Kim H, Loh W: Classification Trees with Unbiased Multiway Splits. Journal of the American Statistical Association 2001, 96: 589604. 10.1198/016214501753168271</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1198%2F016214501753168271" aria-label="View reference 25">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 25 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Classification%20Trees%20with%20Unbiased%20Multiway%20Splits&amp;journal=Journal%20of%20the%20American%20Statistical%20Association&amp;volume=96&amp;pages=589-604&amp;publication_year=2001&amp;author=Kim%2CH&amp;author=Loh%2CW">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="AL. Boulesteix, " /><meta itemprop="datePublished" content="2006" /><meta itemprop="headline" content="Boulesteix AL: Maximally Selected Chi-square Statistics for Ordinal Variables. Biometrical Journal 2006, 48: 4" /><span class="c-article-references__counter">26.</span><p class="c-article-references__text" id="ref-CR26">Boulesteix AL: Maximally Selected Chi-square Statistics for Ordinal Variables. Biometrical Journal 2006, 48: 451462. 10.1002/bimj.200510161</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1002%2Fbimj.200510161" aria-label="View reference 26">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=16845908" aria-label="View reference 26 on PubMed" rel="nofollow">PubMed</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 26 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Maximally%20Selected%20Chi-square%20Statistics%20for%20Ordinal%20Variables&amp;journal=Biometrical%20Journal&amp;volume=48&amp;pages=451-462&amp;publication_year=2006&amp;author=Boulesteix%2CAL">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="AL. Boulesteix, " /><meta itemprop="datePublished" content="2006" /><meta itemprop="headline" content="Boulesteix AL: Maximally Selected Chi-square Statistics and Binary Splits of Nominal Variables. Biometrical Jo" /><span class="c-article-references__counter">27.</span><p class="c-article-references__text" id="ref-CR27">Boulesteix AL: Maximally Selected Chi-square Statistics and Binary Splits of Nominal Variables. Biometrical Journal 2006, 48: 838848. 10.1002/bimj.200510191</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1002%2Fbimj.200510191" aria-label="View reference 27">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=17094347" aria-label="View reference 27 on PubMed" rel="nofollow">PubMed</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 27 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Maximally%20Selected%20Chi-square%20Statistics%20and%20Binary%20Splits%20of%20Nominal%20Variables&amp;journal=Biometrical%20Journal&amp;volume=48&amp;pages=838-848&amp;publication_year=2006&amp;author=Boulesteix%2CAL">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="C. Strobl, AL. Boulesteix, T. Augustin, " /><meta itemprop="datePublished" content="2006" /><meta itemprop="headline" content="Strobl C, Boulesteix AL, Augustin T: Unbiased Split Selection for Classification Trees Based on the Gini Index" /><span class="c-article-references__counter">28.</span><p class="c-article-references__text" id="ref-CR28">Strobl C, Boulesteix AL, Augustin T: Unbiased Split Selection for Classification Trees Based on the Gini Index. Computational Statistics &amp; Data Analysis 2006. [<a href="http://dx.doi.org/10.1016/j.csda.2006.12.030">http://dx.doi.org/10.1016/j.csda.2006.12.030</a>]</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 28 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Computational%20Statistics%20%26%20Data%20Analysis&amp;publication_year=2006&amp;author=Strobl%2CC&amp;author=Boulesteix%2CAL&amp;author=Augustin%2CT">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="T. Hothorn, K. Hornik, A. Zeileis, " /><meta itemprop="datePublished" content="2006" /><meta itemprop="headline" content="Hothorn T, Hornik K, Zeileis A: Unbiased Recursive Partitioning: A Conditional Inference Framework. Journal of" /><span class="c-article-references__counter">29.</span><p class="c-article-references__text" id="ref-CR29">Hothorn T, Hornik K, Zeileis A: Unbiased Recursive Partitioning: A Conditional Inference Framework. Journal of Computational and Graphical Statistics 2006, 15: 651674. 10.1198/106186006X133933</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1198%2F106186006X133933" aria-label="View reference 29">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 29 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Unbiased%20Recursive%20Partitioning%3A%20A%20Conditional%20Inference%20Framework&amp;journal=Journal%20of%20Computational%20and%20Graphical%20Statistics&amp;volume=15&amp;pages=651-674&amp;publication_year=2006&amp;author=Hothorn%2CT&amp;author=Hornik%2CK&amp;author=Zeileis%2CA">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="J. Friedman, P. Hall, " /><meta itemprop="datePublished" content="1999" /><meta itemprop="headline" content="Friedman J, Hall P: On Bagging and Nonlinear Estimation. preprint 1999. [http://www-stat.stanford.edu/~jhf/]" /><span class="c-article-references__counter">30.</span><p class="c-article-references__text" id="ref-CR30">Friedman J, Hall P: On Bagging and Nonlinear Estimation. preprint 1999. [<a href="http://www-stat.stanford.edu/~jhf/">http://www-stat.stanford.edu/~jhf/</a>]</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 30 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=preprint&amp;publication_year=1999&amp;author=Friedman%2CJ&amp;author=Hall%2CP">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="P. Bhlmann, B. Yu, " /><meta itemprop="datePublished" content="2002" /><meta itemprop="headline" content="Bhlmann P, Yu B: Analyzing Bagging. The Annals of Statistics 2002, 30: 927961. 10.1214/aos/1031689014" /><span class="c-article-references__counter">31.</span><p class="c-article-references__text" id="ref-CR31">Bhlmann P, Yu B: Analyzing Bagging. The Annals of Statistics 2002, 30: 927961. 10.1214/aos/1031689014</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1214%2Faos%2F1031689014" aria-label="View reference 31">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 31 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Analyzing%20Bagging&amp;journal=The%20Annals%20of%20Statistics&amp;volume=30&amp;pages=927-961&amp;publication_year=2002&amp;author=B%C3%BChlmann%2CP&amp;author=Yu%2CB">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="DN. Politis, JP. Romano, M. Wolf, " /><meta itemprop="datePublished" content="1999" /><meta itemprop="headline" content="Politis DN, Romano JP, Wolf M: Subsampling. New York: Springer; 1999." /><span class="c-article-references__counter">32.</span><p class="c-article-references__text" id="ref-CR32">Politis DN, Romano JP, Wolf M: Subsampling. New York: Springer; 1999.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 32 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Subsampling&amp;publication_year=1999&amp;author=Politis%2CDN&amp;author=Romano%2CJP&amp;author=Wolf%2CM">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="A. Dobra, J. Gehrke, " /><meta itemprop="datePublished" content="2001" /><meta itemprop="headline" content="Dobra A, Gehrke J: Bias Correction in Classification Tree Construction. In Proceedings of the Seventeenth Inte" /><span class="c-article-references__counter">33.</span><p class="c-article-references__text" id="ref-CR33">Dobra A, Gehrke J: Bias Correction in Classification Tree Construction. In Proceedings of the Seventeenth International Conference on Machine Learning, Williams College, Williamstown, MA, USA Edited by: Brodley CE, Danyluk AP. 2001, 9097.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 33 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Proceedings%20of%20the%20Seventeenth%20International%20Conference%20on%20Machine%20Learning%2C%20Williams%20College%2C%20Williamstown%2C%20MA%2C%20USA&amp;pages=90-97&amp;publication_year=2001&amp;author=Dobra%2CA&amp;author=Gehrke%2CJ">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="C. Strobl, " /><meta itemprop="datePublished" content="2005" /><meta itemprop="headline" content="Strobl C: Statistical Sources of Variable Selection Bias in Classification Tree Algorithms Based on the Gini I" /><span class="c-article-references__counter">34.</span><p class="c-article-references__text" id="ref-CR34">Strobl C: Statistical Sources of Variable Selection Bias in Classification Tree Algorithms Based on the Gini Index. Discussion Paper 420, SFB "Statistical Analysis of Discrete Structures", Munich, Germany 2005. [<a href="http://www.stat.uni-muenchen.de/sfb386/papers/dsp/paper420.ps">http://www.stat.uni-muenchen.de/sfb386/papers/dsp/paper420.ps</a>]</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 34 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Discussion%20Paper%20420%2C%20SFB%20%22Statistical%20Analysis%20of%20Discrete%20Structures%22%2C%20Munich%2C%20Germany&amp;publication_year=2005&amp;author=Strobl%2CC">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="C. Strobl, " /><meta itemprop="datePublished" content="2005" /><meta itemprop="headline" content="Strobl C: Variable Selection in Classification Trees Based on Imprecise Probabilities. In Proceedings of the F" /><span class="c-article-references__counter">35.</span><p class="c-article-references__text" id="ref-CR35">Strobl C: Variable Selection in Classification Trees Based on Imprecise Probabilities. In Proceedings of the Fourth International Symposium on Imprecise Probabilities and Their Applications, Carnegy Mellon University, Pittsburgh, PA, USA Edited by: Cozman F, Nau R, Seidenfeld T. 2005, 340348.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 35 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Proceedings%20of%20the%20Fourth%20International%20Symposium%20on%20Imprecise%20Probabilities%20and%20Their%20Applications%2C%20Carnegy%20Mellon%20University%2C%20Pittsburgh%2C%20PA%2C%20USA&amp;pages=340-348&amp;publication_year=2005&amp;author=Strobl%2CC">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="TM. Therneau, B. Atkinson, BD. Ripley, " /><meta itemprop="datePublished" content="2006" /><meta itemprop="headline" content="Therneau TM, Atkinson B, Ripley BD:rpart: Recursive Partitioning. 2006. [R package version 3.130]. [http://CR" /><span class="c-article-references__counter">36.</span><p class="c-article-references__text" id="ref-CR36">Therneau TM, Atkinson B, Ripley BD:rpart: Recursive Partitioning. 2006. [R package version 3.130]. [<a href="http://CRAN.R-project.org/">http://CRAN.R-project.org/</a>] [R package version 3.130].</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 36 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=rpart%3A%20Recursive%20Partitioning&amp;publication_year=2006&amp;author=Therneau%2CTM&amp;author=Atkinson%2CB&amp;author=Ripley%2CBD">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="PJ. Bickel, JJ. Ren, " /><meta itemprop="datePublished" content="2001" /><meta itemprop="headline" content="Bickel PJ, Ren JJ: The Bootstrap in Hypothesis Testing. In State of the Art in Probability and Statistics, Fes" /><span class="c-article-references__counter">37.</span><p class="c-article-references__text" id="ref-CR37">Bickel PJ, Ren JJ: The Bootstrap in Hypothesis Testing. In State of the Art in Probability and Statistics, Festschrift for Willem R. van Zwet, IMS Lecture Notes Monograph Series, Beachwood, OH, USA Edited by: de Gunst M, Klaassen C, van der Vaart A. 2001, 36: 91112.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 37 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=State%20of%20the%20Art%20in%20Probability%20and%20Statistics%2C%20Festschrift%20for%20Willem%20R.%20van%20Zwet%2C%20IMS%20Lecture%20Notes%20Monograph%20Series%2C%20Beachwood%2C%20OH%2C%20USA&amp;pages=91-112&amp;publication_year=2001&amp;author=Bickel%2CPJ&amp;author=Ren%2CJJ">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="M. van der Laan, " /><meta itemprop="datePublished" content="2006" /><meta itemprop="headline" content="van der Laan M: Statistical Inference for Variable Importance. International Journal of Biostatistics 2006, 2:" /><span class="c-article-references__counter">38.</span><p class="c-article-references__text" id="ref-CR38">van der Laan M: Statistical Inference for Variable Importance. International Journal of Biostatistics 2006, 2: 10081008.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 38 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Statistical%20Inference%20for%20Variable%20Importance&amp;journal=International%20Journal%20of%20Biostatistics&amp;volume=2&amp;pages=1008-1008&amp;publication_year=2006&amp;author=van%20der%20Laan%2CM">
                        Google Scholar</a></li></ul></li></ol><p class="c-article-references__download u-hide-print"><a data-track="click" data-track-action="download citation references" data-track-category="article body" data-track-label="link" href="/articles/10.1186/1471-2105-8-25-references.ris">Download references<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p></div></div></div></section><section aria-labelledby="Ack1"><div class="c-article-section" id="Ack1-section"><h2 class="c-article-section__title u-h2 js-section-title js-c-reading-companion-sections-item" id="Ack1">Acknowledgements</h2><div class="c-article-section__content" id="Ack1-content"><p>CS was supported by the German Research Foundation (DFG), collaborative research center 386 "Statistical Analysis of Discrete Structures". TH received financial support from DFG grant HO 3242/13. The authors would like to thank Thomas Augustin, Friedrich Leisch and Gerhard Tutz for fruitful discussions and for supporting our interest in this field of research, and Peter Bhlmann, an anonymous referee and a semi-anonymous referee for their helpful suggestions.</p></div></div></section><section aria-labelledby="author-information"><div class="c-article-section" id="author-information-section"><h2 class="c-article-section__title u-h2 js-section-title js-c-reading-companion-sections-item" id="author-information">Author information</h2><div class="c-article-section__content" id="author-information-content"><h3 class="c-article-author-information__subtitle u-h3" id="affiliations">Affiliations</h3><ol class="c-article-author-affiliation__list"><li id="Aff1"><span class="c-article-author-affiliation__address u-h3">Institut fr Statistik, Ludwig-Maximilians-Universitt Mnchen, Ludwigstr. 33, 80539, Mnchen, Germany</span><ul class="c-article-author-affiliation__authors-list"><li class="c-article-author-affiliation__authors-item">Carolin Strobl</li></ul></li><li id="Aff2"><span class="c-article-author-affiliation__address u-h3">Institut fr medizinische Statistik und Epidemiologie, Technische Universitt Mnchen, Ismaningerstr. 22, 81675, Mnchen, Germany</span><ul class="c-article-author-affiliation__authors-list"><li class="c-article-author-affiliation__authors-item">Anne-Laure Boulesteix</li></ul></li><li id="Aff3"><span class="c-article-author-affiliation__address u-h3">Department fr Statistik und Mathematik, Wirtschaftsuniversitt Wien, Augasse 2-6, 1090, Wien, Austria</span><ul class="c-article-author-affiliation__authors-list"><li class="c-article-author-affiliation__authors-item">Achim Zeileis</li></ul></li><li id="Aff4"><span class="c-article-author-affiliation__address u-h3">Institut fr Medizininformatik, Biometrie und Epidemiologie, Friedrich-Alexander-Universtitt Erlangen-Nrnberg, Waldstr. 6, D-91054, Erlangen, Germany</span><ul class="c-article-author-affiliation__authors-list"><li class="c-article-author-affiliation__authors-item">Torsten Hothorn</li></ul></li></ol><div class="js-hide u-hide-print" data-test="author-info"><span class="c-article-author-information__subtitle u-h3">Authors</span><ol class="c-article-author-authors-search"><li id="auth-1"><span class="c-article-author-authors-search__title u-h3 js-search-name">Search for Carolin Strobl in:</span><ul class="c-article-author-authors-search__list"><li class="c-article-author-authors-search__item"><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Carolin+Strobl">PubMed</a><span class="bullet">  </span></li><li class="c-article-author-authors-search__item"><a href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Carolin+Strobl%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en">
                        Google Scholar
                    </a></li></ul></li><li id="auth-2"><span class="c-article-author-authors-search__title u-h3 js-search-name">Search for Anne-Laure Boulesteix in:</span><ul class="c-article-author-authors-search__list"><li class="c-article-author-authors-search__item"><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Anne-Laure+Boulesteix">PubMed</a><span class="bullet">  </span></li><li class="c-article-author-authors-search__item"><a href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Anne-Laure+Boulesteix%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en">
                        Google Scholar
                    </a></li></ul></li><li id="auth-3"><span class="c-article-author-authors-search__title u-h3 js-search-name">Search for Achim Zeileis in:</span><ul class="c-article-author-authors-search__list"><li class="c-article-author-authors-search__item"><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Achim+Zeileis">PubMed</a><span class="bullet">  </span></li><li class="c-article-author-authors-search__item"><a href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Achim+Zeileis%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en">
                        Google Scholar
                    </a></li></ul></li><li id="auth-4"><span class="c-article-author-authors-search__title u-h3 js-search-name">Search for Torsten Hothorn in:</span><ul class="c-article-author-authors-search__list"><li class="c-article-author-authors-search__item"><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Torsten+Hothorn">PubMed</a><span class="bullet">  </span></li><li class="c-article-author-authors-search__item"><a href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Torsten+Hothorn%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en">
                        Google Scholar
                    </a></li></ul></li></ol></div><h3 class="c-article-author-information__subtitle u-h3" id="corresponding-author">Corresponding author</h3><p>Correspondence to
                <a id="corresp-c1" rel="nofollow" href="/articles/10.1186/1471-2105-8-25/email/correspondent/c1/new">Carolin Strobl</a>.</p></div></div></section><section aria-labelledby="additional-information"><div class="c-article-section" id="additional-information-section"><h2 class="c-article-section__title u-h2 js-section-title js-c-reading-companion-sections-item" id="additional-information">Additional information</h2><div class="c-article-section__content" id="additional-information-content"><h3 class="c-article__sub-heading u-h3">Authors' contributions</h3><p>CS first observed the variable selection bias in random forests, set up and performed the simulation experiments, studied the sources of the selection bias and drafted the manuscript. ALB, AZ and TH contributed to the design of the simulation experiments, to theoretical investigations of the problem, and to the manuscript. TH implemented the cforest, ctree and varimp functions. ALB analyzed the C-to-U conversion data. All authors read and approved the final manuscript.</p></div></div></section><section aria-labelledby="Sec13"><div class="c-article-section" id="Sec13-section"><h2 class="c-article-section__title u-h2 js-section-title js-c-reading-companion-sections-item" id="Sec13">Electronic supplementary material</h2><div class="c-article-section__content" id="Sec13-content"><div data-test="supplementary-info"><div id="qa-widgetContainer" data-test="figshare-container"></div>
                  
                <div class="c-article-supplementary__item" data-test="supp-item" id="MOESM1"><h3 class="c-article-supplementary__title u-h3"><a class="print-link" data-track="click" data-track-category="article body" data-track-action="view supplementary info" data-track-label="link" data-test="supp-info-link" href="https://static-content.springer.com/esm/art%3A10.1186%2F1471-2105-8-25/MediaObjects/12859_2006_1397_MOESM1_ESM.R" data-supp-info-image="">Additional File 1: <b>R source code</b>. The exemplary R source code includes all function calls and comments on all important options of the randomForest and cforest functions, that were used in the simulation studies and the application to C-to-U conversion data. Please install the latest versions of the packages randomForest and party before use. (R 8 KB)</a></h3></div></div></div></div></section><section aria-labelledby="Sec14"><div class="c-article-section" id="Sec14-section"><h2 class="c-article-section__title u-h2 js-section-title js-c-reading-companion-sections-item" id="Sec14">Authors original submitted files for images</h2><div class="c-article-section__content" id="Sec14-content"><div data-test="supplementary-info"><div id="qa-widgetContainer" data-test="figshare-container"></div><p>Below are the links to the authors original submitted files for images.</p><div class="c-article-supplementary__item" data-test="supp-item" id="MOESM2"><h3 class="c-article-supplementary__title u-h3"><a class="print-link" data-track="click" data-track-category="article body" data-track-action="view supplementary info" data-track-label="link" data-test="supp-info-link" href="https://static-content.springer.com/esm/art%3A10.1186%2F1471-2105-8-25/MediaObjects/12859_2006_1397_MOESM2_ESM.pdf" data-supp-info-image="">Authors original file for figure 1</a></h3></div><div class="c-article-supplementary__item" data-test="supp-item" id="MOESM3"><h3 class="c-article-supplementary__title u-h3"><a class="print-link" data-track="click" data-track-category="article body" data-track-action="view supplementary info" data-track-label="link" data-test="supp-info-link" href="https://static-content.springer.com/esm/art%3A10.1186%2F1471-2105-8-25/MediaObjects/12859_2006_1397_MOESM3_ESM.pdf" data-supp-info-image="">Authors original file for figure 2</a></h3></div><div class="c-article-supplementary__item" data-test="supp-item" id="MOESM4"><h3 class="c-article-supplementary__title u-h3"><a class="print-link" data-track="click" data-track-category="article body" data-track-action="view supplementary info" data-track-label="link" data-test="supp-info-link" href="https://static-content.springer.com/esm/art%3A10.1186%2F1471-2105-8-25/MediaObjects/12859_2006_1397_MOESM4_ESM.pdf" data-supp-info-image="">Authors original file for figure 3</a></h3></div><div class="c-article-supplementary__item" data-test="supp-item" id="MOESM5"><h3 class="c-article-supplementary__title u-h3"><a class="print-link" data-track="click" data-track-category="article body" data-track-action="view supplementary info" data-track-label="link" data-test="supp-info-link" href="https://static-content.springer.com/esm/art%3A10.1186%2F1471-2105-8-25/MediaObjects/12859_2006_1397_MOESM5_ESM.pdf" data-supp-info-image="">Authors original file for figure 4</a></h3></div><div class="c-article-supplementary__item" data-test="supp-item" id="MOESM6"><h3 class="c-article-supplementary__title u-h3"><a class="print-link" data-track="click" data-track-category="article body" data-track-action="view supplementary info" data-track-label="link" data-test="supp-info-link" href="https://static-content.springer.com/esm/art%3A10.1186%2F1471-2105-8-25/MediaObjects/12859_2006_1397_MOESM6_ESM.pdf" data-supp-info-image="">Authors original file for figure 5</a></h3></div><div class="c-article-supplementary__item" data-test="supp-item" id="MOESM7"><h3 class="c-article-supplementary__title u-h3"><a class="print-link" data-track="click" data-track-category="article body" data-track-action="view supplementary info" data-track-label="link" data-test="supp-info-link" href="https://static-content.springer.com/esm/art%3A10.1186%2F1471-2105-8-25/MediaObjects/12859_2006_1397_MOESM7_ESM.pdf" data-supp-info-image="">Authors original file for figure 6</a></h3></div><div class="c-article-supplementary__item" data-test="supp-item" id="MOESM8"><h3 class="c-article-supplementary__title u-h3"><a class="print-link" data-track="click" data-track-category="article body" data-track-action="view supplementary info" data-track-label="link" data-test="supp-info-link" href="https://static-content.springer.com/esm/art%3A10.1186%2F1471-2105-8-25/MediaObjects/12859_2006_1397_MOESM8_ESM.pdf" data-supp-info-image="">Authors original file for figure 7</a></h3></div><div class="c-article-supplementary__item" data-test="supp-item" id="MOESM9"><h3 class="c-article-supplementary__title u-h3"><a class="print-link" data-track="click" data-track-category="article body" data-track-action="view supplementary info" data-track-label="link" data-test="supp-info-link" href="https://static-content.springer.com/esm/art%3A10.1186%2F1471-2105-8-25/MediaObjects/12859_2006_1397_MOESM9_ESM.pdf" data-supp-info-image="">Authors original file for figure 8</a></h3></div><div class="c-article-supplementary__item" data-test="supp-item" id="MOESM10"><h3 class="c-article-supplementary__title u-h3"><a class="print-link" data-track="click" data-track-category="article body" data-track-action="view supplementary info" data-track-label="link" data-test="supp-info-link" href="https://static-content.springer.com/esm/art%3A10.1186%2F1471-2105-8-25/MediaObjects/12859_2006_1397_MOESM10_ESM.pdf" data-supp-info-image="">Authors original file for figure 9</a></h3></div><div class="c-article-supplementary__item" data-test="supp-item" id="MOESM11"><h3 class="c-article-supplementary__title u-h3"><a class="print-link" data-track="click" data-track-category="article body" data-track-action="view supplementary info" data-track-label="link" data-test="supp-info-link" href="https://static-content.springer.com/esm/art%3A10.1186%2F1471-2105-8-25/MediaObjects/12859_2006_1397_MOESM11_ESM.pdf" data-supp-info-image="">Authors original file for figure 10</a></h3></div><div class="c-article-supplementary__item" data-test="supp-item" id="MOESM12"><h3 class="c-article-supplementary__title u-h3"><a class="print-link" data-track="click" data-track-category="article body" data-track-action="view supplementary info" data-track-label="link" data-test="supp-info-link" href="https://static-content.springer.com/esm/art%3A10.1186%2F1471-2105-8-25/MediaObjects/12859_2006_1397_MOESM12_ESM.pdf" data-supp-info-image="">Authors original file for figure 11</a></h3></div></div></div></div></section><section aria-labelledby="rightslink"><div class="c-article-section" id="rightslink-section"><h2 class="c-article-section__title u-h2 js-section-title js-c-reading-companion-sections-item" id="rightslink">Rights and permissions</h2><div class="c-article-section__content" id="rightslink-content"><div class="c-article-license">
                <p>This article is published under license to BioMed Central Ltd. This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<a href="http://creativecommons.org/licenses/by/2.0" rel="license" itemprop="license">http://creativecommons.org/licenses/by/2.0</a>), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.</p>
              </div><p class="c-article-rights"><a data-track="click" data-track-action="view rights and permissions" data-track-category="article body" data-track-label="link" href="https://s100.copyright.com/AppDispatchServlet?imprint=Nature&amp;oa=CC%20BY&amp;title=Bias%20in%20random%20forest%20variable%20importance%20measures%3A%20Illustrations%2C%20sources%20and%20a%20solution&amp;author=Carolin%20Strobl%20et%20al&amp;contentID=10.1186%2F1471-2105-8-25&amp;publication=BMC%20Bioinformatics&amp;publicationDate=2007-01-25&amp;publisherName=SpringerNature&amp;orderBeanReset=true">Reprints and Permissions</a></p></div></div></section><section aria-labelledby="article-info"><div class="c-article-section" id="article-info-section"><h2 class="c-article-section__title u-h2 js-section-title js-c-reading-companion-sections-item" id="article-info">About this article</h2><div class="c-article-section__content" id="article-info-content"><div class="c-bibliographic-information"><div class="c-bibliographic-information__column"><h3 class="c-article__sub-heading" id="citeas">Cite this article</h3><p class="c-bibliographic-information__citation">Strobl, C., Boulesteix, A., Zeileis, A. <i>et al.</i> Bias in random forest variable importance measures: Illustrations, sources and a solution.
                    <i>BMC Bioinformatics</i> <b>8, </b>25 (2007)  doi:10.1186/1471-2105-8-25</p><p class="c-bibliographic-information__download-citation u-hide-print"><a data-test="citation-link" data-track="click" data-track-action="download article citation" data-track-category="article body" data-track-label="link" href="/articles/10.1186/1471-2105-8-25.ris">Download citation<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p><ul class="c-bibliographic-information__list" data-test="publication-history"><li class="c-bibliographic-information__list-item"><span class="u-h4">Received</span><p class="c-bibliographic-information__value"><time datetime="2006-09-18">18 September 2006</time></p></li><li class="c-bibliographic-information__list-item"><span class="u-h4">Accepted</span><p class="c-bibliographic-information__value"><time datetime="2007-01-25">25 January 2007</time></p></li><li class="c-bibliographic-information__list-item"><span class="u-h4">Published</span><p class="c-bibliographic-information__value"><time datetime="2007-01-25">25 January 2007</time></p></li><li class="c-bibliographic-information__list-item c-bibliographic-information__list-item--doi"><span class="u-h4"><abbr title="Digital Object Identifier">DOI</abbr></span><p class="c-bibliographic-information__value"><a href="https://doi.org/10.1186/1471-2105-8-25" data-track="click" data-track-action="view doi" data-track-category="article body" data-track-label="link" itemprop="sameAs">https://doi.org/10.1186/1471-2105-8-25</a></p></li></ul><div data-component="share-box"></div><h3 class="c-article__sub-heading u-h3">Keywords</h3><ul class="c-article-subject-list"><li class="c-article-subject-list__subject"><span itemprop="about">Variable Selection</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Random Forest</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Bootstrap Sampling</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Variable Importance</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Importance Measure</span></li></ul><div data-component="article-info-list"></div></div></div></div></div></section>

                        


                    </article>
                </main>

                <div class="c-page-layout__side u-text-sm">
                    <aside>
                        
    
    <div class="c-pdf-download u-clear-both">
        <a href="//bmcbioinformatics.biomedcentral.com/track/pdf/10.1186/1471-2105-8-25" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-category="article body" data-track-label="link">
            <span>Download PDF</span>
            <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
        </a>
    </div>
    

                        

                        
        
    

                        <div class="c-reading-companion">
                            <div class="c-reading-companion__sticky" data-component="reading-companion-sticky" data-test="reading-companion-sticky">
                                <div class="c-reading-companion__panel c-reading-companion__sections c-reading-companion__panel--active" id="tabpanel-sections">
                                    <div class="js-ad">
    <div class="adsbox c-ad c-ad--MPU1">
        <div class="c-ad__inner" >
            <p class="c-ad__label">Advertisement</p>
            <div id="div-gpt-ad-MPU1"
                 data-gpt-unitpath="/270604982/bmc/bmcbioinformatics/articles"
                 data-gpt-sizes="300x250"
                 data-gpt-targeting="pos=MPU1;doi=10.1186/1471-2105-8-25;kwrd=Variable Selection,Random Forest,Bootstrap Sampling,Variable Importance,Importance Measure;pmc=L15001,B12050,I23050,L17004,M14018,M14018;"
                 data-ad-type="MPU1">
                <noscript>
                    <a href="//pubads.g.doubleclick.net/gampad/jump?iu=/270604982/bmc/bmcbioinformatics/articles&amp;sz=300x250&amp;pos=MPU1&amp;doi=10.1186/1471-2105-8-25&amp;kwrd=Variable Selection,Random Forest,Bootstrap Sampling,Variable Importance,Importance Measure&amp;pmc=L15001,B12050,I23050,L17004,M14018,M14018&amp;">
                        <img data-test="gpt-advert-fallback-img"
                             src="//pubads.g.doubleclick.net/gampad/ad?iu=/270604982/bmc/bmcbioinformatics/articles&amp;sz=300x250&amp;pos=MPU1&amp;doi=10.1186/1471-2105-8-25&amp;kwrd=Variable Selection,Random Forest,Bootstrap Sampling,Variable Importance,Importance Measure&amp;pmc=L15001,B12050,I23050,L17004,M14018,M14018&amp;"
                             alt="Advertisement"
                             width="300"
                             height="250">
                    </a>
                </noscript>
            </div>
        </div>
    </div>
</div>
                                </div>
                                <div class="c-reading-companion__panel c-reading-companion__figures c-reading-companion__panel--full-width" id="tabpanel-figures"></div>
                                <div class="c-reading-companion__panel c-reading-companion__references c-reading-companion__panel--full-width" id="tabpanel-references"></div>
                            </div>
                        </div>
                    </aside>
                </div>
            </div>
        </div>


        
            <div class="c-journal-footer">
                <div class="c-journal-footer__inner">
                    <div class="c-journal-footer__summary">
                        <h4 class="c-journal-title c-journal-title--footer">
                            
                            <span class="c-journal-title__text">BMC Bioinformatics</span>
                        </h4>
                         <p class="c-journal-footer__issn">ISSN: 1471-2105</p>
                    </div>
                    
                        <div class="c-journal-footer__contact">
                            <h4 class="c-journal-footer__contact-title ">Contact us</h4>
                            <ul class="c-journal-footer__contact-list">
                                
                                    <li class="c-journal-footer__contact-item">Submission enquiries: <a href="mailto:bmcbioinformatics@biomedcentral.com">bmcbioinformatics@biomedcentral.com</a></li>
                                
                                
                                    <li class="c-journal-footer__contact-item">General enquiries: <a href="mailto:info@biomedcentral.com">info@biomedcentral.com</a></li>
                                
                            </ul>
                        </div>
                    
                </div>
            </div>
        
        
    <img rel="nofollow" class='tracker' style='display:none' src='/track/article/10.1186/1471-2105-8-25' alt=""/>

         
    <footer>
        
            <div class="c-publisher-footer" data-test="publisher-footer">
    <div class="u-container">
        
        <div class="u-display-flex u-flex-wrap u-flex-justify-space-between" data-test="publisher-footer-menu">
            <div class="u-display-flex">
                
                    
                        <ul class="c-list-group c-list-group--sm u-margin-right-lg u-margin-bottom-md">
                            
                                <li class="c-list-group__item">
                                    <a class="u-gray-link" href="http://blogs.biomedcentral.com/">Read more on our blogs</a>
                                </li>
                            
                                <li class="c-list-group__item">
                                    <a class="u-gray-link" href="//www.biomedcentral.com/login">Receive BMC newsletters</a>
                                </li>
                            
                                <li class="c-list-group__item">
                                    <a class="u-gray-link" href="//www.biomedcentral.com/account">Manage article alerts</a>
                                </li>
                            
                                <li class="c-list-group__item">
                                    <a class="u-gray-link" href="https://authorservices.springernature.com/go/10BMC">Language editing for authors</a>
                                </li>
                            
                                <li class="c-list-group__item">
                                    <a class="u-gray-link" href="http://authorservices.springernature.com/scientific-editing/">Scientific editing for authors</a>
                                </li>
                            
                        </ul>
                    
                        <ul class="c-list-group c-list-group--sm u-margin-right-lg u-margin-bottom-md">
                            
                                <li class="c-list-group__item">
                                    <a class="u-gray-link" href="//www.biomedcentral.com/about/policies">Policies</a>
                                </li>
                            
                                <li class="c-list-group__item">
                                    <a class="u-gray-link" href="//www.biomedcentral.com/accessibility">Accessibility</a>
                                </li>
                            
                                <li class="c-list-group__item">
                                    <a class="u-gray-link" href="//www.biomedcentral.com/about/press-centre">Press center</a>
                                </li>
                            
                        </ul>
                    
                        <ul class="c-list-group c-list-group--sm u-margin-right-lg u-margin-bottom-md">
                            
                                <li class="c-list-group__item">
                                    <a class="u-gray-link" href="https://support.biomedcentral.com/support/home">Support and Contact</a>
                                </li>
                            
                                <li class="c-list-group__item">
                                    <a class="u-gray-link" href="https://biomedcentral.typeform.com/to/VLXboo">Leave feedback</a>
                                </li>
                            
                                <li class="c-list-group__item">
                                    <a class="u-gray-link" href="//www.biomedcentral.com/about/jobs">Careers</a>
                                </li>
                            
                        </ul>
                    
                
            </div>
            <div class="u-margin-bottom-lg">
                <h3 id="social-menu" class="u-text-sm u-reset-margin u-text-normal">Follow BMC</h3>
                <ul class="u-display-flex u-list-reset" data-test="footer-social-links">
                    
                        <li class="u-margin-top-xs u-margin-right-xs">
                            <a href="https://twitter.com/biomedcentral"
                               class="u-gray-link">
                                <span class="u-visually-hidden">BMC Twitter page</span>
                                <svg class="c-icon" width="24" height="24" aria-hidden="true">
                                    <use xlink:href="#icon-twitter-bordered"></use>
                                </svg>
                            </a>
                        </li>
                    
                        <li class="u-margin-top-xs u-margin-right-xs">
                            <a href="https://www.facebook.com/BioMedCentral"
                               class="u-gray-link">
                                <span class="u-visually-hidden">BMC Facebook page</span>
                                <svg class="c-icon" width="24" height="24" aria-hidden="true">
                                    <use xlink:href="#icon-facebook-bordered"></use>
                                </svg>
                            </a>
                        </li>
                    
                        <li class="u-margin-top-xs u-margin-right-xs">
                            <a href="http://www.weibo.com/biomedcentral"
                               class="u-gray-link">
                                <span class="u-visually-hidden">BMC Weibo page</span>
                                <svg class="c-icon" width="24" height="24" aria-hidden="true">
                                    <use xlink:href="#icon-weibo-bordered"></use>
                                </svg>
                            </a>
                        </li>
                    
                </ul>
            </div>
        </div>
        <p class="u-reset-margin">
            By using this website, you agree to our
            <a class="u-gray-link" href="//www.biomedcentral.com/terms-and-conditions">Terms and Conditions</a>,
            <a class="u-gray-link" href="//www.biomedcentral.com/privacy-statement">Privacy
                statement</a> and
            <a class="u-gray-link" href="//www.biomedcentral.com/cookies" data-test="cookie-link">Cookies</a> policy.
            
                <a class="optanon-toggle-display u-gray-link" href="javascript:void(0);">Manage the cookies</a> we use in the preference centre.
            
        </p>
    </div>
</div>

        
        <div class="c-corporate-footer">
    <div class="u-container">
        <img src=/static/images/logo-springernature-44af1f90df.svg class="c-corporate-footer__logo" alt="Springer Nature" itemprop="logo" role="img">
        <p class="c-corporate-footer__legal" data-test="copyright"> &#169; 2020 BioMed Central Ltd unless otherwise stated. Part of
            <a class="c-corporate-footer__link" href="https://www.springernature.com" itemscope itemtype="http://schema.org/Organization" itemid="#parentOrganization">Springer Nature</a>.
        </p>
    </div>
</div>

        
    </footer>

    </div>

    <noscript>
	<img hidden src="https://verify.nature.com/verify/nature.png" border="0" width="0" height="0" style="display: none">
</noscript>



        
    <svg class="u-hide hide">
        <symbol id="global-icon-chevron-right" viewBox="0 0 16 16">
            <path d="M7.782 7L5.3 4.518c-.393-.392-.4-1.022-.02-1.403a1.001 1.001 0 011.417 0l4.176 4.177a1.001 1.001 0 010 1.416l-4.176 4.177a.991.991 0 01-1.4.016 1 1 0 01.003-1.42L7.782 9l1.013-.998z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-download" viewBox="0 0 16 16">
            <path d="M2 14c0-.556.449-1 1.002-1h9.996a.999.999 0 110 2H3.002A1.006 1.006 0 012 14zM9 2v6.8l2.482-2.482c.392-.392 1.022-.4 1.403-.02a1.001 1.001 0 010 1.417l-4.177 4.177a1.001 1.001 0 01-1.416 0L3.115 7.715a.991.991 0 01-.016-1.4 1 1 0 011.42.003L7 8.8V2c0-.55.444-.996 1-.996.552 0 1 .445 1 .996z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-email" viewBox="0 0 18 18">
            <path d="M1.995 2h14.01A2 2 0 0118 4.006v9.988A2 2 0 0116.005 16H1.995A2 2 0 010 13.994V4.006A2 2 0 011.995 2zM1 13.994A1 1 0 001.995 15h14.01A1 1 0 0017 13.994V4.006A1 1 0 0016.005 3H1.995A1 1 0 001 4.006zM9 11L2 7V5.557l7 4 7-4V7z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-institution" viewBox="0 0 18 18">
            <path d="M14 8a1 1 0 011 1v6h1.5a.5.5 0 01.5.5v.5h.5a.5.5 0 01.5.5V18H0v-1.5a.5.5 0 01.5-.5H1v-.5a.5.5 0 01.5-.5H3V9a1 1 0 112 0v6h8V9a1 1 0 011-1zM6 8l2 1v4l-2 1zm6 0v6l-2-1V9zM9.573.401l7.036 4.925A.92.92 0 0116.081 7H1.92a.92.92 0 01-.528-1.674L8.427.401a1 1 0 011.146 0zM9 2.441L5.345 5h7.31z" fill-rule="evenodd"/>
        </symbol>
    </svg>

        
<script data-test="app-bundle">
    (function() {
        if (window.config && window.config.mustardcut) {
            var appScript = document.createElement('script');
            
            appScript.src = '/static/js/app-bundle-ea63498cd0.js';
            
            appScript.async = false;
            document.body.appendChild(appScript);
        }
    })();
</script>




    
    
    <script>
        window.Component = {};
    </script>
    <script src="/static/js/global-article-bundle-28cec0c85c.js"></script>


    </body>
</html>



